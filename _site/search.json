[
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "ART FROM CODE",
    "section": "Welcome!",
    "text": "Welcome!\n\nAbout the workshop\nComputer-generated artwork has been around for quite a while. The idea of using R for this purpose, however, is a little more recent. Designed originally as a programming language for academic statistical computing, R is now a mainstream language for data science and analytics. Can it also work as an artistic medium? Is there an overlap between our familiar data science workflows and the artistic process? Perhaps we can become better data scientists through art, and vice versa.\nThis workshop provides a hands-on introduction to generative art in R. You’ll learn artistic techniques that generative artists use regularly in their work including flow fields, iterative function systems, and more. You’ll also learn about R packages specialised for generative art. But more than that, you’ll learn how to reuse skills you already have as part of an artistic process: with a little work, ggplot2, dplyr, and Rcpp can become an artist’s best friends. The assumed background is that you’re reasonably comfortable using R and RStudio, and have experience with tidyverse.\nGitHub repository: github.com/rstudio-conf-2022/art-from-code\n\n\nAbout the instructor\nDanielle Navarro is a generative artist, data scientist, professional educator, mathematical psychologist, academic professor in recovery, open source R developer, and occasional essayist. She is currently a developer advocate at Voltron Data working with the Apache Arrow ecosystem. You can find her art at art.djnavarro.net, and other professional details at djnavarro.net. Danielle lives in Sydney, Australia with her two children and her Netflix subscription."
  },
  {
    "objectID": "index.html#day-1-july-25",
    "href": "index.html#day-1-july-25",
    "title": "ART FROM CODE",
    "section": "Day 1: July 25",
    "text": "Day 1: July 25\n\n\nGet started\n\n\n\n\n\n\n\n\n\n\n\nTime: 09:00 - 10:30\nDescription: Hands on introduction to generative art. Make your own pieces using {ggplot2} and {dplyr}\n\n\n\n\n\n\nSpatial noise tricks\n\n\n\n\n\n\n\n\n\n\n\nTime: 11:00 - 12:30\nDescription: Multidimensional noise generators. Flow fields, fractals, and more using the {ambient} package\n\n\n\n\n\n\nPolygon tricks\n\n\n\n\n\n\n\n\n\n\n\nTime: 13:30 - 15:00\nDescription: Learn how to create textures with recursive polygon deformation, draw wonky hearts as animated gifs, and convert boring lines to textured strokes\n\n\n\n\n\n\nShading tricks\n\n\n\n\n\n\n\n\n\n\n\nTime: 15:30 - 17:00\nDescription: Learn how to use {rayshader} to add depth to 2D plots, and generate 3D graphics from generative art"
  },
  {
    "objectID": "index.html#day-2-july-26",
    "href": "index.html#day-2-july-26",
    "title": "ART FROM CODE",
    "section": "Day 2: July 26",
    "text": "Day 2: July 26\n\n\nIterated function systems\n\n\n\n\n\n\n\n\n\n\n\nTime: 09:00 - 10:30\nDescription: Iterated function systems. Embrace the chaotic joy of the fractal flame and render quickly with {Rcpp}. This one is a bit technical\n\n\n\n\n\n\nTiles and tesselations\n\n\n\n\n\n\n\n\n\n\n\nTime: 11:00 - 12:30\nDescription: Make lovely things by subdividing a rectangle, explore Voronoi tesselations, and have a passing encounter with Truchet tiles\n\n\n\n\n\n\nPixel filters\n\n\n\n\n\n\n\n\n\n\n\nTime: 13:30 - 15:00\nDescription: Manipulate ggplot objects as if they were raster graphics using {ggfx}: learn to dither, mask, displace, blend, and more. The {flametree} package makes as special guest appearance in this one\n\n\n\n\n\n\n\nWrapping up\n\n\n\n\n\n\n\n\n\n\n\nTime: 15:30 - 17:00\nDescription: A comment on creativity in art and code"
  },
  {
    "objectID": "day-1/session-1/index.html",
    "href": "day-1/session-1/index.html",
    "title": "GENERATIVE ART WITH R",
    "section": "",
    "text": "Once upon a time I was a professor.\nIt’s a dull story, and I won’t bore you with the details, but I mention it because at the start of almost every class I taught I’d have to go being by explaining the terminology. Want to teach a class on human learning? You better start out by saying what you think “learning” means. Want to teach people about computational models of cognition? The students would like you to start by giving a working definition of “computation”, “model” and “cognition”. It doesn’t really matter if the definitions aren’t good definitions (spoiler: they’re always terrible), but it helps people to start out from something that looks vaguely like stable ground to stand on.\nSo. If this is going to be a workshop on generative art in R, I should say something about what I mean by “R”, “art”, and “generative”. Of the three terms, R is the easiest one to define: it’s a programming language used primarily for statistical computing and data science. To anyone starting this workshop I don’t really have to give a lot more detail than that. We all know (roughly speaking) what R is: we wouldn’t be participating at rstudio::conf if we didn’t! For the current purposes all I’ll say is that I’m talking about R the way it is typically used in 2022: R doesn’t just mean “base R”. It also includes “tidyverse”. It includes the sprawling ecosystem of packages on CRAN and GitHub. Often that includes code written in other languages: thanks to packages like Rcpp and cpp11 it’s not at all unusual for computationally intensive subroutines to be farmed out to C++ code, and not written in “pure” R. Supplying bindings to libraries written in other languages is a well-established tradition in R: in this workshop we shall not be purists. If we can do a thing by working with R code, then we’re doing something with R even if other languages are doing some of the work for us.\nOkay, so that’s “R”. What about “art” – what counts as “art”? In this essay I will…\n…just kidding. I do not have the arrogance to pretend that I know what art is. Art is pretty (except when it isn’t). Art is created (except when it is found). Art is intentional (except when it is accidental). Art makes you think (sometimes, not always). Art relies on artist skill (except when you send GPT-3 generated text to DALL-E). Art is uniquely human (no it isn’t). Art… yeah, look, I have no idea what art is. Personally, I like to make pretty things from code that appeal to my aesthetic sensibilities, and that’s good enough for me.\nWhich brings me to the third word: “generative”. When we talk about “generative art”, what do we mean? The term isn’t particularly well defined, but what we typically (not always) mean is that generative art is computational artwork that incorporates some source of noise, disorder, or randomness (natural or artificial) into the artistic process itself. It’s a kind of perverse artistry: almost always we’re working with computers, one of the most precise and flexible tools that humans have devised, and yet we are deliberately making the products of the machine unpredictable, unknowable even to the artist.\nWe are writing code that makes unpredictable paintings."
  },
  {
    "objectID": "day-1/session-1/index.html#art-is-theft",
    "href": "day-1/session-1/index.html#art-is-theft",
    "title": "GENERATIVE ART WITH R",
    "section": "Art is theft",
    "text": "Art is theft\nOkay that’s quite enough preamble. Let’s stop talking and start making some art! Following Picasso’s dictum that “art is theft” I want to begin with an act of wholesale thievery. I am going to co-opt tools that were created for serious data science purposes and repurpose them for art. If you’re in this room with me then you already know these tools by name: ggplot2 is an R package designed for data visualisation; dplyr is designed for data manipulation; tibble is designed for data representation. None of these packages were created for artists. They’re practical tools designed for statisticians, data scientists, analysts, and other knowledge workers.\nFuck it. Let’s steal them. Sorry Hadley.\n\nlibrary(ggplot2)\nlibrary(tibble)\n\nLet’s start with a data visualisation exercise that most R users have encountered at one time or another: creating a scatterplot. The ggplot2 package supplies the tediously-overused mpg data set that… I don’t know, it has something to do with cars, I think? I don’t drive and I am trying very hard to pretend I never learned anything about the internal combustion engine. The point here is that we have a data set. From the perspective of the generative artist our main concern is that it’s a table that contains some numbers and text organised in a table:\n\nmpg\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   <chr>        <chr>      <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# … with 224 more rows\n\n\nWe need not concern ourselves with why displ refers to engine displacement nor what that term even means. Nor do we have to care about how hwy represents highway mileage or how drv has something to do with gears. Really, this is not our concern. As generative artists we think of these as raw sources of structure and randomness.\nHere’s what I mean. As a data scientist, I might draw a plot like this:\n\nmpg |>\n  ggplot(aes(displ, hwy, colour = drv)) + \n  geom_point()\n\n\n\n\n\n\n\n\nOn the x-axis I’ve plotted one column in the table, on the y-axis I’ve plotted another column, and each row in the table shows up as a dot. A third row of the table is used to supply the colour. Because ggplot2 is designed to support interpretation, the resulting plot has a collection of guides, legends and other labels. In the world of data visualisation, these things are essential for helping the viewer understand how the picture relates to the thing in the world (cars, apparently) that the data pertains to.\nAs an artist, I cannot be bothered with such dull practicalities. Let’s get rid of all of them, and – violating all sorts of data visualisation best practices – I’m going to vary the size of the dots in a way that doesn’t help anyone make sense of the data:\n\nmpg |>\n  ggplot(aes(displ, hwy, colour = drv, size = cyl)) + \n  geom_point(show.legend = FALSE) + \n  theme_void() + \n  scale_color_brewer()\n\n\n\n\n\n\n\n\nOnce we strip away the practical purpose of the data visualisation, we’re left with something that isn’t quite so easy to interpret, but is… well, it’s kind of pretty, right? There’s an overall structure to the scatterplot. The colours, shapes, and positions of the data don’t necessarily tell an easily-understood story about the real world anymore but they’re quite pleasing to look at.\nViewing ggplot2 through this lens opens up a new world of possibilities. Inspired by Leland Wilkinson’s book on the subject, Hadley Wickham wrote the package to provide a grammar of graphics: it supplies a collection of transformation and composition rules that we can use to construct mappings between data (that represent a thing in the world) and images (that our visual systems can quickly interpret). Those rules are not arbitrary: they’re created to make our lives as data analysts easier. But we can repurpose them. The grammatical rules of human language did not evolve to serve the needs of poets, but the poets use them anyway. So too we as visual artists can (and will) reuse the grammar of graphics for artistic purposes. A few minor tweaks gives us this:\n\nmpg |>\n  ggplot(aes(displ, hwy, colour = drv)) + \n  geom_point(show.legend = FALSE, size = 4) + \n  geom_point(show.legend = FALSE, size = 1, colour = \"#222222\") + \n  coord_polar() + \n  theme_void() + \n  scale_color_brewer()\n\n\n\n\n\n\n\n\nAnd let’s be honest. At this point the image has very little to do with cars. Sure, I’m using the mpg data to drive the process, but as far as I’m concerned it’s really just a source of raw numbers. As a generative artist these numbers are my raw materials, but I’m not too fussed about exactly how I came into possession of these numbers.\n\n\n\n\n\n\nExercise\n\n\n\nTry it yourself! Using nothing other than ggplot2 and the mpg data set, create your own artwork. Don’t take too long: 3 minutes at the absolute most! See what you can come up with in that time!\n\n\nI could just have easily created my own raw materials. As a statistical programming language R comes equipped with a very sophisticated collection of tools for generating pseudorandom numbers with various distributions. I can tap into this whenever I like but in a lot of cases I don’t need anything more fancy than the runif() function. Uniformly distributed random numbers are perfectly adequate for many purposes. Let’s make some:\n\nset.seed(1)\nn <- 50\ndat <- tibble(\n  x0 = runif(n),\n  y0 = runif(n),\n  x1 = x0 + runif(n, min = -.2, max = .2),\n  y1 = y0 + runif(n, min = -.2, max = .2),\n  shade = runif(n), \n  size = runif(n)\n)\ndat\n\n# A tibble: 50 × 6\n       x0     y0    x1      y1 shade  size\n    <dbl>  <dbl> <dbl>   <dbl> <dbl> <dbl>\n 1 0.266  0.478  0.327  0.523  0.268 0.762\n 2 0.372  0.861  0.313  0.884  0.219 0.933\n 3 0.573  0.438  0.481  0.370  0.517 0.471\n 4 0.908  0.245  1.11   0.226  0.269 0.604\n 5 0.202  0.0707 0.255  0.0709 0.181 0.485\n 6 0.898  0.0995 0.784 -0.0282 0.519 0.109\n 7 0.945  0.316  0.796  0.328  0.563 0.248\n 8 0.661  0.519  0.652  0.349  0.129 0.499\n 9 0.629  0.662  0.799  0.573  0.256 0.373\n10 0.0618 0.407  0.101  0.292  0.718 0.935\n# … with 40 more rows\n\n\nYup. Those look like a bunch of numbers. They do not mean anything to me. They’re entirely deterministic – at least in the sense that the set.seed() command ensures that the pseudorandom number will always generate the same random numbers with this code – but the underlying generator is utterly without structure. As the outside observer I am entirely indifferent about whether I should use set.seed(1) or set.seed(234534). Both versions of this command will initialise the state of the random number generator in a way that ensures that runif() generates pure noise. Under the hood there are some fancy definitions of what we mean by “randomness” and “noise”, but this is not the place to talk about Martin-Löf randomness. For our purposes it is sufficient to agree that the output of a uniform random number generator is meaningless noise, no matter what seed value we supply.\nThe key point is this: the input is garbage. Garbage in…\n\ndat |> \n  ggplot(aes(\n    x = x0,\n    y = y0,\n    xend = x1,\n    yend = y1,\n    colour = shade,\n    size = size\n  )) +\n  geom_segment(show.legend = FALSE) +\n  coord_polar() +\n  scale_y_continuous(expand = c(0, 0)) +\n  scale_x_continuous(expand = c(0, 0)) + \n  scale_color_viridis_c() + \n  scale_size(range = c(0, 10)) + \n  theme_void()\n\n\n\n\n\n\n\n\n…art out?\nNot that anyone has ever asked my opinion on the topic, but this is what I think generative art really is. An automated process that takes garbage as input and creates unpredictably delightful outputs – sometimes with a little helpful human oversight and curation – is a generative art system. It is fundamentally a process of making something from nothing. Art from the void. Treasure from trash. Signal from noise. You get the idea."
  },
  {
    "objectID": "day-1/session-1/index.html#technique",
    "href": "day-1/session-1/index.html#technique",
    "title": "GENERATIVE ART WITH R",
    "section": "Technique",
    "text": "Technique\nAt this point we have some sense of what our creative endeavour is all about, which leads naturally to questions about technique. One thing I’ve learned – about art, yes, but I think it holds quite generally – is that you can’t teach “personal style”. Everyone has their own tastes and preferences, and it makes no sense whatsoever to tell someone else who, what, or how they should love. I have no business telling you what is pleasing and what isn’t. I’m not arrogant enough to try.\nWhat I can do, however, is talk about the tools and coding practices that have made it easier for me to create the things that I think have aesthetic value. When art schools talk about teaching “technique”, this is what I think they mean. The point isn’t to dictate what you create, but to give you skills that will let you make a reality from the thing you envision. Fundamentally, this is a workshop on technique, in this sense of the term.\nLet’s start with a core principle: code reuse. The entire point of generative art is that we’re turning trash into treasure, and trash is not a scarce resource. If you can write code to create one beautiful thing, the same code should be reusable to create many beautiful things. This “reuse principle” means that the substantive work of writing generative art code is almost always a matter of writing functions. Functions are beautiful…\n…but they are opinionated. A function exists if (and only if) you intend to reuse it. In the ideal case, a function is a thing that makes sense on its own terms and – as a consequence – you might reuse it in many different contexts. Every scientific programming language since the dawn of time has included functions like exp() and log() because scientists will always reuse these functions. Exponents and logarithms are scientifically-reusable concepts.\nSo what counts as an artistically-reusable concept? Well, at a minimum, the definition of an artistic system is a reusable concept. Suppose I want to create many art pieces that are “in the same style” as the piece I created above. To do that, I could wrap my code in a function that I’ll call polar_art():\n\npolar_art <- function(seed, n, palette) {\n  \n  # set the state of the random number generator\n  set.seed(seed)\n  \n  # data frame containing random values for \n  # aesthetics we might want to use in the art\n  dat <- tibble(\n    x0 = runif(n),\n    y0 = runif(n),\n    x1 = x0 + runif(n, min = -.2, max = .2),\n    y1 = y0 + runif(n, min = -.2, max = .2),\n    shade = runif(n), \n    size = runif(n)\n  )\n  \n  # plot segments in various colours, using \n  # polar coordinates and a gradient palette\n  dat |> \n    ggplot(aes(\n      x = x0,\n      y = y0,\n      xend = x1,\n      yend = y1,\n      colour = shade,\n      size = size\n    )) +\n    geom_segment(show.legend = FALSE) +\n    coord_polar() +\n    scale_y_continuous(expand = c(0, 0)) +\n    scale_x_continuous(expand = c(0, 0)) + \n    scale_colour_gradientn(colours = palette) + \n    scale_size(range = c(0, 10)) + \n    theme_void()\n}\n\n\n\n\nBecause I’ve written this thing down as a function, I’m now free to reuse it to create multiple pieces. Varying the seed argument creates new pieces that don’t differ in any systematic way from one another, whereas varying n and palette changes the number of segments plotted and the colour scheme used.\n\npolar_art(seed = 1, n = 500, palette = c(\"antiquewhite\", \"orange\", \"bisque\"))\npolar_art(seed = 1, n = 500, palette = c(\"red\", \"black\", \"white\"))\npolar_art(seed = 2, n = 50, palette = c(\"red\", \"black\", \"white\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nIn the materials folder there is a file called polar_art.R that contains a copy of the polar_art() function. Open it and use the polar_art() function to generate your own pieces. Try changing the seed, n, and the palette to create a variety of different pieces.\nCreate a new file called polar_art_02.R that contains the polar_art() function. In the new file, try modifying the polar_art() function itself to see if you can create your own new system.\nSomething to think about: Usually in data science we try to avoid naming our files my_file_version_1, my_file_version_2, etc, and instead we place files under version control using git. Yet here I am in an art context, apparently giving the advice to fall back on the old-fashioned system of naming files with version numbers. Why might I be doing that?"
  },
  {
    "objectID": "day-1/session-1/index.html#colour",
    "href": "day-1/session-1/index.html#colour",
    "title": "GENERATIVE ART WITH R",
    "section": "Colour",
    "text": "Colour\n\nlibrary(scales)\nlibrary(ggthemes)\n\nPicking a palette is always tricky, but can often be made simpler because R has so many packages that provides prespecified colour palettes. My usual approach is to use palettes defined by a few colours, and it’s easy to find sites online that make it easy to find colour combinations you like. One of my favourite sites is coolors.co, which you can browse for preselected palettes or use the tools to build your own. For example I might decide that this palette is the one I want to use. The site makes it easy to export the hex codes for each colour, so I can cut and paste to get this:\n\npal <- c(\"#cdb4db\", \"#ffc8dd\", \"#ffafcc\", \"#bde0fe\", \"#a2d2ff\")\n\nThe show_col() function from the scales package is a nice way to quickly preview the colours:\n\nshow_col(pal)\n\n\n\n\n\n\n\n\nThough there are only five colours in this palette, the polar_art() function uses scales_colour_gradientn() to construct a continuous colour scale from them by linearly interpolating between them. You can do the same thing manually using colorRampPalette(). In the code below I’ve created a new function palette_fn() that will generate a vector of colours that linearly interpolates between the five input colours in pal:\n\npalette_fn <- colorRampPalette(pal)\n\nIf I need 100 colours distributed along the spectrum defined by pal, all I need to do is this:\n\npalette_fn(100)\n\n  [1] \"#CDB4DB\" \"#CFB4DB\" \"#D1B5DB\" \"#D3B6DB\" \"#D5B7DB\" \"#D7B8DB\" \"#D9B8DB\"\n  [8] \"#DBB9DB\" \"#DDBADB\" \"#DFBBDB\" \"#E1BCDB\" \"#E3BCDB\" \"#E5BDDB\" \"#E7BEDC\"\n [15] \"#E9BFDC\" \"#EBC0DC\" \"#EDC0DC\" \"#EFC1DC\" \"#F1C2DC\" \"#F3C3DC\" \"#F5C4DC\"\n [22] \"#F7C4DC\" \"#F9C5DC\" \"#FBC6DC\" \"#FDC7DC\" \"#FFC7DC\" \"#FFC6DC\" \"#FFC5DB\"\n [29] \"#FFC4DA\" \"#FFC3DA\" \"#FFC2D9\" \"#FFC1D8\" \"#FFC0D8\" \"#FFBFD7\" \"#FFBED6\"\n [36] \"#FFBDD5\" \"#FFBCD5\" \"#FFBBD4\" \"#FFBAD3\" \"#FFB9D3\" \"#FFB8D2\" \"#FFB7D1\"\n [43] \"#FFB6D1\" \"#FFB5D0\" \"#FFB4CF\" \"#FFB3CF\" \"#FFB2CE\" \"#FFB1CD\" \"#FFB0CD\"\n [50] \"#FFAFCC\" \"#FDAFCD\" \"#FBB1CF\" \"#F8B3D1\" \"#F5B5D3\" \"#F3B7D5\" \"#F0B9D7\"\n [57] \"#EDBBD9\" \"#EBBDDB\" \"#E8BFDD\" \"#E5C1DF\" \"#E3C3E1\" \"#E0C5E3\" \"#DDC7E5\"\n [64] \"#DBC9E7\" \"#D8CBE9\" \"#D5CDEB\" \"#D3CFED\" \"#D0D1EF\" \"#CDD3F1\" \"#CBD5F3\"\n [71] \"#C8D7F5\" \"#C5D9F7\" \"#C3DBF9\" \"#C0DDFB\" \"#BDDFFD\" \"#BCDFFE\" \"#BBDFFE\"\n [78] \"#BADEFE\" \"#B8DDFE\" \"#B7DDFE\" \"#B6DCFE\" \"#B5DCFE\" \"#B4DBFE\" \"#B3DBFE\"\n [85] \"#B2DAFE\" \"#B1D9FE\" \"#B0D9FE\" \"#AFD8FE\" \"#AED8FE\" \"#ACD7FE\" \"#ABD7FE\"\n [92] \"#AAD6FE\" \"#A9D5FE\" \"#A8D5FE\" \"#A7D4FE\" \"#A6D4FE\" \"#A5D3FE\" \"#A4D3FE\"\n [99] \"#A3D2FE\" \"#A2D2FF\"\n\n\nHere’s what those colours look like as a smooth palette:\n\nimage(\n  x = matrix(1:100, ncol = 1), \n  col = palette_fn(100),\n  useRaster = TRUE,\n  axes = FALSE\n)\n\n\n\n\n\n\n\n\nIn this example, I took one set of colours from the web to define a palette, but there are many built-in palettes you can select from randomly as part of your generative process. For example, the ggthemes package contains a list called canva_palettes, which contains 150 palettes taken from canva.com. For example, here’s one of those palettes\n\ncanva_palettes[[101]]\n\n[1] \"#4abdac\" \"#fc4a1a\" \"#f7b733\" \"#dfdce3\"\n\nshow_col(canva_palettes[[101]])\n\n\n\n\n\n\n\n\nThe fact that we have a list containing 150 different palettes, it’s a simple matter to write a sample_canva() function that samples one of these palettes at random:\n\nsample_canva <- function(seed = NULL) {\n  if(!is.null(seed)) set.seed(seed)\n  sample(ggthemes::canva_palettes, 1)[[1]]\n}\n\nHere’s an example of me using it:\n\npolar_art(seed = 2, n = 100, palette = sample_canva(seed = 2))\npolar_art(seed = 2, n = 100, palette = sample_canva(seed = 3))\npolar_art(seed = 2, n = 100, palette = sample_canva(seed = 4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice that I’ve set it up in a way that allows me some degree of control over which elements of the image are allowed to vary. In all three images I used the same seed when calling polar_art(), so the random configuration of shapes is identical in all three cases. In contrast, I gave different seeds to the sample_canva() function, so the images have different palettes. The reverse is also possible, producing different configurations with the same colour scheme:\n\npolar_art(seed = 5, n = 100, palette = sample_canva(seed = 1))\npolar_art(seed = 6, n = 100, palette = sample_canva(seed = 1))\npolar_art(seed = 7, n = 100, palette = sample_canva(seed = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe ability to pick and choose when the randomness gets turned on and off is quite handy!\n\n\n\n\n\n\nExercises\n\n\n\n\nIn the materials folder there is a file called palette-generators.R that contains a copy of the sample_canva() function. Take a look and try calling the function a few times to see what kind of output it produces. You may find it handy to use show_col() to visualise the results.\nTry writing your own random palette generator. A simple (and occasionally useful) approach is to construct a palette consisting of distinct but otherwise randomly selected named colours in R. There is a set of 502 colour names generated by calling colours() with distinct = TRUE). Write a function called sample_named_colours() that takes n as an input argument, and then returns a sample of n of these colour. Try using it with the polar_art() function.\nThe sample_canva() function, as I’ve written it, preserves the original structure of the 150 palettes in ggthemes::canva_palettes, so that the 4 colours returned all belong to the same palette on the Canva website originally. Try breaking this constraint. If you call unlist(ggthemes::canva_palettes) you get a vector of 600 distinct colours. Write a palette generating function that samples colours randomly from that set of 600 colours."
  },
  {
    "objectID": "day-1/session-1/index.html#composition",
    "href": "day-1/session-1/index.html#composition",
    "title": "GENERATIVE ART WITH R",
    "section": "Composition",
    "text": "Composition\nThe polar_art() function I wrote earlier is nice, but it’s not very flexible. It allows some control over the palette and the number of segments to be plotted, but that’s all. It doesn’t let me use the full flexibility of ggplot2 to create artwork. For example, what if I wanted to create more pieces in a “similar” style to the ones I created earlier, but plot different geoms? Or perhaps I want to plot more than one data set as part of a single piece? The polar_art() function doesn’t allow that. The data generation and plot building is all handled internally. Perhaps there’s a case to be made that we should break this into smaller functions and see if that helps.\nLet’s start out by writing a “random tibble generator” function, sample_data(). This function will generate tibbles full of random numbers, but that’s all:\n\nsample_data <- function(seed = NULL, n = 100){\n  if(!is.null(seed)) set.seed(seed)\n  dat <- tibble(\n    x0 = runif(n),\n    y0 = runif(n),\n    x1 = x0 + runif(n, min = -.2, max = .2),\n    y1 = y0 + runif(n, min = -.2, max = .2),\n    shade = runif(n), \n    size = runif(n),\n    shape = factor(sample(0:22, size = n, replace = TRUE))\n  )\n}\n\nNext, let’s create a styled_plot() function that takes a palette and (optionally) a data set as inputs, and sets up the mappings and the stylistic aspects to the plot. This function does a lot of the work in defining what kind of artwork is possible using this system, even though it doesn’t actually draw anything. For example, it specifies coord_polar() as the coordinate system, so any points or lines that get created will be shown in polar coordinates. It uses guide_none() to suppress legends, and theme_void() to suppress axes, axis titles and so on.\n\npolar_styled_plot <- function(data = NULL, palette) {\n  ggplot(\n    data = data,\n    mapping = aes(\n      x = x0,\n      y = y0,\n      xend = x1,\n      yend = y1,\n      colour = shade,\n      size = size\n    )) + \n    coord_polar(clip = \"off\") +\n    scale_y_continuous(\n      expand = c(0, 0),\n      limits = c(0, 1), \n      oob = scales::oob_keep\n    ) +\n    scale_x_continuous(\n      expand = c(0, 0), \n      limits = c(0, 1), \n      oob = scales::oob_keep\n    ) + \n    scale_colour_gradientn(colours = palette) + \n    scale_size(range = c(0, 10)) + \n    theme_void() + \n    guides(\n      colour = guide_none(),\n      size = guide_none(),\n      fill = guide_none(),\n      shape = guide_none()\n    )\n}\n\nThis structure gives a clean delineation of responsibility among the different functions. The sample_canva() function does the work of generating random palettes, sample_data() does the job of creating random data to drive the plot, polar_styled_plot() takes care of all the ggplot set up, and then you can pick and choose which geom you want to add. So we can write code like this that differs only in the choice of geom:\n\ndat <- sample_data(n = 100, seed = 1) \npal <- sample_canva(seed = 1)\n\npolar_styled_plot(data = dat, palette = pal) + geom_segment()\npolar_styled_plot(data = dat, palette = pal) + geom_path()\npolar_styled_plot(data = dat, palette = pal) + geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBecause the output of polar_styled_plot() is a ggplot that we can add layers to, and because each layer in a ggplot can supply its own data, we now have the ability to reuse these components in different ways. For that it’s helpful to load dplyr. Here’s an example where we generate two random data sets and feed those into four separate geoms:\n\nlibrary(dplyr)\n\ndat1 <- sample_data(n = 2000, seed = 123) \ndat2 <- sample_data(n = 100, seed = 456) |>  \n  mutate(y0 = .3 + y0 * .6, y1 = .3)\n\npolar_styled_plot(palette = sample_canva(seed = 7)) + \n  geom_segment(\n    data = dat1 |> mutate(size = size * 3)\n  ) + \n  geom_segment(\n    data = dat2 |> mutate(size = size / 5), \n    lineend = \"round\", \n    colour = \"white\"\n  ) +\n  geom_segment(\n    data = dat2 |> mutate(size = size / 40), \n    lineend = \"round\", \n    colour = \"#222222\"\n  ) +\n  geom_point(\n    data = dat2 |> mutate(size = size * 2),\n    colour = \"#222222\"\n  )\n\n\n\n\n\n\n\n\nAnother example that three copies of the same random data set to produce a variation that has additional symmetries:\n\ndat <- sample_data(n = 2000, seed = 123) |>\n  mutate(y1 = y0, size = size / 2)\n\npolar_styled_plot(palette = sample_canva(seed = 456)) + \n  geom_segment(data = dat) + \n  geom_segment(data = dat |> mutate(y1 = y1 - .2, y0 = y0 - .2)) +\n  geom_segment(data = dat |> mutate(y1 = y1 - .4, y0 = y0 - .4))\n\n\n\n\n\n\n\n\nFinally, here’s a version that uses the linetype argument to geom_segment() to create a “choppier” version of these pieces:\n\ndat <- sample_data(n = 1000, seed = 1) |>\n  mutate(y1 = y0, size = size / 4)\n\npolar_styled_plot(palette = sample_canva(seed = 2)) + \n  geom_segment(data = dat, linetype = \"331311\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nIn the materials folder there is a file called polar-styled-plots.R that contains a copy of the sample_canva(), sample_data() and polar_styled_plot() functions. Without modifying any of these three functions, explore how much flexibility you have to make different pieces in which (1) data are generated with sample_data(), (2) the plot is initialised by calling polar_styled_plot(), and (3) the piece is created by adding ggplot2 geoms. Data manipulation with dplyr is allowed!\nIn the examples above and the previous exercise you saw that the polar_styled_plot() function plays the role of defining an overarching “style” for possible art pieces, but it doesn’t completely constrain artistic freedom. Your task in this exercise is to try to write a my_styled_plot() that does something similar… but creates a different style that you can explore"
  },
  {
    "objectID": "day-1/session-2/index.html",
    "href": "day-1/session-2/index.html",
    "title": "SPATIAL TRICKS WITH AMBIENT",
    "section": "",
    "text": "library(dplyr)\nlibrary(purrr)\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(ambient)"
  },
  {
    "objectID": "day-1/session-2/index.html#sampling-spatial-patterns",
    "href": "day-1/session-2/index.html#sampling-spatial-patterns",
    "title": "SPATIAL TRICKS WITH AMBIENT",
    "section": "Sampling spatial patterns",
    "text": "Sampling spatial patterns\nGenerative art relies on having access to a source of randomness, and using that randomness to construct patterned objects. In the last session I wrote a simple function to generate random palettes, for instance:\n\nsample_canva <- function(seed = NULL) {\n  if(!is.null(seed)) set.seed(seed)\n  sample(ggthemes::canva_palettes, 1)[[1]]\n}\n\nEvery time I call this function (assuming I don’t set the seed argument), R uses the pseudorandom number generator to select a palette of four colours:\n\nsample_canva()\nsample_canva()\nsample_canva()\n\n[1] \"#fcc875\" \"#baa896\" \"#e6ccb5\" \"#e38b75\"\n[1] \"#99d3df\" \"#88bbd6\" \"#cdcdcd\" \"#e9e9e9\"\n[1] \"#265c00\" \"#68a225\" \"#b3de81\" \"#fdffff\"\n\n\nEach of these colours is itself an object defined in a three dimensional space (the hex codes refer to co-ordinates in RGB space), and when I sample a palette of four colours what I’m really doing is constructing a random object with 12 components.\nWe can take this idea further. The sample_data() function I wrote in the last session creates random tibbles according to some simple rules, and those tibbles are structured objects too. Admittedly the structure to those objects isn’t very complicated, because there’s no pattern to numbers in the generated table, but there’s nothing stopping us from writing a function that randomly generates tabular data structures that have patterns in them, right? For instance, I could do this:\n\nsample_cross_matrix <- function(n = 10, seed = NULL) {\n  if(!is.null(seed)) set.seed(seed)\n  mat <- matrix(data = 0, nrow = n, ncol = n)\n  mat[sample(n, 1), ] <- 1\n  mat[, sample(n, 1)] <- 1\n  return(mat)\n}\n\nsample_cross_matrix()\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n [1,]    0    0    1    0    0    0    0    0    0     0\n [2,]    1    1    1    1    1    1    1    1    1     1\n [3,]    0    0    1    0    0    0    0    0    0     0\n [4,]    0    0    1    0    0    0    0    0    0     0\n [5,]    0    0    1    0    0    0    0    0    0     0\n [6,]    0    0    1    0    0    0    0    0    0     0\n [7,]    0    0    1    0    0    0    0    0    0     0\n [8,]    0    0    1    0    0    0    0    0    0     0\n [9,]    0    0    1    0    0    0    0    0    0     0\n[10,]    0    0    1    0    0    0    0    0    0     0\n\n\nAgain, this isn’t the most complicated example, but it’s an illustration of the idea that we can write functions to sample random spatial patterns:\n\nimage(sample_cross_matrix(n = 50), axes = FALSE, useRaster = TRUE)\nimage(sample_cross_matrix(n = 50), axes = FALSE, useRaster = TRUE)\nimage(sample_cross_matrix(n = 50), axes = FALSE, useRaster = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI’ll concede that a generative art system that draws a cross at a random location in the image isn’t the most exciting or innovative thing I’ve ever written, but the core idea is clear I hope. And you would probably be unsurprised to learn that there are a number of more sophisticated tools you can use to generate random spatial patterns.\nIn this session I’ll introduce the ambient package, developed by Thomas Lin Pedersen, which supplies R bindings to a C++ library called FastNoise."
  },
  {
    "objectID": "day-1/session-2/index.html#our-first-ambient-artwork",
    "href": "day-1/session-2/index.html#our-first-ambient-artwork",
    "title": "SPATIAL TRICKS WITH AMBIENT",
    "section": "Our first ambient artwork",
    "text": "Our first ambient artwork\nThe first step in creating art using the ambient package is to define the “canvas”, a spatial grid of x and y co-ordinates in which values will be stored. I find it helpful to imagine my canvas as the unit square: the smallest value is 0 and the largest value is 1. If I want an 800x800 grid, I use the seq() function to define a length-800 sequence of evenly-spaced numbers starting at 0 and ending at 1:\n\nx_coords <- seq(from = 0, to = 1, length.out = 800)\ny_coords <- seq(from = 0, to = 1, length.out = 800)\n\nThe canvas that I’ll paint on will be a data frame consisting of all possible combinations of x_coords and y_coords. In base R we can create an object like this using the expand.grid() function, and there’s a tidy equivalent called expand_grid() in the tidyr package. However, when working with the ambient package I prefer to use the long_grid() function that it supplies:\n\ncanvas <- long_grid(x = x_coords, y = y_coords) \ncanvas\n\n# A tibble: 640,000 × 2\n       x       y\n   <dbl>   <dbl>\n 1     0 0      \n 2     0 0.00125\n 3     0 0.00250\n 4     0 0.00375\n 5     0 0.00501\n 6     0 0.00626\n 7     0 0.00751\n 8     0 0.00876\n 9     0 0.0100 \n10     0 0.0113 \n# … with 639,990 more rows\n\n\nThe reason I use long_grid() rather than one of the more familiar versions is that under the hood Thomas has supplied some optimisations that make these objects more efficient for generative art purposes. Among other things, you can easily convert them to arrays, matrices, and raster objects that respect the implied spatial grid, which makes it a lot easier to render images from these objects. But let’s not dive too deep into the details right now!\nNow that we have a “canvas” we’ll want to add some “paint”, and to apply that paint we’ll need to select a “brush”. In this context, the brush is a spatial pattern generator of some kind. The ambient package includes many such generator functions. Some generate very regular patterns:\n\ngen_waves() generates smooth concentric wave-like patterns\ngen_spheres() generates concentric circles\ngen_checkerboard() generates grids of squares in a checkerboard pattern\n\nOthers generate very irregular patterns:\n\ngen_white() generates white noise: equal intensity at every spatial frequency\n\nThe most interesting generators tend to be those that create patterns that have some structure but are still quite unpredictable:\n\ngen_perlin() and gen_simplex() generate random “wavy” patterns\ngen_worley() generates random “cellular” patterns\n\nWe’ll see some examples of those later! For now let’s use gen_perlin() as our brush! Like all the pattern generators, the gen_perlin() function takes coordinate values as input. At a minimum it expects an x co-ordinate, but you can also supply y and z values if you like. You can also specify the frequency parameter, which sets the scale for the output: high frequency patterns will vary quickly as the co-ordinates change, low-frequency patterns will vary slowly. Compare these outputs for instance:\n\ngen_perlin(x = 1:5, y = 1, frequency = .001, seed = 1)\ngen_perlin(x = 1:5, y = 1, frequency = .5, seed = 1)\n\n[1] -0.001000010 -0.001000010 -0.001000009 -0.001000009 -0.001000007\n[1] -0.375  0.000  0.000 -0.250  0.000\n\n\nBoth versions show variability, but the scale is quite different! As an aside, notice that gen_perlin() also allows you to specify the seed used to generate the pattern, similar to the way I did earlier when writing sample_canva() to generate random palettes.\nNow that we have a sense for what the gen_perlin() function does let’s use it to add a new column to our canvas. I have dplyr loaded so I’ll use mutate() to do this:\n\ncanvas <- canvas |> \n  mutate(paint = gen_perlin(x, y, frequency = 10, seed = 1234))\ncanvas\n\n# A tibble: 640,000 × 3\n       x       y  paint\n   <dbl>   <dbl>  <dbl>\n 1     0 0       0     \n 2     0 0.00125 0.0125\n 3     0 0.00250 0.0249\n 4     0 0.00375 0.0370\n 5     0 0.00501 0.0489\n 6     0 0.00626 0.0604\n 7     0 0.00751 0.0713\n 8     0 0.00876 0.0817\n 9     0 0.0100  0.0915\n10     0 0.0113  0.101 \n# … with 639,990 more rows\n\n\nNow that I have this column, I can use it to control the fill aesthetic in a ggplot. The co-ordinate values x and y specify a two dimensional grid, which means I can use geom_raster() here to create my artwork:\n\nart <- ggplot(canvas, aes(x, y, fill = paint)) + \n  geom_raster(show.legend = FALSE) \n\nTo see what our Perlin art looks like, I’ll build the plot in three different ways. First poorly with no customisation of the ggplot theme and scales, then a little nicer by removing unneeded details, then finally with a little flair:\n\nart\nart + \n  theme_void() +\n  coord_equal()\nart + \n  theme_void() +\n  coord_equal() +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  scale_fill_gradientn(colours = sample_canva())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNot bad. A little blurry looking, but it’s a nice place to start!\n\n\n\n\n\n\nExercise\n\n\n\nTry it yourself! In the materials folder there is a file called first-ambient-art.R that reproduces the code above. Try playing around with it to see what kind of output you can create by changing the values fed to gen_perlin(), or by trying other generator functions!"
  },
  {
    "objectID": "day-1/session-2/index.html#our-first-system",
    "href": "day-1/session-2/index.html#our-first-system",
    "title": "SPATIAL TRICKS WITH AMBIENT",
    "section": "Our first system",
    "text": "Our first system\nThe next step in the process is to start thinking about what aspects to the art should be variable, what aspects should be fixed, and use those insights to formalise this as a function. Some things that won’t change:\n\nThe art will always be a square grid rendered with geom_raster()\nThe spatial pattern will always come from one of the ambient::gen_*() functions\nWe’ll always remove extraneous elements from the art using theme_void() etc\n\nThese aspects to the art will be codified in the function body. There are some things that we might like to vary, however, and those will become arguments to the function:\n\nThe colour palette could vary from piece to piece\nThe underlying generator might be different in each piece\nThe spatial frequency could be different in each piece\nThe number of pixels in the grid could vary\nThe random number generator seed could vary\n\n\nmake_noise_art <- function(\n    generator = gen_perlin, \n    frequency = 10, \n    seed = 1234,\n    pixels = 2000,\n    palette = c(\"#e5ddc8\", \"#01949a\", \"#004369\", \"#db1f48\"), \n    ...\n) {\n  \n  # define the grid\n  canvas <- long_grid(\n    x = seq(from = 0, to = 1, length.out = pixels),\n    y = seq(from = 0, to = 1, length.out = pixels)\n  ) \n  \n  # use the generator to add paint\n  canvas <- canvas |>\n    mutate(\n      paint = generator(\n        x, y, \n        frequency = frequency, \n        seed = seed, \n        ...\n      )\n    )\n  \n  # use ggplot2 to draw the picture\n  art <- canvas |> \n    ggplot(aes(x, y, fill = paint)) + \n    geom_raster(show.legend = FALSE) +\n    theme_void() +\n    coord_equal() +\n    scale_x_continuous(expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0)) +\n    scale_fill_gradientn(colours = palette)\n  \n  return(art)\n}\n\nLet’s take a lot the effect of each of these arguments. Varying seed changes the spatial pattern depicted in each piece, but it doesn’t change it in any systematic way:\n\nmake_noise_art(seed = 1234)\nmake_noise_art(seed = 1001)\nmake_noise_art(seed = 9999)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn contrast, when I change the frequency argument I get systematic variation. The granularity of the spatial pattern changes in predictable ways as the frequency changes:\n\nmake_noise_art(frequency = 10)\nmake_noise_art(frequency = 20)\nmake_noise_art(frequency = 90)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere’s what happens when I vary palette. In the first example I’ve created a greyscale image by specifying a palette that runs from \"white\" to \"black\". The other two use palettes output by sample_canva():\n\nmake_noise_art(palette = c(\"white\", \"black\"))\nmake_noise_art(palette = sample_canva(seed = 123))\nmake_noise_art(palette = sample_canva(seed = 456))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinally, we can vary the generator function. It probably will come as no surprise to discover that varying the generator has some wild effects. The output of a checkerboard pattern generator is fundamentally different to the output of a Worley noise generator, which in turn is very distinct from Perlin noise. As you become more familiar with using ambient you’ll start getting a sense of what each of these generators produce, and develop your own preferences for how to use them. For now, it’s enough to note that because the gen_*() functions all adopt (roughly) the same API, our make_noise_art() function works perfectly well when we swap out one for another:\n\nmake_noise_art(generator = gen_perlin)\nmake_noise_art(generator = gen_worley)\nmake_noise_art(generator = gen_waves) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nIn the materials folder there is a file called make-noise-art.R that includes the make_noise_art() function. Unlike the code I’ve shown here, the version in the script writes the output to a file (located at output/noise-art.png). Try playing around with the inputs to make_noise_art() to see what outputs you can create.\nAt the moment, the script is set up so that the output is always written to the same file, output/noise-art.png. When you create your own generative art systems you will want to ensure that each unique output is written to a file with a unique filename, and that this filename should (ideally!) allow you to work out what inputs were used to create the piece. How would you write code to do this?"
  },
  {
    "objectID": "day-1/session-2/index.html#why-dplyr-is-a-girls-best-friend",
    "href": "day-1/session-2/index.html#why-dplyr-is-a-girls-best-friend",
    "title": "SPATIAL TRICKS WITH AMBIENT",
    "section": "Why dplyr is a girls best friend",
    "text": "Why dplyr is a girls best friend\nAs you can see from the output we’ve created so far, spatial noise patterns can be quite pretty even without any special artistic intervention. Our make_noise_art() function isn’t complicated: it takes the output from a generator function like gen_perlin() and plots it as a raster object. It doesn’t manipulate or modify that output in any way. However, there’s nothing preventing us from doing precisely that if that’s what we want to do. To simplify the later code, let’s create a blank_canvas object that we can reuse as the starting point for our later pieces:\n\nblank_canvas <- long_grid(\n  x = seq(from = 0, to = 1, length.out = 2000),\n  y = seq(from = 0, to = 1, length.out = 2000)\n) \n\nNow, let’s imagine that we’ve used some ambient magic to add a column called paint to our canvas. Here’s a plotting function that we can use that plots this as a raster object, just like we’ve been doing in the previous pieces (it optionally takes a palette too):\n\nplot_painted_canvas <- function(canvas, palette = NULL) {\n  if(is.null(palette)) {\n    palette <- c(\"#e5ddc8\",\"#01949a\",\"#004369\",\"#db1f48\")\n  }\n  canvas |> \n    ggplot(aes(x, y, fill = paint)) + \n    geom_raster(show.legend = FALSE) +\n    theme_void() +\n    coord_equal() +\n    scale_x_continuous(expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0)) +\n    scale_fill_gradientn(colours = palette)\n}\n\nNow that we have these in place, we can recreate one of our earlier pieces by wrting it as a dplyr pipeline:\n\nblank_canvas |>\n  mutate(paint = gen_perlin(x, y, frequency = 90, seed = 1234)) |>\n  plot_painted_canvas()\n\n\n\n\n\n\n\n\nHowever, the mere fact that we can rewrite our art code like this opens up the possibility of using the dplyr data manipulation grammar in a more sophisticated way. Here’s an example that creates three different spatial patterns and then adds them together:\n\nblank_canvas |> \n  mutate(\n    lf_noise = gen_simplex(x, y, frequency = 1, seed = 1234),\n    mf_noise = gen_simplex(x, y, frequency = 20, seed = 1234),\n    hf_noise = gen_simplex(x, y, frequency = 99, seed = 1234),\n    paint = lf_noise + mf_noise + hf_noise\n  ) |>\n  plot_painted_canvas()\n\n\n\n\n\n\n\n\nRecall that our plot_painted_canvas() function uses the x and y columns to define the grid, and the paint column to define the to-be-plotted values. The lf_noise, mf_noise, and hf_noise columns are ignored. They’re intermediate steps, components that get mixed together when we define the paint column!\nIn the previous example I created the paint column by adding three columns together, but there is nothing preventing me from defining more elaborate mixing rules. In the example below, for example, I’ve generated a fourth spatially-varying pattern and used as a “gating” mechanism. So now what we have is a situation where the lf_noise, mf_noise, and hf_noise patterns are mixed together in a spatially inhomogeneous way that depends on the value of the gate column:\n\nblank_canvas |> \n  mutate(\n    lf_noise = gen_simplex(x, y, frequency = 1),\n    mf_noise = gen_simplex(x, y, frequency = 20),\n    hf_noise = gen_simplex(x, y, frequency = 99),\n    gate = gen_spheres(x, y, frequency = 10) |> normalise(),\n    paint = lf_noise +\n      (1 + mf_noise) * (gate >= .1 & gate < .6) +\n      (1 + hf_noise) * (gate >= .05)\n  ) |>\n  plot_painted_canvas(palette = sample_canva(seed = 2))\n\n\n\n\n\n\n\n\nThe normalise() function in this code is supplied by the ambient package and in this context all I’m doing with it is ensuring that the output of the gen_spheres() generator is rescaled to lie between 0 and 1.\nThe same basic idea can be used to produce some quite striking pieces when we apply a fancier generator to construct the spatial gate pattern:\n\nblank_canvas |> \n  mutate(\n    lf_noise = gen_simplex(x, y, frequency = 1),\n    mf_noise = gen_simplex(x, y, frequency = 20),\n    hf_noise = gen_simplex(x, y, frequency = 99),\n    gate = gen_simplex(x, y, frequency = 10) |> normalise(),\n    paint = lf_noise +\n      (2 + mf_noise) * (gate >= .2 & gate < .8) +\n      (2 + hf_noise) * (gate >= .1)\n  ) |>\n  plot_painted_canvas(palette = sample_canva(seed = 3))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nTry it yourself! In the materials folder there is a script called dplyr-ambient.R that defines blank_canvas and plot_painted_canvas() for you. At the bottom of the file there is space for you to add to the blank canvas. Try using dplyr and ambient together to create a spatial noise pattern of your own."
  },
  {
    "objectID": "day-1/session-2/index.html#fractals",
    "href": "day-1/session-2/index.html#fractals",
    "title": "SPATIAL TRICKS WITH AMBIENT",
    "section": "Fractals",
    "text": "Fractals\nYou can also use the ambient package to create fractal patterns. The function that controls this is called fracture() and it’s easiest to demonstrate if we start with something simple. Suppose we have a “generator” function gen_sin() that generates sinusoidal patterns with a particular frequency. The code for this function is very simple:\n\ngen_sin <- function(x, frequency, ...) {\n  sin(x * frequency)\n}\n\nTo create a fractal pattern based on this generator, we repeatedly apply this function to the input at different values of frequency. The outputs of repeated applications are combined together using a rule prescribed by a fractal function. This combination function doesn’t have to be very complicated: it might just be a linear combination! As an example, one of the fractal functions provided by ambient is fbm(), which stands for “fractional Brownian motion”. When this is used as the combination rule, the results are added together with increasing frequencies and decreasing strength. The code for fbm() is this:\n\nfbm <- function(base, new, strength, ...) {\n  base + new * strength\n}\n\nA base pattern is added to a new pattern, weighted by some strength. That’s all it does!\nIf we wanted to create a fractal based on the gen_sin() generator, using fbm() as our fractal function, this is the code we would use:\n\nfracture(\n  x = 1:20, \n  noise = gen_sin, \n  fractal = fbm, \n  octaves = 8\n)\n\n [1]  1.24983550  0.80892271 -0.26356816 -0.20012820 -0.97755603 -0.80161946\n [7]  1.08394804  1.11211005 -0.24443826 -0.04492181 -0.97817310 -1.04255993\n[13]  1.07719639  0.86143412  0.21216704  0.24305786 -0.95445686 -1.32043009\n[19]  0.56698796  1.00122663\n\n\nIn this code, octaves = 8 specifies the number of times to apply the generator and fractal function. In essence it is the number of iterations over which we run the algorithm. It’s easiest to see what this looks like if we gradually increase the number of iterations and plot the results:\n\ndat <- tibble(\n  x = seq(0, 10, length.out = 1000), \n  y1 = fracture(x = x, noise = gen_sin, fractal = fbm, octaves = 1),\n  y2 = fracture(x = x, noise = gen_sin, fractal = fbm, octaves = 2),\n  y8 = fracture(x = x, noise = gen_sin, fractal = fbm, octaves = 8),\n  y20 = fracture(x = x, noise = gen_sin, fractal = fbm, octaves = 20)\n) \n\nggplot(dat) + geom_path(aes(x, y1)) + ggtitle(\"One iteration\")\nggplot(dat) + geom_path(aes(x, y2)) + ggtitle(\"Two iterations\")\nggplot(dat) + geom_path(aes(x, y8)) + ggtitle(\"Eight iterations\")\nggplot(dat) + geom_path(aes(x, y20)) + ggtitle(\"Twenty iterations\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs the number of octaves increases the plots become more and more detailed. In this case we can’t visually discriminate between 8 and 20 octaves because the differences are too fine-grained to be visible. That’s quite typical because – unless you modify the gain and frequency functions used by fracture() – each successive iteration (or octave) will be calculated at double the frequency of the previous one (leading to finer-grained changes) and with half the strength (less weight is given to later octaves). You can modify this if you want to. For example:\n\ncustom_fracture <- function(x, ...) {\n  fracture(\n    gain = function(strength) {strength * .8},\n    frequency = function(frequency) {frequency * 1.3},\n    noise = gen_sin, \n    fractal = fbm,\n    x = x,\n    ...\n  )\n}\n\ndat <- tibble(\n  x = seq(0, 10, length.out = 1000), \n  y1 = custom_fracture(x, octaves = 1),\n  y2 = custom_fracture(x, octaves = 2),\n  y8 = custom_fracture(x, octaves = 8),\n  y20 = custom_fracture(x, octaves = 20)\n) \n\nggplot(dat) + geom_path(aes(x, y1)) + ggtitle(\"One iteration\")\nggplot(dat) + geom_path(aes(x, y2)) + ggtitle(\"Two iterations\")\nggplot(dat) + geom_path(aes(x, y8)) + ggtitle(\"Eight iterations\")\nggplot(dat) + geom_path(aes(x, y20)) + ggtitle(\"Twenty iterations\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHopefully you get the basic idea.\nIn any case, let’s take this same concept and start using it in conjunction with the spatial noise generators supplied by ambient. To keep things simple and avoid the need to write plotting code over and over, let’s define a fractal_art() function like this:\n\nfractal_art <- function(fractal, generator, palette = NULL, ...) {\n  blank_canvas |>\n    mutate(\n      paint = fracture(\n        noise = generator,\n        fractal = fractal,\n        x = x, \n        y = y, \n        ...\n      )\n    ) |>\n    plot_painted_canvas(palette = palette)\n}\n\nHere’s what happens when we use gen_checkerboard() as our spatial pattern generator, and fbm() as our fractal function:\n\nfractal_art(fbm, gen_checkerboard, seed = 1, octaves = 1)\nfractal_art(fbm, gen_checkerboard, seed = 1, octaves = 2)\nfractal_art(fbm, gen_checkerboard, seed = 1, octaves = 20)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt has the same “feel” as the sinusoidal fractals we were working with earlier: as we increase the number of octaves the output contains more copies of the “checker board” pattern, each one depicted on a smaller scale than the last one. The same idea applies to the gen_waves() generator:\n\nfractal_art(fbm, gen_waves, seed = 1, octaves = 1)\nfractal_art(fbm, gen_waves, seed = 1, octaves = 2)\nfractal_art(fbm, gen_waves, seed = 1, octaves = 20)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBy the time we reach 20 octaves, the image has a quite intricate pattern of concentric rings. It’s quite pretty, but gen_checkerboard() and gen_waves() are both very simple generator functions. What happens when our generator is a more elaborate multidimensional noise generator like gen_simplex()? Simplex noise looks like this before we apply any fractal function to it:\n\nblank_canvas |>\n  mutate(paint = gen_simplex(x, y, seed = 2)) |>\n  plot_painted_canvas()\n\n\n\n\n\n\n\n\nHere’s what happens when we combine gen_simplex() with the fbm() fractal function:\n\nfractal_art(fbm, gen_simplex, seed = 2, octaves = 1)\nfractal_art(fbm, gen_simplex, seed = 2, octaves = 2)\nfractal_art(fbm, gen_simplex, seed = 2, octaves = 20)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe result, once we reach 20 octaves, is quite intricate.\nChanging the fractal function has a substantial effect on the output. So far all the fractals I’ve created have used fbm() as the fractal function, but there’s nothing stopping you from writing your own or using one of the other functions supplied by ambient. For example, the ridged() fractal function produces some very lovely patterns:\n\nfractal_art(ridged, gen_simplex, seed = 2, octaves = 1)\nfractal_art(ridged, gen_simplex, seed = 2, octaves = 2)\nfractal_art(ridged, gen_simplex, seed = 2, octaves = 20)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt’s also possible to get nice effects by modifying the gain and frequency functions. For example, here’s an example where the strength of each successive iteration of ridged() noise diminishes to 80% of of the strength of the previous iteration:\n\ngf <- function(x) x * .8\nfractal_art(ridged, gen_simplex, seed = 2, octaves = 1, gain = gf)\nfractal_art(ridged, gen_simplex, seed = 2, octaves = 2, gain = gf)\nfractal_art(ridged, gen_simplex, seed = 2, octaves = 20, gain = gf)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorley noise is an interesting case. The behaviour of gen_worley() is to carve the image up in to distinct cells, and colour each pixel in the image based on the cells they belong to. It’s closely related to Voronoi tesselation, a technique I’ll talk about in a later session. In the simplest case, all pixels in a particular cell are assigned the same colour. So a very basic Worley noise pattern might look like this:\n\nblank_canvas |>\n  mutate(paint = gen_worley(x, y, seed = 6)) |>\n  plot_painted_canvas()\n\n\n\n\n\n\n\n\n\n\n\n\nWhen we create fractals using this kind of generator, there’s a tendency to end up with “kaleidoscopic” looking patterns. Here’s an example using the billow() fractal function:\n\nfractal_art(billow, gen_worley, seed = 6, octaves = 1)\nfractal_art(billow, gen_worley, seed = 6, octaves = 3)\nfractal_art(billow, gen_worley, seed = 6, octaves = 8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHowever, gen_worley() allows also allows you to colour the pixels in different ways. For example, if I set value = \"distance\", each pixel will be coloured as a function of how distant it is from the centroid of the cell it belongs to. A basic pattern looks like this:\n\nblank_canvas |>\n  mutate(paint = gen_worley(x, y, seed = 6, value = \"distance\")) |>\n  plot_painted_canvas()\n\n\n\n\n\n\n\n\n\n\n\n\nFractals created using this method look like this:\n\nfractal_art(billow, gen_worley, seed = 6, octaves = 1, value = \"distance\")\nfractal_art(billow, gen_worley, seed = 6, octaves = 3, value = \"distance\")\nfractal_art(billow, gen_worley, seed = 6, octaves = 8, value = \"distance\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere’s nothing stopping you from writing your own generator function either. At the start of this section that’s exactly what I did in one dimension with gen_sin(). As a two dimensional example, let’s suppose I wanted to create a variation of Worley noise that mixes both the \"cell\" colouring and the \"distance\" colouring. Here’s a generator function that does precisely that:\n\ngen_scope <- function(x, y, ...) {\n  worley_cell <-gen_worley(x, y, value = \"cell\", ...)\n  worley_dist <-gen_worley(x, y, value = \"distance\", ...)\n  return(normalise(worley_cell) + 5 * normalise(worley_dist))\n}\n\npal <- sample_canva(seed = 2)\n\nblank_canvas |>\n  mutate(paint = gen_scope(x, y, seed = 9)) |>\n  plot_painted_canvas(palette = pal)\n\n\n\n\n\n\n\n\n\n\n\n\nI can now use my gen_scope() function as the generator for my fractal:\n\nfractal_art(billow, gen_scope, palette = pal, seed = 9, octaves = 1)\nfractal_art(billow, gen_scope, palette = pal, seed = 9, octaves = 2)\nfractal_art(billow, gen_scope, palette = pal, seed = 9, octaves = 8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI can make the generator as elaborate as I like. The gen_gate() function below uses a “gating” mechanism just like the example I used earlier:\n\ngen_gate <- function(x, y, frequency, ...) {\n  lf <- gen_simplex(x, y, frequency = frequency, ...)\n  mf <- gen_simplex(x, y, frequency = frequency * 20, ...)\n  hf <- gen_simplex(x, y, frequency = frequency * 99, ...)\n  gate <- gen_simplex(x, y, frequency = frequency * 10, ...) \n  gate <- normalise(gate)\n  paint <- lf + \n    (mf + 2) * (gate >= .2 & gate < .8) + \n    (hf + 2) * (gate >= .1)\n  return(paint)\n}\n\npal <- sample_canva(seed = 3)\n\nfractal_art(billow, gen_gate, palette = pal, seed = 9, octaves = 1)\nfractal_art(billow, gen_gate, palette = pal, seed = 9, octaves = 2)\nfractal_art(billow, gen_gate, palette = pal, seed = 9, octaves = 20)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\nThe fractal_art.R script in the materials folder contains all the setup you need to play around with the fractal_art() function. Try using it to explore the possibilities! There are a lot of possibilities in fractals. Here are a few ideas to get you started:\n\nThe easiest way to play around with fractals is to modify the basic arguments. Try changing the generator, fractal, freq_init (i.e., frequency value for the first octave), octaves, seed, and palette to make a piece you really like.\nA fun inversion: use those same arguments to create something that you find incredibly ugly!\nThe fractal_art() function is written flexibly enough that you can pass your own gain functions and frequency functions. There’s an example of this above. Try writing your own functions to modify the gain and frequency rules that apply to the fractal.\nUsing the gen_scope() and gen_gate() examples to motivate you, write your own generator function. See what effect that has."
  },
  {
    "objectID": "day-1/session-2/index.html#curl-of-a-spatial-noise-pattern",
    "href": "day-1/session-2/index.html#curl-of-a-spatial-noise-pattern",
    "title": "SPATIAL TRICKS WITH AMBIENT",
    "section": "Curl (of a spatial) noise (pattern)",
    "text": "Curl (of a spatial) noise (pattern)\nThe last topic to talk about in regards to the ambient package is curl noise. The concept comes from vector calculus, I’m afraid, but fortunately for us we don’t actually need to care. To quote from Wikipedia, the curl is\n\na vector operator that describes the infinitesimal circulation of a vector field in three-dimensional Euclidean space. The curl at a point in the field is represented by a vector whose length and direction denote the magnitude and axis of the maximum circulation. The curl of a field is formally defined as the circulation density at each point of the field.\n\nExciting stuff. But what does it mean? Well, let’s suppose I have a vector field and…\n… wait, what?\nOkay, let’s take a step back. Suppose I have a very small grid of points:\n\nsmol_grid <- long_grid(x = 1:20, y = 1:20)\nggplot(smol_grid) +\n  geom_point(aes(x, y), colour = \"white\") + \n  theme_void() + \n  coord_equal()\n\n\n\n\n\n\n\n\nNow let’s compute the value of the simplex noise pattern at each of these points using gen_simplex(), and represent that as the size of the plot marker (because I can’t resist the urge to make something pretty), or more conventionally as a contour plot illustrating the “height” of the pattern at each point:\n\nsmol_simplex <- smol_grid |>\n  mutate(z = gen_simplex(x, y, seed = 1, frequency = .1)) \n\nsmol_simplex |>\n  ggplot(aes(x, y, size = z)) +\n  geom_point(colour = \"white\", show.legend = FALSE) + \n  theme_void() + \n  coord_equal()\nsmol_simplex |>\n  ggplot(aes(x, y, z = z)) +\n  geom_contour_filled(show.legend = FALSE, bins = 10) + \n  theme_void() + \n  coord_equal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow imagine placing a ball at a point on this surface. Unless it’s at a completely flat spot, it will start rolling in a particular direction and at a particular speed. We can work out where it will start rolling by computing the slope of surface at each point. To do this, we’ll use a finite differencing approximation to calculate the partial derivatives. Or, to put it in less fancy terms, we’ll add a small diffrenece eps to the x-coordinate and compute the value of the simplex noise at the modified values. That gives us the slope in the x-direction. We do the same thing for the y-direction. Putting these two vectors together gives us the local slope.\n\neps <- .001\nsmol_curl <- smol_grid |> mutate(\n  x_add = gen_simplex(x + eps, y, seed = 1, frequency = .1),\n  x_sub = gen_simplex(x - eps, y, seed = 1, frequency = .1),\n  y_add = gen_simplex(x, y + eps, seed = 1, frequency = .1),\n  y_sub = gen_simplex(x, y - eps, seed = 1, frequency = .1),\n  x_slope = (x_add - x_sub) / (2 * eps), \n  y_slope = (y_add - y_sub) / (2 * eps),\n  x_curl = -y_slope, \n  y_curl = x_slope\n)\n\nIf I wanted to plot how fast the simplex noise field was changing at each point on this grid, I’d just plot the x_slope and y_slope values. That would give me something like this:\n\nggplot(smol_curl) + \n  geom_segment(\n    mapping = aes(\n      x = x, \n      y = y, \n      xend = x + x_slope * 2, \n      yend = y + y_slope * 2\n    ), \n    colour = \"white\", \n    arrow = arrow(length = unit(0.1, \"cm\"))\n  ) + \n  theme_void() + \n  coord_equal()\n\n\n\n\n\n\n\n\nThis map of arrows (a.k.a. vector field) depicts the slope at each point on the simplex noise surface. It’s a measure of how fast a ball would start rolling if you placed it down at a particular spot.\nLet’s tweak the analogy slightly. Instead of a ball on a hill, imagine the arrows depict a current pushing a rough-edged disc around in a pool of water. When we place the disc in the water it will start moving because the current pushes it around, but because it’s rough-edged the friction of water flowing over it will make it start rotating. The curl of a field describes these rotational forces. In the same way that our simplex noise pattern implies a vector field of slope values, it also implies a vector field of curl values. For reasons that I’m sure a physicist can explain to me – that I’m certain will have something to do with a conservation law of some kind – x_curl = -y_slope and y_curl = x_slope.\nWhatever.\nAnyway.\nNow we have the curl of our simplex noise and we know vaguely what it means. More importantly, we can draw a pretty picture of the curl field:\n\nggplot(smol_curl) + \n  geom_segment(\n    mapping = aes(\n      x = x, \n      y = y, \n      xend = x + x_curl * 2, \n      yend = y + y_curl * 2\n    ), \n    colour = \"white\", \n    arrow = arrow(length = unit(0.1, \"cm\"))\n  ) + \n  theme_void() + \n  coord_equal()\n\n\n\n\n\n\n\n\nAs it turns out I actually didn’t need to bother with computing this manually, because ambient supplies a curl_noise() function that does the exact same computations for us. I pass it the x and y coordinates from my smol_grid, specify that the generator function is gen_simplex(), and pass the parameters of the noise function (e.g., its seed and frequency) as additional arguments:\n\ncurl <- curl_noise(\n  generator = gen_simplex,\n  seed = 1,\n  frequency = .1,\n  x = smol_grid$x, \n  y = smol_grid$y\n)\n\nas_tibble(curl)\n\n# A tibble: 400 × 2\n         x        y\n     <dbl>    <dbl>\n 1  0.312   0.0597 \n 2  0.124   0.0560 \n 3 -0.0121  0.00537\n 4 -0.0647 -0.0316 \n 5 -0.0808 -0.0412 \n 6 -0.121  -0.0349 \n 7 -0.216  -0.0351 \n 8 -0.214  -0.0817 \n 9 -0.0387 -0.196  \n10  0.138  -0.311  \n# … with 390 more rows\n\n\nThis curl data frame contains x and y columns that specify the curl values at each point in the input. So now I can plot these curl values in the same “map of arrows” style, and unsurprisingly I obtain the same result as last time:\n\nsmol_grid |>\n  mutate(\n    x2 = x + curl$x * 2,\n    y2 = y + curl$y * 2\n  ) |> \n  ggplot() + \n  geom_segment(\n    mapping = aes(x, y, xend = x2, yend = y2),\n    colour = \"white\", \n    arrow = arrow(length = unit(0.1, \"cm\"))\n  ) + \n  theme_void() + \n  coord_equal()\n\n\n\n\n\n\n\n\nGenerative artists have a particular fondness for computing the curl of a noise field and using it for nefarious purposes. There are technical reasons for that, no doubt, but I’m lazy and I feel like I’ve spent too much of my life thinking about this already. So let’s skip the reasons this time and just start doing it. To make my life a little easier I’ll write an update_curl() function that takes a current_state data frame as input (which we assume contains variables x and y that define a grid), computes the curl at all points in this grid, and then returns a new set of x and y values that “add a little bit of curl” to those x and y values:\n\nupdate_curl <- function(current_state, step_size = .0005, ...) {\n  curl <- curl_noise(\n    x = current_state$x, \n    y = current_state$y,\n    ...\n  )\n  next_state <- current_state |>\n    mutate(\n      x = x + curl$x * step_size,\n      y = y + curl$y * step_size,\n      time = time + 1\n    )\n  return(next_state)\n}\n\nNext, let’s define an initial state. At “time” point 1 we have a set of co-ordinates laid out on a grid:\n\ncoords <- seq(0, 1, length.out = 50)\ntime_1 <- long_grid(x = coords, y = coords) |> \n  mutate(id = row_number(), time = 1)\ntime_1\n\n# A tibble: 2,500 × 4\n       x      y    id  time\n   <dbl>  <dbl> <int> <dbl>\n 1     0 0          1     1\n 2     0 0.0204     2     1\n 3     0 0.0408     3     1\n 4     0 0.0612     4     1\n 5     0 0.0816     5     1\n 6     0 0.102      6     1\n 7     0 0.122      7     1\n 8     0 0.143      8     1\n 9     0 0.163      9     1\n10     0 0.184     10     1\n# … with 2,490 more rows\n\n\nNow we can use our update_curl() function to compute a new set of x and y values. We can do this multiple times if we like:\n\ntime_2 <- time_1 |>\n  update_curl(\n    generator = gen_simplex,\n    frequency = 10, \n    seed = 1234\n  )\n\ntime_3 <- time_2 |> \n  update_curl(\n    generator = gen_simplex,\n    frequency = 10, \n    seed = 1234\n  )\n\ntime_3\n\n# A tibble: 2,500 × 4\n          x      y    id  time\n      <dbl>  <dbl> <int> <dbl>\n 1 -0.0264  0.0309     1     3\n 2  0.0226  0.0502     2     3\n 3  0.0417  0.0712     3     3\n 4  0.00234 0.0843     4     3\n 5 -0.0372  0.0573     5     3\n 6 -0.0253  0.0786     6     3\n 7 -0.0154  0.117      7     3\n 8 -0.00378 0.136      8     3\n 9  0.00913 0.159      9     3\n10 -0.0199  0.201     10     3\n# … with 2,490 more rows\n\n\nAt this point it’s important to notice something of particular relevance to generative art. Are there any physicists near you as you read this? Can you hear them sighing?\nGood.\nFrom a physics perspective I’ve done something quite peculiar in this code. I’ve updated the “position” of a set of points (or particles) by adding their rotation (i.e. curl) to their current “position”. I’m not really simulating real movement in physical space I’m plotting changes in rotational forces. Curl fields don’t plot real world movement, they’re an abstraction.\nWhich is fine. From an artistic point of view we care mostly about the fact that we can use this tool to make pretty things. So let’s visualise these “curl updates”:\n\ndat12 <- bind_rows(time_1, time_2)\ndat123 <- bind_rows(time_1, time_2, time_3)\n\ndat12 |>\n  ggplot(aes(x, y, group = id)) + \n  geom_path(colour = \"white\") +\n  theme_void() + \n  coord_equal() \ndat123 |>\n  ggplot(aes(x, y, group = id)) + \n  geom_path(colour = \"white\") +\n  theme_void() + \n  coord_equal() \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis seems promising, right?"
  },
  {
    "objectID": "day-1/session-2/index.html#curl-of-a-fractal-pattern",
    "href": "day-1/session-2/index.html#curl-of-a-fractal-pattern",
    "title": "SPATIAL TRICKS WITH AMBIENT",
    "section": "Curl of a fractal pattern",
    "text": "Curl of a fractal pattern\nOne nice thing about curl_noise() is that it can be applied to any generator, including fracture(). Here’s the basic idea:\n\ncurl_data <- function(\n    data, \n    iterations = 50,\n    step_size = .001,\n    ...\n) {\n  \n  update <- function(current_state, iteration, ...) {\n    curl <- curl_noise(\n      x = current_state$x, \n      y = current_state$y,\n      generator = fracture,\n      ...\n    )\n    next_state <- current_state |>\n      mutate(\n        x = x + curl$x * step_size,\n        y = y + curl$y * step_size,\n        time = time + 1\n      )\n    return(next_state)\n  }\n  \n  data |> \n    mutate(id = row_number(), time = 1) |>\n    accumulate(1:iterations, update, .init = _, ...) |>\n    bind_rows()\n}\n\ncurl_art <- function(...) {\n  curl_data(...) |> \n    ggplot(aes(x, y, group = id)) + \n    geom_path(colour = \"white\") +\n    theme_void() + \n    coord_equal() \n}\n\nA grid of small fractal walks:\n\nsmol_grid |>\n  mutate(x = normalise(x), y = normalise(y)) |>\n  curl_art(noise = gen_simplex, fractal = fbm, octaves = 4, freq_init = .5)\n\n\n\n\n\n\n\n\nAn example where the initial points all lie on a circle:\n\ncircle <- function(n = 100) {\n  tibble(\n    theta = 2 * pi * (1:n) / n, \n    x = cos(theta),\n    y = sin(theta)\n  )\n}\n\ncurl_circle <- function(octaves) {\n  curl_art(\n    data = circle(500),\n    iterations = 100, \n    noise = gen_simplex,\n    fractal = fbm,\n    octaves = octaves, \n    seed = 1, \n    freq_init = 1,\n    frequency = ~ . * 1.2,\n    gain_init = 1,\n    gain = ~ . * .9,\n    step_size = .003\n  )\n}\n\ncurl_circle(octaves = 1)\ncurl_circle(octaves = 3)\ncurl_circle(octaves = 8)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA related example using polygons, heavily influenced by Thomas Lin Pedersen’s “genesis” system:\n\ncustom_curl_data <- function(data) {\n  curl_data(\n    data = data,\n    iterations = 80, \n    octaves = 10,\n    fractal = ridged,\n    noise = gen_cubic,\n    freq_init = 1,\n    frequency = ~ . * 1.2,\n    gain_init = 1,\n    gain = ~ . * .9,\n    seed = 1\n  )\n}\n\ndat1 <- circle(5000) |> \n  custom_curl_data()\n\ndat2 <- circle(5000) |>\n  mutate(x = x * .99, y = y * .99) |>\n  custom_curl_data()\n\nggplot(mapping = aes(x, y, group = time)) +\n  geom_polygon(data = dat1, fill = \"#22222210\") +\n  geom_polygon(data = dat2, fill = \"#ffffff05\") +\n  theme_void() + \n  coord_equal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\nThe curl-art-1.R and curl-art-2.R scripts contain code to generate the “small grid of fractal walks” image and the “genesis-inspired” image. In both cases the ouput is written to a 2000x2000 pixel png file, and the time taken to complete the task printed to the screen.\n\nRun both scripts, and compare the difference in rendering times.\nModify the “small grid” version so that it produces smoother looking results.\nExplore what you can do with the “genesis style”. It’s a powerful technique that can do a lot more than I’ve done in this code. By now you should have a good sense of what dials you can turn: the fractal, the generator, the parameters, the palette, etc. You can use dplyr to modify the data if you want to. Try to make something you really like!"
  },
  {
    "objectID": "day-1/session-3/index.html",
    "href": "day-1/session-3/index.html",
    "title": "POLYGON TRICKS",
    "section": "",
    "text": "library(dplyr)\nlibrary(purrr)\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(ambient)\nlibrary(tictoc)\nlibrary(ggthemes)\nlibrary(gifski)"
  },
  {
    "objectID": "day-1/session-3/index.html#semi-transparent-polygons",
    "href": "day-1/session-3/index.html#semi-transparent-polygons",
    "title": "POLYGON TRICKS",
    "section": "Semi-transparent polygons",
    "text": "Semi-transparent polygons\nA commonly used trick in generative art is to simulate graded textures by plotting many slightly-different and mostly-transparent polygons over the top of one another. I showed an example of this at the end of the previous section, in fact. However, it was all tangled up in the discussion of fractals and spatial noise patterns, so it might be useful to revisit it here.\nIn this section I’m going to adapt the recursive polygon-deformation technique described in Tyler Hobbes’ guide to simulating water colour paint. It’s a simple method and works surprisingly well sometimes. The approach I take here isn’t precisely identical to his, but it’s pretty close.\nLet’s start by creating a square tibble that contains x and y columns specifying the coordinates for a square, and a seg_len column that specifies the length of that of the edge connecting that point to the next one (i.e., the point specified by the next row):\n\nsquare <- tibble(\n  x = c(0, 1, 1, 0, 0),\n  y = c(0, 0, 1, 1, 0),\n  seg_len = c(1, 1, 1, 1, 0)\n)\n\nThis representation defines a closed path: the fifth and final point is the same location as the first one. You don’t technically need this for geom_polygon(), but it’s convenient for other reasons to set it up so that the final “segment” has length 0.\nNext let’s write a simple plotting function to display a polygon:\n\nshow_polygon <- function(polygon, show_vertices = TRUE, ...) {\n  \n  pic <- ggplot(polygon, aes(x, y)) +\n    geom_polygon(colour = \"white\", fill = NA, show.legend = FALSE, ...) + \n    coord_equal() + \n    theme_void()\n  \n  if(show_vertices == TRUE) {\n    pic <- pic + geom_point(colour = \"white\", size = 2)\n  }\n  return(pic)\n}\n\nshow_polygon(square)\n\n\n\n\n\n\n\n\nYes, that is indeed a square.\nThe next step in our process is to think about ways that we can deform this polygon. A simple method would be to insert a new vertex: we select one of the edges and split it in half by creating a new point in between the two endpoints. If we then add a little noise to perturb the location of the new point, the polygon will be slightly deformed.\nHow should we select the edge to break in two? One possibility is to select completely at random, but I’m going to try something slightly different and choose edges with probability proportional to their length. A bias to break longer edges will help ensure we don’t end up with polygons with one or two very long edges and many tiny edges. Here’s a function that does this:\n\nsample_edge <- function(polygon) {\n  sample(nrow(polygon), 1, prob = polygon$seg_len)\n}\n\nAs a side bonus, this algorithm will never select the “edge” that starts with the final point (e.g., the “fifth” point in square never gets selected) because the corresponding edge has length zero. Thanks to this we can safely assume that no matter which row gets selected by sample_edge(), it can’t be the last one. For every possible row ind it can return, there will always be a row ind + 1 in the polygon.\nNext step is to realise that if we break an edge into two edges, we’ll need to compute the length of these two new edges: so we might as well have a helper function that takes the co-ordinates of two points as input, and returns the length of an edge connecting them.\n\nedge_length <- function(x1, y1, x2, y2) {\n  sqrt((x1 - x2)^2 + (y1 - y2)^2)\n}\n\nFinally, as a convenience, here’s a function that takes a size argument and returns a random number between -size/2 and size/2. It’s just a wrapper around runif() but I find it helps me remember why I’m using the random number generator and it makes my code a little easier for me to read:\n\nedge_noise <- function(size) {\n  runif(1, min = -size/2, max = size/2)\n}\n\nNow that I’ve got my helper functions, here’s the code for an insert_edge() function that selects an edge and breaks it into two edges. In addition to expecting a polygon as input (a tibble like square that has columns x, y, and seg_len), it takes a noise argument: a number used to scale the amount of noise added when edge_noise() is called:\n\ninsert_edge <- function(polygon, noise) {\n  \n  # sample and edge and remember its length\n  ind <- sample_edge(polygon)\n  len <- polygon$seg_len[ind]\n  \n  # one endpoint of the old edge\n  last_x <- polygon$x[ind]\n  last_y <- polygon$y[ind]\n  \n  # the other endpoint of the old edge\n  next_x <- polygon$x[ind + 1]\n  next_y <- polygon$y[ind + 1]\n  \n  # location of the new point to be inserted: noise \n  # is scaled proportional to the length of the old edge\n  new_x <- (last_x + next_x) / 2 + edge_noise(len * noise)\n  new_y <- (last_y + next_y) / 2 + edge_noise(len * noise)\n  \n  # the new row for insertion into the tibble, \n  # containing coords and length of the 'new' edge\n  new_row <- tibble(\n    x = new_x,\n    y = new_y,\n    seg_len = edge_length(new_x, new_y, next_x, next_y)\n  )\n  \n  # update the length of the 'old' edge\n  polygon$seg_len[ind] <- edge_length(\n    last_x, last_y, new_x, new_y\n  )\n  \n  # insert a row into the tibble\n  bind_rows(\n    polygon[1:ind, ],\n    new_row,\n    polygon[-(1:ind), ]\n  )\n}\n\nHere’s the function in action:\n\nset.seed(2)\npolygon <- square \npolygon <- insert_edge(polygon, noise = .5); show_polygon(polygon)\npolygon <- insert_edge(polygon, noise = .5); show_polygon(polygon)\npolygon <- insert_edge(polygon, noise = .5); show_polygon(polygon)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI’ve no intention of manually calling insert_edge() over and over, so the time has come to write a grow_polygon() function that sequentially inserts edges into a polygon for a fixed number of iterations, and at a specific noise level. I’ll also set it up so the user can optionally elect to specify the seed used to generate random numbers. If the user doesn’t specify a seed, the random number generator state is left as-is:\n\ngrow_polygon <- function(polygon, iterations, noise, seed = NULL) {\n  if(!is.null(seed)) set.seed(seed)\n  for(i in 1:iterations) polygon <- insert_edge(polygon, noise)\n  return(polygon)\n}\n\nThe images below show what our recursively deformed polygon looks like after 30, 100, and 1000 iterations:\n\nsquare |> \n  grow_polygon(iterations = 30, noise = .5, seed = 2) |> \n  show_polygon(show_vertices = FALSE)\nsquare |> \n  grow_polygon(iterations = 100, noise = .5, seed = 2) |> \n  show_polygon(show_vertices = FALSE)\nsquare |> \n  grow_polygon(iterations = 1000, noise = .5, seed = 2) |> \n  show_polygon(show_vertices = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow that we have functions grow_polygon() and show_polygon() that will create and display a single deformed polygon, let’s generalise them. The grow_multipolygon() function below creates many deformed polygons by calling grow_polygon() repeatedly, and the show_multipolygon() function is a minor variation on show_polygon() that plots many polygons with a low opacity:\n\ngrow_multipolygon <- function(base_shape, n, seed = NULL, ...) {\n  if(!is.null(seed)) set.seed(seed)\n  polygons <- list()\n  for(i in 1:n) {\n    polygons[[i]] <- grow_polygon(base_shape, ...)\n  }\n  polygons <- bind_rows(polygons, .id = \"id\")\n  polygons\n}\n\nshow_multipolygon <- function(polygon, fill, alpha = .02, ...) {\n  ggplot(polygon, aes(x, y, group = id)) +\n    geom_polygon(colour = NA, alpha = alpha, fill = fill, ...) + \n    coord_equal() + \n    theme_void()\n}\n\nSo now here’s what we do. We take the original square and deform it a moderate amount. Running grow_polygon() for about 100 iterations seems to do the trick. This then becomes the base_shape to be passed to grow_multipolygon(), which we then use to create many polygons (say, n = 50) that are all derived from this base shape. Finally, we use show_multipolygon() to plot all 50 polygons. Each individual polygon is plotted with very low opacity, so the overall effect is to create a graded look:\n\ntic()\ndat <- square |> \n  grow_polygon(iterations = 100, noise = .5, seed = 2) |>\n  grow_multipolygon(n = 50, iterations = 1000, noise = 1, seed = 2)\ntoc()\n\n38.597 sec elapsed\n\nshow_multipolygon(dat, fill = \"#d43790\")\n\n\n\n\n\n\n\n\nIt’s a little slow to produce results, but at least the results are pretty!\n\n\n\n\n\n\nExercise\n\n\n\n\nLet’s look at single polygons first. All the code you need to work with those is included in the grow-polygon.R function. Try modifying the iterations, noise, and seed arguments to see what kind of output is created at different parameter values.\nThe grow-multipolygons.R file contains the extra machinery to create these textured plots. Try playing around with the code for this. I’ve tweaked the parameter settings so that it runs faster than the code shown here, but doesn’t produce output that looks quite as nice."
  },
  {
    "objectID": "day-1/session-3/index.html#growing-polygons-faster",
    "href": "day-1/session-3/index.html#growing-polygons-faster",
    "title": "POLYGON TRICKS",
    "section": "Growing polygons faster",
    "text": "Growing polygons faster\nAs an aside, you may have noticed that the code I’ve written here is inefficient: I’ve got vectors growing in a loop, which is very inefficient in R. There’s a few ways we could speed this up. The most time consuming would be to rewrite the resource intensive loops in C++ and then call it from R using a package like Rcpp or cpp11. I’ll show an example of this technique later in the workshop, but in this case I’ll do something a little simpler.\nThe big problem with the previous code is that I’ve got atomic vectors (numeric vectors in this case) growing inside the loop, which tends to cause the entire vector to be copied at every iteration. One solution to this is to store each point as its own list, and treat the polygon as a list of points. That way, when I modify the polygon to add a new point, R will alter the container object (the list), but the objects representing the points themselves don’t get copied. Happily, only a few minor modifications of the code are needed to switch to this “list of points” representation:\n\nsquare_l <- transpose(square)\n\nsample_edge_l <- function(polygon) {\n  sample(length(polygon), 1, prob = map_dbl(polygon, ~ .x$seg_len))\n}\n\ninsert_edge_l <- function(polygon, noise) {\n  \n  ind <- sample_edge_l(polygon)\n  len <- polygon[[ind]]$seg_len\n  \n  last_x <- polygon[[ind]]$x\n  last_y <- polygon[[ind]]$y\n  \n  next_x <- polygon[[ind + 1]]$x\n  next_y <- polygon[[ind + 1]]$y\n  \n  new_x <- (last_x + next_x) / 2 + edge_noise(len * noise)\n  new_y <- (last_y + next_y) / 2 + edge_noise(len * noise)\n  \n  new_point <- list(\n    x = new_x,\n    y = new_y,\n    seg_len = edge_length(new_x, new_y, next_x, next_y)\n  )\n  \n  polygon[[ind]]$seg_len <- edge_length(\n    last_x, last_y, new_x, new_y\n  )\n  \n  c(\n    polygon[1:ind],\n    list(new_point),\n    polygon[-(1:ind)]\n  )\n}\n\ngrow_polygon_l <- function(polygon, iterations, noise, seed = NULL) {\n  if(!is.null(seed)) set.seed(seed)\n  for(i in 1:iterations) polygon <- insert_edge_l(polygon, noise)\n  return(polygon)\n}\n\ngrow_multipolygon_l <- function(base_shape, n, seed = NULL, ...) {\n  if(!is.null(seed)) set.seed(seed)\n  polygons <- list()\n  for(i in 1:n) {\n    polygons[[i]] <- grow_polygon_l(base_shape, ...) |>\n      transpose() |>\n      as_tibble() |>\n      mutate(across(.fn = unlist))\n  }\n  polygons <- bind_rows(polygons, .id = \"id\")\n  polygons\n}\n\nThat’s a fairly large code chunk, but if you compare each part to the earlier versions you can see that these functions have almost the same structure as the original ones. Most of the changes are little changes to the indexing, like using polygon[[ind]]$x to refer to coordinate rather than polygon$x[ind].\nThe code to generate images using the list-of-points version is almost identical to the original version. All we’re doing differently is using square_l, grow_polygon_l(), and grow_multipolygon_l() where previously we’d used square, grow_polygon(), and grow_multipolygon():\n\ntic()\ndat <- square_l |> \n  grow_polygon_l(iterations = 100, noise = .5, seed = 2) |>\n  grow_multipolygon_l(n = 50, iterations = 1000, noise = 1, seed = 2) \ntoc()\n\n30.412 sec elapsed\n\n\nThat’s a pretty substantial improvement in performance relative to the original version, with only very minor rewriting of the code. And yes, it does produce the same result:\n\nshow_multipolygon(dat, fill = \"#d43790\")"
  },
  {
    "objectID": "day-1/session-3/index.html#using-the-method-splotches",
    "href": "day-1/session-3/index.html#using-the-method-splotches",
    "title": "POLYGON TRICKS",
    "section": "Using the method: splotches",
    "text": "Using the method: splotches\nOkay, so that’s the method. What I generally find when making art is that it’s a little awkward to play around and explore when it takes a long time to render pieces, so it’s handy to have a version of your generative art tools that will quickly produce results, even if those results aren’t quite as nice. It’s a little like having the ability to make rough sketches: something you can do easily before committing to doing something in detail. With that in mind, the splotch() function below wraps a slightly cruder version of the method than the one I showed earlier. It generates fewer polygons, and those polygons have fewer vertices.\n\nsplotch <- function(seed, layers = 10) {\n  set.seed(seed)\n  square_l <- transpose(tibble(\n    x = c(0, 1, 1, 0, 0),\n    y = c(0, 0, 1, 1, 0),\n    seg_len = c(1, 1, 1, 1, 0)\n  ))\n  square_l |> \n    grow_polygon_l(iterations = 10, noise = .5, seed = seed) |>\n    grow_multipolygon_l(n = layers, iterations = 500, noise = .8, seed = seed) \n}\n\nThe results aren’t quite as nice as the full fledged version, but they are fast:\n\ntic()\nsplotch_1 <- splotch(seed = 12) \nsplotch_2 <- splotch(seed = 34)\nsplotch_3 <- splotch(seed = 56)\nsplotch_4 <- splotch(seed = 78)\ntoc()\n\n5.894 sec elapsed\n\n\nBecause splotch() is fast and a little crude, it can be a handy way to explore colour choices:\n\nshow_multipolygon(splotch_1, \"#f51720\", alpha = .2)\nshow_multipolygon(splotch_2, \"#f8d210\", alpha = .2)\nshow_multipolygon(splotch_3, \"#059dc0\", alpha = .2)\nshow_multipolygon(splotch_4, \"#81b622\", alpha = .2)"
  },
  {
    "objectID": "day-1/session-3/index.html#using-the-method-smudged-hexagons",
    "href": "day-1/session-3/index.html#using-the-method-smudged-hexagons",
    "title": "POLYGON TRICKS",
    "section": "Using the method: Smudged hexagons",
    "text": "Using the method: Smudged hexagons\nThe goal of splotch() is to have a tool we can play around with and explore the method. That’s nice and all, but can we also use the method to make something fun? Here’s one example: since we are R users and love our hexagons, let’s write a function that paints hexagons using this recursive deformation method. The goal is to create a shape with a naturalistic look, as if it had been painted or coloured, with some of the edges smudged or blurred. The smudged_hexagon() function attempts to do that:\n\nsmudged_hexagon <- function(seed, noise1 = 0, noise2 = 2, noise3 = 0.5) {\n  set.seed(seed)\n  \n  # define hexagonal base shape\n  theta <- (0:6) * pi / 3\n  hexagon <- tibble(\n    x = sin(theta),\n    y = cos(theta),\n    seg_len = edge_length(x, y, lead(x), lead(y))\n  )\n  hexagon$seg_len[7] <- 0\n  hexagon <- transpose(hexagon)\n  base <- hexagon |> \n    grow_polygon_l(\n      iterations = 60, \n      noise = noise1\n    )\n  \n  # define intermediate-base-shapes in clusters\n  polygons <- list()\n  ijk <- 0\n  for(i in 1:3) {\n    base_i <- base |> \n      grow_polygon_l(\n        iterations = 50, \n        noise = noise2\n      )\n    \n    for(j in 1:3) {\n      base_j <- base_i |> \n        grow_polygon_l(\n          iterations = 50, \n          noise = noise2\n        )\n      \n      # grow 10 polygons per intermediate-base\n      for(k in 1:10) {\n        ijk <- ijk + 1\n        polygons[[ijk]] <- base_j |>\n          grow_polygon_l(\n            iterations = 500, \n            noise = noise3\n          ) |>\n          transpose() |>\n          as_tibble() |>\n          mutate(across(.fn = unlist))\n      }\n    }\n  }\n  \n  # return as data frame\n  bind_rows(polygons, .id = \"id\")\n}\n\nHere it is in action:\n\ntic()\ndat <- smudged_hexagon(seed = 1)\ntoc()\n\n19.919 sec elapsed\n\ndat |> show_multipolygon(fill = \"#d4379005\")\n\n\n\n\n\n\n\n\n\nsmudged_hexagon(seed = 11) |> show_multipolygon(fill = \"#d4379005\")\nsmudged_hexagon(seed = 44) |> show_multipolygon(fill = \"#d4379005\")\nsmudged_hexagon(seed = 88) |> show_multipolygon(fill = \"#d4379005\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndat <- bind_rows(\n  smudged_hexagon(seed = 11),\n  smudged_hexagon(seed = 44),\n  smudged_hexagon(seed = 88),\n  .id = \"source\"\n) |>\n  mutate(\n    id = paste(id, source),\n    x = x + as.numeric(source)\n  ) |>\n  arrange(id)\n\nggplot(dat, aes(x, y, group = id, fill = factor(source))) +\n  geom_polygon(alpha = .02, show.legend = FALSE) + \n  theme_void() + \n  scale_fill_manual(values = c(\n    \"#ff1b8d\", \"#ffda00\", \"#1bb3ff\"\n  )) +\n  coord_equal() \n\n\n\n\n\n\n\n\nThis one makes me happy :-)\n\n\n\n\n\n\nExercise\n\n\n\nCode for these two systems is included in the splotch.R and smudged-hexagon.R scripts."
  },
  {
    "objectID": "day-1/session-3/index.html#slightly-misshapen-objects",
    "href": "day-1/session-3/index.html#slightly-misshapen-objects",
    "title": "POLYGON TRICKS",
    "section": "Slightly misshapen objects",
    "text": "Slightly misshapen objects\nThe second case of polygon trickery that I want to talk about is adapted from an example kindly shared with me by Will Chase. Will posted some code on twitter showing how to very gently deform the outline of a shape to give it a slightly hand drawn look, and I’ll expand on that example here. Let’s suppose I want to draw the outline of a heart. I do a little googling and discover some formulas that I can use for that purpose. If I have a vector describing the angle around circle from 0 to 2\\(\\pi\\), I can compute the x- and y-coordinates for a heart shape using these functions:\n\nheart_x <- function(angle) {\n  x <- (16 * sin(angle) ^ 3) / 17\n  return(x - mean(x))\n}\n\nheart_y <- function(angle) {\n  y <- (13 * cos(angle) - 5 * cos(2 * angle) - 2 * cos(3 * angle) -\n          cos(4 * angle)) / 17\n  return(y - mean(y))\n}\n\nHere’s what it looks like when I draw a heart using these formulas:\n\nheart_shape <- tibble(\n  angle = seq(0, 2 * pi, length.out = 50),\n  x = heart_x(angle),\n  y = heart_y(angle)\n)\nshow_polygon(heart_shape)\n\n\n\n\n\n\n\n\nI use hearts drawn with these formulas quite frequently in my art. They’re easy to compute, the shape often produces interesting patterns when other processes are applied to it, and of course it’s meaningfully associated with positive emotions and affection! However, the problem with using this formula is that the hearts it draws are very precise and mechanical. Sometimes that’s fine: precise, crisp shapes are often exactly the look we’re going for. But other times we might want an outline that looks a little more naturalistic. For instance, I asked my 9 year old daughter to draw a few heart shapes for me that I could use as an example. Here’s what she drew:\n\nknitr::include_graphics(\"hand-drawn-hearts.jpg\")\n\n\n\n\n\n\n\n\nSetting aside the fact that in one case she decided that she actually wanted to draw a frog face rather than a heart – unlike DALL-E, humans have a tendency to flat out refuse to follow the text prompts when you ask them to make art for you – these hearts have a qualitatively different feel to the crisp and clean look of the artificial ones.\nWhat we’d like to do is gently and smoothly deform the outline of the original shape to produce something that captures some of the naturalistic feel that the hand-drawn hearts have. As always we’re not going to try to perfectly reproduce all the features of the original, just capture “the vibe”."
  },
  {
    "objectID": "day-1/session-3/index.html#perlin-blobs",
    "href": "day-1/session-3/index.html#perlin-blobs",
    "title": "POLYGON TRICKS",
    "section": "Perlin blobs",
    "text": "Perlin blobs\nLet’s start with a slightly simpler version of the problem: instead of deforming a heart shape we’ll deform a circle using Perlin noise. Our base shape is a circle that looks like this:\n\ncircle <- tibble(\n  angle = seq(0, 2*pi, length.out = 50),\n  x = cos(angle),\n  y = sin(angle)\n)\nshow_polygon(circle)\n\n\n\n\n\n\n\n\nWe can create gently distorted circles using the perlin_blob() function shown below. Here’s how it works. First it defines coordinates in the shape of a perfect circle (that’s the variables x_base and y_base). Then we use gen_perlin() to calculate some spatially varying noise at each of those co-ordinates. Or, more precisely, we generate fractal noise at those coordinates using gen_perlin() as the generator and fbm() as the fractal function, but that’s not a super important detail rignt now. What is important is to realise that, although we want to use the numbers returned by our fractal generator to slightly modify the radius of the circle at that location, those numbers can be negative. So we’ll rescale them using the helper function normalise_radius() so that the minimum distance from the origin is r_min and the maximum distance from the origin is r_max. This rescaling helps to ensure that the output is regular.\nIn any case, after computing the (Perlin-noise distorted) radius associated with each coordinate, we compute the final x and y values for the “Perlin blob” by multiplying the coordinates of the base shape by the radius. Here’s the code:\n\nnormalise_radius <- function(x, min, max) {\n  normalise(x, from = c(-0.5, 0.5), to = c(min, max))\n}\n\nperlin_blob <- function(n = 100, \n                        freq_init = 0.3,\n                        octaves = 2, \n                        r_min = 0.5, \n                        r_max = 1) {\n  tibble(\n    angle = seq(0, 2*pi, length.out = n),\n    x_base = cos(angle),\n    y_base = sin(angle),\n    radius = fracture(\n      x = x_base, \n      y = y_base, \n      freq_init = freq_init,\n      noise = gen_perlin, \n      fractal = fbm, \n      octaves = octaves\n    ) |>\n      normalise_radius(r_min, r_max),\n    x = radius * x_base,\n    y = radius * y_base\n  )\n}\n\nHere are three outputs from our perlin_blob() function:\n\nset.seed(1); perlin_blob() |> show_polygon(FALSE)\nset.seed(2); perlin_blob() |> show_polygon(FALSE)\nset.seed(3); perlin_blob() |> show_polygon(FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo give you a feel for how this function behaves, here’s a few images showing the effect of changing the freq_init parameter. This argument is used to set the overall noise level when generating fractal noise patterns:\n\nset.seed(1); perlin_blob(freq_init = .2) |> show_polygon(FALSE)\nset.seed(1); perlin_blob(freq_init = .4) |> show_polygon(FALSE)\nset.seed(1); perlin_blob(freq_init = .8) |> show_polygon(FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe effect of the radius parameters is slightly different to the effect of the noise parameter. Shifting the r_min and r_max arguments has the effect of “globally flattening” the pattern of variation because the overall shape can only vary within a narrow bound. But it’s quite possible to set a high value for freq_init (causing noticeable distortions to the radius to emerge even at small scales) while constraining the global shape to be almost perfectly circular. The result is a rough-edged but otherwise perfect circle:\n\nset.seed(1); \nperlin_blob(\n  n = 1000,\n  freq_init = 10, \n  r_min = .95, \n  r_max = 1\n) |> \n  show_polygon(FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\nAt these parameter settings the output of perlin_blob() reminds me more of a cookie shape than a hand-drawn circle. I’ve never used those settings in art before, but I can imagine some tasty applications!\n\n\n\n\n\n\nExercise\n\n\n\nCode for this system is included in the perlin-blob.R script. You can also find analogous code for the Perlin heart system describe in in the next section in the perlin-heart.R script."
  },
  {
    "objectID": "day-1/session-3/index.html#perlin-hearts",
    "href": "day-1/session-3/index.html#perlin-hearts",
    "title": "POLYGON TRICKS",
    "section": "Perlin hearts",
    "text": "Perlin hearts\nModifying this system so that it draws distorted heart shapes rather than distorted circles is not too difficult. There’s a few different ways we can do this, but the way I find most pleasing is to start with a distorted circle and then apply the heart_x() and heart_y() transformations:\n\nperlin_heart <- function(n = 100, \n                         freq_init = 0.3,\n                         octaves = 2, \n                         r_min = 0.5, \n                         r_max = 1,\n                         x_shift = 0,\n                         y_shift = 0,\n                         id = NA,\n                         seed = NULL) {\n  if(!is.null(seed)) set.seed(seed)\n  tibble(\n    angle = seq(0, 2*pi, length.out = n),\n    x_base = cos(angle),\n    y_base = sin(angle),\n    radius = fracture(\n      x = x_base, \n      y = y_base, \n      freq_init = freq_init,\n      noise = gen_perlin, \n      fractal = fbm, \n      octaves = octaves\n    ) |>\n      normalise_radius(r_min, r_max),\n    x = radius * heart_x(angle) + x_shift,\n    y = radius * heart_y(angle) + y_shift,\n    id = id\n  )\n}\n\nHere are three outputs from our perlin_heart() function:\n\nperlin_heart(seed = 1) |> show_polygon(FALSE)\nperlin_heart(seed = 2) |> show_polygon(FALSE)\nperlin_heart(seed = 3) |> show_polygon(FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOne of my favourite systems is a very simple one that draws many of these Perlin hearts on a grid, filling each one with a colour selected from a randomly sampled palette. To replicate that here I’ll need a palette generator and once again I’ll fall back on our old favourite sample_canva()\n\nsample_canva <- function(seed = NULL) {\n  if(!is.null(seed)) set.seed(seed)\n  sample(ggthemes::canva_palettes, 1)[[1]]\n}\n\nNow that we have a palette generator we can use the functional programming toolkit from purrr to do the work for us. In this case I’m using pmap_dfr() to call the perlin_heart() at a variety of different settings. I’ve included the x_shift, y_shift and id values among the settings to make it a little easier to plot the data:\n\nperlin_heart_grid <- function(nx = 10, ny = 6, seed = NULL) {\n  if(!is.null(seed)) set.seed(seed)\n  \n  heart_settings <- expand_grid(\n    r_min = .3, \n    r_max = .4, \n    x_shift = 1:nx, \n    y_shift = 1:ny\n  ) |>\n    mutate(id = row_number()) \n  \n  heart_data <-  pmap_dfr(heart_settings, perlin_heart)\n  \n  heart_data |>\n    ggplot(aes(x, y, group = id, fill = sample(id))) +\n    geom_polygon(size = 0, show.legend = FALSE) +\n    theme_void() +\n    scale_fill_gradientn(colours = sample_canva(seed)) +\n    coord_equal(xlim = c(0, nx + 1), ylim = c(0, ny + 1))\n}\n\nperlin_heart_grid(seed = 451)\n\n\n\n\n\n\n\n\n\n\n\n\nWe can elaborate on this idea in various ways. For example, the perlin_heart2() function shown below modifies the original idea by adding a additional width variable computed in a similar way to radius:\n\nperlin_heart2 <- function(n = 100, \n                          freq_init = 0.3,\n                          octaves = 2, \n                          r_min = 0.5, \n                          r_max = 1,\n                          w_min = 0,\n                          w_max = 4,\n                          rot = 0,\n                          x_shift = 0,\n                          y_shift = 0,\n                          id = NA,\n                          seed = NULL) {\n  if(!is.null(seed)) set.seed(seed)\n  tibble(\n    angle = seq(0, 2*pi, length.out = n),\n    \n    radius = fracture(\n      x = cos(angle), \n      y = sin(angle), \n      freq_init = freq_init,\n      noise = gen_perlin, \n      fractal = fbm, \n      octaves = octaves\n    ) |>\n      normalise_radius(r_min, r_max),\n    \n    x = radius * heart_x(angle) + x_shift,\n    y = radius * heart_y(angle) + y_shift,\n    \n    width = fracture(\n      x = cos(angle + rot), \n      y = sin(angle + rot), \n      freq_init = freq_init,\n      noise = gen_perlin, \n      fractal = fbm, \n      octaves = octaves\n    ) |>\n      normalise(to = c(w_min, w_max)),\n    \n    id = id\n  )\n}\n\nHere are three outputs from our perlin_heart2() function, showing the effect of varying the rot parameter. Because the width of outline varies, rot causes the whole pattern of variable thickness to rotate around the heart. As you might imagine, this is going to turn out to be very handy in a moment when we start animating these things!\n\nshow_width <- function(polygon) {\n  ggplot(polygon, aes(x, y, size = width)) +\n    geom_path(colour = \"white\", fill = NA, show.legend = FALSE) + \n    coord_equal() + \n    scale_size_identity() +\n    theme_void()\n}\n\nperlin_heart2(n = 1000, rot = 0, seed = 2) |> show_width()\nperlin_heart2(n = 1000, rot = pi / 2, seed = 2) |> show_width()\nperlin_heart2(n = 1000, rot = pi, seed = 2) |> show_width()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere’s an example where I plot several hearts at once courtesy of the magic of pmap_dfr():\n\nperlin_heart_grid2 <- function(nx = 4, ny = 2, seed = NULL) {\n  if(!is.null(seed)) set.seed(seed)\n  \n  heart_settings <- expand_grid(\n    r_min = .3, \n    r_max = .4, \n    w_min = .01,\n    w_max = 6,\n    x_shift = 1:nx, \n    y_shift = 1:ny\n  ) |>\n    mutate(\n      n = 200,\n      x_shift = x_shift + runif(n(), -.1, .1),\n      y_shift = y_shift + runif(n(), -.1, .1),\n      rot = runif(n(), -.1, .1),\n      id = row_number()\n    ) \n  \n  heart_data <-  pmap_dfr(heart_settings, perlin_heart2)\n  \n  heart_data |>\n    ggplot(aes(x, y, group = id, colour = sample(id), size = width)) +\n    geom_path(show.legend = FALSE) +\n    theme_void() +\n    scale_size_identity() +\n    scale_colour_gradientn(colours = sample_canva(seed)) +\n    scale_x_continuous(expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0)) +\n    coord_fixed(xlim = c(0, nx + 1), ylim = c(0, ny + 1))\n}\n\nperlin_heart_grid2(seed = 666)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCode for these two systems is included in the perlin-heart-grid.R and perlin-heart-grid-2.R scripts."
  },
  {
    "objectID": "day-1/session-3/index.html#animated-perlin-hearts",
    "href": "day-1/session-3/index.html#animated-perlin-hearts",
    "title": "POLYGON TRICKS",
    "section": "Animated perlin hearts",
    "text": "Animated perlin hearts\nThe final example for this session uses the gifsky package to create an animated version of the variable-width hearts from the last section, by “rotating” or “sliding” the variable-with curves along the contours of the Perlin hearts. The design of the functions in this system is very similar in spirit to that adopted in the static systems. The main difference is that the output is created by calling the save_gif() function. We pass it an expression that, in the normal course of events, would create many plots – that’s what the generate_all_frames() function does – and it captures these plots and turns them into a single animated gif:\n\nperlin_heart_data <- function(nhearts = 10, scatter = .05, seed = NULL) {\n  \n  if(!is.null(seed)) set.seed(seed)\n  \n  palette <- sample_canva(seed) |>\n    (\\(x) colorRampPalette(x)(nhearts))()\n  \n  heart_settings <- tibble(\n    id = 1:nhearts,\n    n = 500,\n    r_min = .35, \n    r_max = .4,\n    w_min = -10, \n    w_max = 10,\n    x_shift = runif(nhearts, -scatter/2, scatter/2),\n    y_shift = runif(nhearts, -scatter/2, scatter/2),\n    rot = runif(nhearts, -pi, pi)\n  )\n  \n  heart_settings |>\n    pmap_dfr(perlin_heart2) |>\n    group_by(id) |>\n    mutate(\n      shade = sample(palette, 1),\n      width = abs(width)\n    )\n}\n\ngenerate_one_frame <- function(dat) {\n  \n  pic <- dat |>\n    ggplot(aes(x, y, group = id, size = width, colour = shade)) +\n    geom_path(show.legend = FALSE) +\n    theme_void() +\n    scale_x_continuous(expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0)) +\n    scale_colour_identity() +\n    scale_size_identity() +\n    coord_fixed(xlim = c(-.6, .6), ylim = c(-.6, .6))\n  \n  print(pic)\n}\n\nrotate_vector <- function(x, percent) {\n  \n  len <- length(x)\n  ind <- ceiling(len * percent)\n  if(ind == 0) return(x)\n  if(ind == len) return(x)\n  c(x[(ind+1):len], x[1:ind])\n}\n\ngenerate_all_frames <- function(dat, nframes = 100) {\n  \n  for(frame in 1:nframes) {\n    dat |>\n      group_by(id) |>\n      mutate(width = width |> rotate_vector(frame / nframes)) |>\n      generate_one_frame()\n  }\n}\n\nanimated_perlin_heart <- function(seed, ...) {\n  \n  save_gif(\n    expr = perlin_heart_data(seed = seed, ...) |> generate_all_frames(),\n    gif_file = paste0(\"animated-perlin-heart-\", seed, \".gif\"),\n    height = 1000,\n    width = 1000,\n    delay = .1,\n    progress = TRUE,\n    bg = \"#222222\"\n  )\n  invisible(NULL)\n}\n\ntic()\nanimated_perlin_heart(seed = 100)\ntoc()\n\n17.938 sec elapsed\n\nknitr::include_graphics(\"animated-perlin-heart-100.gif\") \n\n\n\n\n\n\n\n\n\nanimated_perlin_heart(seed = 123)\nanimated_perlin_heart(seed = 456)\nanimated_perlin_heart(seed = 789)\n\nknitr::include_graphics(\"animated-perlin-heart-123.gif\")\nknitr::include_graphics(\"animated-perlin-heart-456.gif\")\nknitr::include_graphics(\"animated-perlin-heart-789.gif\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCode for this system is included in the perlin-heart-animated.R script."
  },
  {
    "objectID": "day-1/session-3/index.html#textured-lines",
    "href": "day-1/session-3/index.html#textured-lines",
    "title": "POLYGON TRICKS",
    "section": "Textured lines",
    "text": "Textured lines\n\nlibrary(e1071)\n\nThere’s one other topic I want to mention in this session, and it’s completely unrelated to rayshader or 3D graphics. It’s also – broadly speaking – to do with texture and shading, but it applies at a much lower level. To motivate the topic, I’ll start by writing a function that uses statistical tools to generate random smooth curves in two dimensions:\n\nsmooth_loess <- function(x, span) {\n  n <- length(x)\n  dat <- tibble(time = 1:n, walk = x)\n  mod <- loess(walk ~ time, dat, span = span)\n  predict(mod, tibble(time = 1:n))\n}\n\nsmooth_path <- function(n = 1000, smoothing = .4, seed = NULL) { \n  if(!is.null(seed)) set.seed(seed)\n  tibble(\n    x = smooth_loess(rbridge(1, n), span = smoothing),\n    y = smooth_loess(rbridge(1, n), span = smoothing),\n    stroke = 1\n  )\n}\n\nHere’s an example of the paths it produces:\n\npath <- smooth_path(seed = 123)\n\npath |> \n  ggplot(aes(x, y)) +\n  geom_path(colour = \"white\", size = 2) + \n  coord_equal() +\n  theme_void() \n\n\n\n\n\n\n\n\nThe path it self is smooth but slightly misshapen (i.e., it doesn’t feel “precise” in the same way that the very first heart felt precise), and you can imagine creating a generative art system that uses this kind of technique, but it doesn’t feel hand drawn. The problem here is that while the path feels fairly natural, the stroke itself is too perfect. It’s a solid line with no texture or grading to it. That spoils the illusion of naturalness to an extent.\nIt’s not too difficult to improve on this if, instead of plotting one smooth curve to represent the path, we plot a very large number of points or small segments with irregular breaks and spacing. In this section I won’t go into a lot of detail on design choices and the various ways you can do this, but I’ll mention that Ben Kovach has a lovely post on making generative art feel natural that discusses this in more detail.\nFor now, I’ll limit myself to presenting some code for a system that implements this idea:\n\nperturb <- function(path, noise = .01, span = .1) {\n  path |> \n    group_by(stroke) |>\n    mutate(\n      x = x + rnorm(n(), 0, noise),\n      y = y + rnorm(n(), 0, noise),\n      x = smooth_loess(x, span),\n      y = smooth_loess(y, span),\n      alpha = runif(n()) > .5,\n      size = runif(n(), 0, .2)\n    )\n}\n\nbrush <- function(path, bristles = 100, seed = 1, ...) {\n  set.seed(seed)\n  dat <- list()\n  for(i in 1:bristles) {\n    dat[[i]] <- perturb(path, ...)\n  }\n  return(bind_rows(dat, .id = \"id\"))\n}\n\nstroke <- function(dat, geom = geom_path, colour = \"white\", ...) {\n  dat |>  \n    ggplot(aes(\n      x = x, \n      y = y, \n      alpha = alpha, \n      size = size, \n      group = paste0(stroke, id)\n    )) + \n    geom(\n      colour = colour, \n      show.legend = FALSE,\n      ...\n    ) + \n    coord_equal() +\n    scale_alpha_identity() +\n    scale_size_identity() +\n    theme_void() + \n    theme(plot.background = element_rect(\n      fill = \"#222222\", \n      colour = \"#222222\"\n    ))\n}\n\nThe plots below show a couple of examples of how you can apply this idea to our original curve:\n\npath |>\n  brush() |>\n  stroke()\npath |>\n  brush(bristles = 200, span = .08) |>\n  mutate(size = size * 3) |>\n  stroke(geom = geom_point, stroke = 0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis doesn’t in any sense exhaust the possibilities, but I hope it’s a useful hint about how to get started if you ever find yourself trying to figure out how to draw naturalistic looking pen strokes. Also, the fact that I’ve included the code means I get to apply the idea to the Perlin hearts system:\n\nperlin_heart(n = 500, seed = 123) |>\n  mutate(stroke = 1) |>\n  brush(bristles = 100, noise = .02) |>\n  stroke() \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCode for this system is included in the textured-lines.R script."
  },
  {
    "objectID": "day-1/session-4/index.html",
    "href": "day-1/session-4/index.html",
    "title": "SHADING TRICKS",
    "section": "",
    "text": "library(rayshader)\nlibrary(tibble)\nlibrary(ambient)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggthemes)\nlibrary(tictoc)\nlibrary(dplyr)"
  },
  {
    "objectID": "day-1/session-4/index.html#rayshader-art",
    "href": "day-1/session-4/index.html#rayshader-art",
    "title": "SHADING TRICKS",
    "section": "Rayshader art",
    "text": "Rayshader art\nThe rayshader package is a tool used to generate 2D and 3D visualisations in R. It is designed primarily to work with elevation data: you can use it to create beautiful shaded maps in two and three dimensions. You don’t have to restrict yourself to mapping applications though. For example, you can use it to create 3D ggplot images if you want. More importantly for our purposes, generative artists in the R community have begun exploring the artistic possibilities inherent in the package. It’s a relatively new addition to my repertoire: I’ve only built a few generative art systems this way, and I’m still a novice user of the package. However, it’s too much fun not to talk about it here, so let’s take rayshader for a spin.\nTo help get us started, I’ll build a very simple generative art system. All it does is overlay a few circles on top of one another. To make this system work, I’ll define a helper function is_within_circle that takes coordinate vectors x_coord and y_coord as inputs, and returns a logical vector that is TRUE whenever those coordinates fall within a circle specified by the radius, x_center, and y_center values.\n\nis_within_circle <- function(x_coord, y_coord, x_center, y_center, radius) {\n  (x_coord - x_center)^2 + (y_coord - y_center)^2 < radius^2\n}\n\nThe additive_circles() function generates n circles at random (defaulting to 5 circles), and returns a long grid that defines a canvas with coordinate columns x and y, and a value column paint indicating the proportion of circles that each point falls in. If a particular point falls within every circle, the corresponding paint value is 1; if it falls within none of the circles the value is 0:\n\nadditive_circles <- function(n = 5, pixels = 1000, seed = NULL) {\n  \n  if(!is.null(seed)) set.seed(seed)\n  \n  # setup canvas\n  art <- long_grid(\n    x = seq(0, 1, length.out = pixels),\n    y = seq(0, 1, length.out = pixels)\n  )\n  art$paint <- 0\n  \n  for(i in 1:n) {\n    \n    # sample a random circle\n    x_center <- runif(1, min = .3, max = .7)\n    y_center <- runif(1, min = .3, max = .7)\n    radius <- runif(1, min = .05, max = .25)\n    \n    # add +1 to all points inside the circle\n    art <- art |>\n      mutate(\n        paint = paint + is_within_circle(\n          x, y, x_center, y_center, radius\n        )\n      )\n  }\n  \n  # normalise paint to [0, 1] range and return\n  art$paint <- normalise(art$paint)\n  return(art)\n}\n\nHere’s what happens when we generate output from the system and then use geom_raster() to plot it:\n\ncircle_art <- additive_circles(seed = 99)\ncircle_art\n\n# A tibble: 1,000,000 × 3\n       x       y paint\n   <dbl>   <dbl> <dbl>\n 1     0 0           0\n 2     0 0.00100     0\n 3     0 0.00200     0\n 4     0 0.00300     0\n 5     0 0.00400     0\n 6     0 0.00501     0\n 7     0 0.00601     0\n 8     0 0.00701     0\n 9     0 0.00801     0\n10     0 0.00901     0\n# … with 999,990 more rows\n\nggplot(circle_art, aes(x, y, fill = paint)) +\n  geom_raster(show.legend = FALSE) + \n  theme_void()\n\n\n\n\n\n\n\n\nExperienced ggplot2 users might wonder why I’m generating art in this fashion. Why go to all the trouble of defining a raster when ggplot2 already has a geom_polygon() function that I could have used to draw the same image? The answer to this is that the rayshader package likes to deal with matrices (and other arrays). Instead of representing the data in a tibble with x and y coordinates that just happen to define a grid, it expects inputs in the form of a matrix where each row corresponds to a y coordinate and each column corresponds to an x coordinate, and the values in each cell correspond to (in our case) the paint values. Conveniently for us, the object we used to store our artwork isn’t a regular tibble, it’s a long grid provide by the ambient package. The ambient package knows how to convert this to an array quickly and painlessly:\n\ncircle_array <- circle_art |>\n  as.array(value = paint) \n\ncircle_array[1:10, 1:10]\n\n       x\ny       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n   [1,]    0    0    0    0    0    0    0    0    0     0\n   [2,]    0    0    0    0    0    0    0    0    0     0\n   [3,]    0    0    0    0    0    0    0    0    0     0\n   [4,]    0    0    0    0    0    0    0    0    0     0\n   [5,]    0    0    0    0    0    0    0    0    0     0\n   [6,]    0    0    0    0    0    0    0    0    0     0\n   [7,]    0    0    0    0    0    0    0    0    0     0\n   [8,]    0    0    0    0    0    0    0    0    0     0\n   [9,]    0    0    0    0    0    0    0    0    0     0\n  [10,]    0    0    0    0    0    0    0    0    0     0\n\n\nThe ability to flip back and forth between a tibble-like representation and a matrix-like representation is very handy! Anyway, the important point is that circle_array is now a matrix. I can plot this matrix directly using image():\n\ncircle_array |> \n  image(axes = FALSE, asp = 1, useRaster = TRUE)\n\n\n\n\n\n\n\n\nLet’s imagine for a moment that this image is actually a terrain map, and the values stored in circle_array refer to the height of the terrain at each point on the grid. If that were true, and we placed an illumination source above the terrain, what pattern of shadows would be cast? We can solve this using ray shading algorithms, and unsurprisingly the rayshader package contains a function called ray_shade() that does this for us. We pass our data matrix as the heightmap argument, provide sunaltitude and sunangle arguments to specify the position of the illumination source, and use the zscale argument to specify the scale of the z-axis (the values) relative to the x- and y-axes.\nHere’s what that looks like:\n\ncircle_shadow <- ray_shade(\n  heightmap = circle_array,\n  sunaltitude = 15, \n  sunangle = 135,\n  zscale = .01,\n  multicore = TRUE\n)\n\nplot_map(circle_shadow, rotate = 270)\n\n\n\n\n\n\n\n\nThe results lack colour because this is only a map of the intensity of the shadow at each point. It’s not a map of the terrain. If we want to construct that map we need something like a hill shading algorithm supplied by sphere_shade(), but that requires us to supply a texture. That’s probably overkill for our initial application. Alternatively, if all we want is a height-to-colour mapping, we can use height_shade() to create the texture, and then use add_shadow() to add the shadow:\n\ncircle_scape <- circle_array |> \n  height_shade() |>\n  add_shadow(\n    shadowmap = circle_shadow,\n    max_darken = .1\n  )\n\nplot_map(circle_scape, rotate = 270)\n\n\n\n\n\n\n\n\nIn the final line I called plot_map() to draw the final image, using the rotate argument so that the final image has the same orientation as the image I created with geom_raster() at the beginning of this page.\n\n\n\n\n\n\nExercise\n\n\n\nCode for this system is included in the circle-scape.R script."
  },
  {
    "objectID": "day-1/session-4/index.html#shadowed-noise-fields",
    "href": "day-1/session-4/index.html#shadowed-noise-fields",
    "title": "SHADING TRICKS",
    "section": "Shadowed noise fields",
    "text": "Shadowed noise fields\nNow that we have a general sense of how to use rayshader to create pretty images, let’s see if we can use it to make something a little more interesting than a shaded map of a few circles laid on top of one another. One place to start is to return to the spatial noise patterns generated by gen_perlin(), gen_simplex() and so on. There’s some potential for interesting art there right?\nBefore we get into that, we’re going to – yet again – need a palette generating function. So once again I’ll define a function to sample palettes using the ggthemes::canva_palettes list. However, this time around I’ll be a little more elaborate. All the palettes in the original object contain exactly four colours. What I’ll with the sample_canva2() function is include an n argument that specifies the number of colours desired, linearly interpolating between colours as necessary.\n\nsample_canva2 <- function(seed = NULL, n = 4) {\n  \n  if(!is.null(seed)) set.seed(seed)\n  sample(ggthemes::canva_palettes, 1)[[1]] |>\n    (\\(x) colorRampPalette(x)(n))()  \n}\n\nHere’s an example:\n\nsample_canva2(seed = 1)\nsample_canva2(seed = 1, n = 7)\n\n[1] \"#FCC875\" \"#BAA896\" \"#E6CCB5\" \"#E38B75\"\n[1] \"#FCC875\" \"#DBB885\" \"#BAA896\" \"#D0BAA5\" \"#E6CCB5\" \"#E4AB95\" \"#E38B75\"\n\n\nThis functionality is handy in this context to ensure that we have enough different colours to produce nice gradients in our rayshader outputs. When working with ggplot2 the scale_*_gradientn() function took care of that for us, but we’re not using ggplot2 here.\nIn any case, here’s ridge_art(), a function that uses the spatial noise toolkit from the ambient package to produce patterns. The output comes in matrix form rather than as a long grid:\n\nridge_art <- function(seed = NULL, pixels = 2000) {\n  \n  if(!is.null(seed)) set.seed(seed)\n  long_grid(\n    x = seq(from = 0, to = 1, length.out = pixels),\n    y = seq(from = 0, to = 1, length.out = pixels)\n  ) |> \n    mutate(\n      paint = fracture(\n        x = x, \n        y = y,\n        noise = gen_simplex,\n        fractal = ridged,\n        octaves = 8,\n        frequency = 10,\n        seed = seed\n      ),\n      paint = normalise(paint)\n    ) |>\n    as.array(value = paint)\n}\n\nAll the work in generating images is being done by the gen_simplex() generator, the ridged() fractal function, and the fracture() function that provides ambients API for fractal noise. To give you a sense of what kind of output this system produces natively, here’s an image():\n\nridge_art(1234) |> \n  image(\n    axes = FALSE, \n    asp = 1, \n    useRaster = TRUE, \n    col = sample_canva2(seed = 1234, n = 256)\n  ) \n\n\n\n\n\n\n\n\nThat’s quite pretty in its own right, but we can give it a real feeling of depth by using rayshader. The idea is essentially identical to what we did when shading our circles art: compute a height map, a shadow map, and add them together before calling plot_map(). Here’s the code for a shaded_ridge_art() function that does this:\n\nshaded_ridge_art <- function(seed = NULL) {\n  \n  art <- ridge_art(seed) \n  height_shade(\n    heightmap = art,\n    texture = sample_canva2(seed, 256)\n  ) |>\n    add_shadow(\n      shadowmap = ray_shade(\n        heightmap = art, \n        sunaltitude = 30, \n        sunangle = 90,\n        multicore = TRUE, \n        zscale = .05\n      ), \n      max_darken = .1\n    ) |>\n    plot_map()\n}\n\nHere’s our ridged art piece rendered as a shaded version:\n\ntic()\nshaded_ridge_art(1234)\n\n\n\n\n\n\n\ntoc()\n\n15.464 sec elapsed\n\n\nJust because they’re pretty and it’s not that hard to generate new pieces – one of the joys of generative art is that the moment you make one piece you like you can immediately make many more in the same style – here are a few more outputs from the system:\n\nshaded_ridge_art(100)\nshaded_ridge_art(101)\nshaded_ridge_art(102) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCode for this system is included in the shaded-ridge-art.R script."
  },
  {
    "objectID": "day-1/session-4/index.html#fractured-terrain",
    "href": "day-1/session-4/index.html#fractured-terrain",
    "title": "SHADING TRICKS",
    "section": "Fractured terrain",
    "text": "Fractured terrain\nBack in the early days of the pandemic I made a series of generative art pieces called Quarantine Moods that was, well, pretty incoherent. Not very surprising: I was trapped indoors and stressed, so there’s no theme or structure to the whole thing. Later on though I found the code for one of the pieces that I really liked and reworked it to create a new system that I called Ice Floes. Pieces from this system have a jagged, fractured geometric look to them. One of the first thoughts I had when exploring the rayshader package was that these images would generate some really interesting shadows, and it would be fun to see what happens when I applied rayshader methods to those outputs. So… that’s what I did!\nThe first step in the process is to recreate the ice floes system, or at least something very similar to it. The trick behind this system is to generate spatial noise defined over a different space to the one I intend to plot at the end. I generate new coordinates by constructing a map from the original coordinates to the corresponding curl space. Or, to put it in less pretentious terms, I use curl_noise() to produce a new set of coordinates that I’m going to feed into other noise processes. Here’s the function I’ll use to that:\n\ntransform_to_curl_space <- function(x, y, frequency = 1, octaves = 10) {\n  curl_noise(\n    generator = fracture,\n    noise = gen_simplex,\n    fractal = fbm,\n    octaves = octaves,\n    frequency = frequency,\n    x = x,\n    y = y\n  )\n}\n\nThe next step is to use Worley noise to construct a set of cells, in this transformed space. To do that I’ll define a helper function that takes a set of coordinates (in whatever space) as input and outputs values associated with the cells:\n\ndefine_worley_cells <- function(x, y, frequency = 3, octaves = 6) {\n  fracture(\n    noise = gen_worley,\n    fractal = billow,\n    octaves = octaves,\n    frequency = frequency,\n    value = \"cell\",\n    x = x,\n    y = y\n  ) |>\n    rank() |> \n    normalise()\n}\n\nNow back in the original space, we’ll use the cell values to (discontinuously) add offsets to the x- and y-coordinates, and then generate simplex noise using those offset coordinates. The net effect of this is that we have the simplex noise varies smoothly within cells (whose borders are quite peculiar because they’re generated in the curl space) but discontinuous between cells. This is going to give us an image that is both smooth and jagged.\nAnyway, this means we need one more helper function:\n\nsimplex_noise <- function(x, y, frequency = .1, octaves = 10) {\n  fracture(\n    noise = gen_simplex,\n    fractal = ridged,\n    octaves = octaves,\n    frequency = frequency,\n    x = x,\n    y = y\n  ) |>\n    normalise()\n}\n\nNow we have all the pieces we need to construct an ice_floe() function that is more or less equivalent to my original system:\n\nice_floe <- function(seed) {\n  \n  set.seed(seed)\n  \n  grid <- long_grid(\n    x = seq(0, 1, length.out = 2000),\n    y = seq(0, 1, length.out = 2000)\n  )\n  \n  coords <- transform_to_curl_space(grid$x, grid$y)\n  \n  grid |>\n    mutate(\n      cells = define_worley_cells(coords$x, coords$y),\n      paint = simplex_noise(x + cells, y + cells),\n      paint = normalise(paint)\n    ) |>\n    as.array(value = paint)\n}\n\nTo give you a sense of what images from the original system look like when coloured using one of the canva palettes, I’ll again use image() to plot the output of the base system:\n\nice_floe(170) |> \n  image(\n    axes = FALSE, \n    asp = 1, \n    useRaster = TRUE, \n    col = sample_canva2(seed = 170, n = 256)\n  )\n\n\n\n\n\n\n\n\nCreating the shaded version of the system proceeds the same way it did when we created the shaded_ridge_art() function. We call ice_floe() to create a matrix of elevations, construct an appropriately shaded elevation map using height_shade(), and then call add_shadow() to add a shadow map generated using ray_shade(). Then we call plot_map() to create the output:\n\nshaded_ice_floe <- function(seed) {\n  \n  art <- ice_floe(seed)\n  \n  height_shade(\n    heightmap = art,\n    texture = sample_canva2(seed, 256)\n  ) |>\n    add_shadow(\n      shadowmap = ray_shade(\n        heightmap = art, \n        sunaltitude = 30, \n        sunangle = 90,\n        multicore = TRUE, \n        zscale = .005\n      ), \n      max_darken = .05\n    ) |>\n    plot_map()\n}\n\nshaded_ice_floe(170)\n\n\n\n\n\n\n\n\nTurns out it’s quite pretty. Here are a few more outputs:\n\nshaded_ice_floe(100)\nshaded_ice_floe(101)\nshaded_ice_floe(102)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshaded_ice_floe(106)\nshaded_ice_floe(107)\nshaded_ice_floe(108)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCode for this system is included in the shaded-icescape.R script."
  },
  {
    "objectID": "day-1/session-4/index.html#three-dimensional-art",
    "href": "day-1/session-4/index.html#three-dimensional-art",
    "title": "SHADING TRICKS",
    "section": "Three dimensional art",
    "text": "Three dimensional art\nThe examples I’ve shown so far all have a feeling of depth because of the way ray_shade() produces natural looking shadows. They’re not truly 3D renderings though. You can’t rotate them in 3D or display them from different perspectives. Happily, the rayshader package allows you to create 3D plots using the plot_3d() function. Under the hood, this function relies on the rgl package, which in turn provides access to OpenGL. For this function to work, your installation of the rgl package needs to be built with access to OpenGL tools. On windows that should happen automatically, but it can be a little mmore tricky on other operating systems. To get it to work on my Ubuntu machine what I had to do was first install OpenGL. The command I used at the terminal was this:\nsudo apt-get install libgl1-mesa-dev libglu1-mesa-dev\nOnce that was complete, I had to force a reinstall for the rgl package to ensure it had been built with the OpenGL libraries present. At the R console:\ninstall.packages(\"rgl\", force = TRUE)\nHaving done so, everything worked pretty smoothly for me.\nOkay, so what can we do with 3d rendering? To start with, let’s keep things simple and use the “circles” example. I’ve already computed a height map (circle_array) and a shading map (circle_scape) that incorporates the shadows, so I can pass both of the to plot_3d(). It’s a little fiddly, so I had to tinker with the angles and other settings to get a result that worked:\n\nplot_3d(\n  hillshade = circle_scape,\n  heightmap = circle_array,\n  theta = 230,\n  phi = 15,\n  zoom = .8,\n  zscale = .001,\n  baseshape = \"circle\",\n  background = \"#222222\",\n  shadow = FALSE,\n  soliddepth = .3,\n  solidcolor = \"#111111\",\n  windowsize = 1200\n)\n\nrender_snapshot(\n  filename = \"circles_3d.png\", \n  clear = TRUE\n)\n\nknitr::include_graphics(\"circles_3d.png\")\n\n\n\n\n\n\n\n\nIt kind of looks like a tower. It’s kind of neat in its own right, but the output gets much more fun when you start feeding richer input to plot_3d(). Here’s what happens when I adapt the “ice floes” system to produce truly three dimensional images:\n\nseed <- 170\n\nice_height <- matrix(0, 2500, 2500)\nice_height[251:2250, 251:2250] <- ice_floe(seed)\n\nice_scape <- height_shade(\n  heightmap = ice_height,\n  texture = sample_canva2(seed, 256)\n) |>\n  add_shadow(\n    shadowmap = ray_shade(\n      heightmap = ice_height, \n      sunaltitude = 30, \n      sunangle = 90,\n      multicore = TRUE, \n      zscale = .005\n    ), \n    max_darken = .05\n  )\n\nplot_3d(\n  hillshade = ice_scape,\n  heightmap = ice_height,\n  theta = 45,\n  phi = 30,\n  zoom = .75,\n  zscale = .001,\n  background = \"#222222\",\n  shadow = FALSE,\n  soliddepth = .5,\n  solidcolor = \"#222222\",\n  windowsize = c(2500, 1500)\n)\n\nrender_snapshot(\n  filename = \"ice_3d.png\", \n  clear = TRUE\n)\n\nknitr::include_graphics(\"ice_3d.png\")\n\n\n\n\n\n\n\n\nEven I have to admit I was impressed with myself this time. That worked way better than I was expecting it to, and I suspect it would look even nicer if I’d taken the time to learn more about hill shading algorithms and used sphere_shade() to create a proper terrain map rather rather than relying on height_shade(). Something to play around with in the future :)\n\n\n\n\n\n\nExercise\n\n\n\nCode for this system is included in the icescape-3d.R script."
  },
  {
    "objectID": "day-2/session-1/index.html",
    "href": "day-2/session-1/index.html",
    "title": "ITERATED FUNCTION SYSTEMS",
    "section": "",
    "text": "library(Rcpp)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(ggthemes)\nlibrary(tictoc)\nSo… iterated function systems. What are they?"
  },
  {
    "objectID": "day-2/session-1/index.html#some-tiresome-formalism",
    "href": "day-2/session-1/index.html#some-tiresome-formalism",
    "title": "ITERATED FUNCTION SYSTEMS",
    "section": "Some tiresome formalism",
    "text": "Some tiresome formalism\nOne of the joys of leaving academia is that I can stop pretending that I don’t get all my mathematical knowledge from Wikipedia, and as the entry for iterated function systems oh so helpfully informs us, an iterated function system is defined as a finite set of contractive maps on a complete metric space \\(X = (M, d)\\), formally denoted\n\\[\n\\left\\{f_i : X \\rightarrow X \\mid i = 1, 2, \\ldots N \\right\\}, N \\in \\mathcal{N}\n\\]\nwhere the function \\(f_i\\) is a contraction on \\(X\\) if there exists some real number \\(k\\) such that \\(d(f_i(x), f_i(y)) \\leq k \\ d(x,y)\\) for all \\(x \\in M\\) and \\(y \\in M\\).\nIf that weren’t impenetrable enough, Wikipedia continues to explain that\n\nHutchinson (1981) showed that, for the metric space \\({\\displaystyle \\mathbb {R} ^{n}}\\), or more generally, for a complete metric space \\(X\\), such a system of functions has a unique nonempty compact (closed and bounded) fixed set \\(S\\). One way of constructing a fixed set is to start with an initial nonempty closed and bounded set \\(S_0\\) and iterate the actions of the \\(f_i\\), taking \\(S_{n+1}\\) to be the union of the images of \\(S_n\\) under the \\(f_i\\); then taking \\(S\\) to be the closure of the union of the \\(S_n\\). Symbolically, the unique fixed (nonempty compact) set \\(S\\subseteq X\\) has the property\n\n\\[S = \\overline{\\bigcup_{i=1}^N f_i(S)}.\\]\n\nThe set \\(S\\) is thus the fixed set of the Hutchinson operator \\(F:2^{X}\\to 2^{X}\\) defined for \\(A\\subseteq X\\) via\n\n\\[F(A)={\\overline {\\bigcup _{i=1}^{N}f_{i}(A)}}.\\]\n\nThe existence and uniqueness of \\(S\\) is a consequence of the contraction mapping principle, as is the fact that\n\n\\[\\lim _{n\\to \\infty }F^{\\circ n}(A)=S\\]\n\nfor any nonempty compact set \\(A \\in X\\). (For contractive IFS this convergence takes place even for any nonempty closed bounded set \\(A\\)). Random elements arbitrarily close to \\(S\\) may be obtained by the “chaos game”\n\nI am entirely certain that you do not care.\nAs impressive as I find all this notation, I don’t find it helps me understand what an iterated function system actually does. What I do find helpful, however, is to play the chaos game, because that’s a concrete method we can use to simulate the behaviour of an IFS, and in practice that’s what our code will actually do!"
  },
  {
    "objectID": "day-2/session-1/index.html#chaos-game-for-the-barnsley-fern",
    "href": "day-2/session-1/index.html#chaos-game-for-the-barnsley-fern",
    "title": "ITERATED FUNCTION SYSTEMS",
    "section": "Chaos game for the Barnsley fern",
    "text": "Chaos game for the Barnsley fern\nWhen written as pseudocode, the chaos game is remarkably simple:\n\nChoose a set of starting values \\((x_0, y_0)\\)\nSet iteration number \\(i = 1\\)\nChoose a transformation function \\(f\\) to use on this iteration\nGet the next value by passing the current value to the function, i.e. \\((x_i, y_i) = f(x_{i-1}, y_{i-1})\\)\nUpdate iteration number \\(i = i + 1\\) and return to step 3; or finish\n\nI’ve written this on the assumption that the functions are defined over a two dimensional space with \\(x\\) and \\(y\\) coordinates, but it generalises naturally to any number of dimensions. When choosing a transformation function in step 3, you can sample uniformly at random, or impose a bias so that some transformation are applied more often than others.\nTo get a sense of how this works, let’s start with a classic example: the Barnsley fern. The Barnsley fern, like many iterated function systems I use for my art, is constructed from functions \\(f(x, y)\\) defined in two dimensons. Better yet, they’re all affine transformations so we can write any such function down using good old fashioned linear algebra, and compute everything using matrix multiplication and addition:\n\\[f(x,y)={\\begin{bmatrix}a&b\\\\c&d\\end{bmatrix}}{\\begin{bmatrix}x\\\\y\\end{bmatrix}}+{\\begin{bmatrix}e\\\\f\\end{bmatrix}}\\]\nThere are four such functions used to build the Barnsley fern, with coefficients shown below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(a\\)\n\\(b\\)\n\\(c\\)\n\\(d\\)\n\\(e\\)\n\\(f\\)\nweight\ninterpretation\n\n\n\n\n\\(f_1(x, y)\\)\n0\n0\n0\n0.16\n0\n0\n0.01\nmakes the stem\n\n\n\\(ƒ_2(x, y)\\)\n0.85\n0.04\n−0.04\n0.85\n0\n1.60\n0.85\nmakes ever-smaller leaflets\n\n\n\\(ƒ_3(x, y)\\)\n0.20\n−0.26\n0.23\n0.22\n0\n1.60\n0.07\nmakes largest left-hand leaflet\n\n\n\\(ƒ_4(x, y)\\)\n−0.15\n0.28\n0.26\n0.24\n0\n0.44\n0.07\nmakes largest right-hand leaflet\n\n\n\nOkay, so let’s start by implementing the Barnsley fern transformation functions in R. The fern_transform() function below takes coord input as a two-element numeric vector, and an ind argument that specifies which of the four transformations to apply (this should be an integer between 1 and 4). The output is the next set of coord values to use in the chaos game:\n\nfern_transform <- function(coord, ind) {\n  \n  # coefficients for the stem function f_1\n  if(ind == 1) {\n    mat <- matrix(c(0, 0, 0, .16), 2, 2) # matrix to multiply\n    off <- c(0, 0)                       # offset vector to add\n  }\n  \n  # coefficients for the small leaflet function f_2\n  if(ind == 2) {\n    mat <- matrix(c(.85, -.04, .04, .85), 2, 2)\n    off <- c(0, 1.6)                      \n  }\n  # coefficients for the right-side function f_3\n  if(ind == 3) {\n    mat <- matrix(c(.2, .23, -.26, .22), 2, 2)\n    off <- c(0, 1.6)                      \n  }\n  \n  # coefficients for the left-side function f_4\n  if(ind == 4) {\n    mat <- matrix(c(-.15, .26, .28, .24), 2, 2)\n    off <- c(0, .44)                     \n  }\n  \n  # return the affine transformed coords\n  coord <- mat %*% coord + off\n  return(coord)\n}\n\nArmed with the fern_transform() function, we can write a fern_chaos() function that implements the chaos game for the Barnsley fern. The arguments to fern_chaos() specify the number of iterations over which the game should be played, and (optionally) a seed to control the state of the random number generator:\n\nfern_chaos <- function(iterations = 10000, seed = NULL) {\n  if(!is.null(seed)) set.seed(seed)\n  \n  # which transformation to apply at each iteration\n  transform_index <- sample(\n    x = 1:4, \n    size = iterations, \n    replace= TRUE, \n    prob = c(.01, .85, .07, .07)\n  )\n  \n  # initialise chaos game at the origin\n  start <- matrix(c(0, 0))\n  \n  # helper function to collapse accumulated output\n  bind_to_column_matrix <- function(lst) {\n    do.call(cbind, lst)\n  }\n  \n  # iterate until done!\n  coord_matrix <- transform_index |>\n    accumulate(fern_transform, .init = start) |>\n    bind_to_column_matrix() \n  \n  # tidy the output, add extra columns, and return\n  coord_df <- t(coord_matrix) |> \n    as.data.frame() \n  names(coord_df) <- c(\"x\", \"y\")\n  coord_df <- coord_df |>\n    as_tibble() |>\n    mutate(\n      transform = c(0, transform_index),\n      iteration = row_number() - 1\n    )\n  return(coord_df)\n}\n\nThis function is a little fussier than it really needs to be. For example, if you compare my code to the base R version on Wikipedia you’ll see I spend extra effort tidying the results at the end: rather than returning a matrix of points, I’ve coerced it to a tibble that includes the coordinates as columns x and y, but in addition contains a column transform specifying which of the transformation functions was used to generate each point, and the iteration number as a unique identifier for each row. In any case, here’s the output:\n\nfern_dat <- fern_chaos(seed = 1)\nfern_dat\n\n# A tibble: 10,001 × 4\n        x     y transform iteration\n    <dbl> <dbl>     <dbl>     <dbl>\n 1  0     0             0         0\n 2  0     1.6           2         1\n 3  0.064 2.96          2         2\n 4  0.173 4.11          2         3\n 5 -1.03  2.54          3         4\n 6 -0.778 3.80          2         5\n 7 -1.14  2.26          3         6\n 8  0.804 0.684         4         7\n 9  0.711 2.15          2         8\n10  0.690 3.40          2         9\n# … with 9,991 more rows\n\n\nIt looks nicer as a plot though :)\n\nggplot(fern_dat, aes(x, y)) +\n  geom_point(colour = \"white\", size = 1, stroke = 0) +\n  coord_equal() +\n  theme_void()\n\n\n\n\n\n\n\n\nThe reason I went to the extra trouble of storing the transform column was so I could map it to the colour aesthetic in my plot. When I do this, I get this as the result: there’s a transformation function that defines the left leaf shape, another that defines the right leaf shape, and a third one that defines the stem shape. Finally, there’s a function that copies, shifts-up, and rotates its input in a way that produces the vertical symmetry in the output.\n\nggplot(fern_dat, aes(x, y, colour = factor(transform))) +\n  geom_point(size = 1, stroke = 0) +\n  coord_equal() +\n  theme_void() + \n  theme(\n    legend.text = element_text(colour = \"white\"),\n    legend.title = element_text(colour = \"white\")\n  ) +\n  guides(colour = guide_legend(\n    title = \"transformation\", \n    override.aes = list(size = 5))\n  )\n\n\n\n\n\n\n\n\nIt’s painfully obvious now what each of the transformation functions does!\nAs we’ll see a little later, it can be very useful to plot your outputs this way sometimes: even if you’re planning to do something fancier with colour later, the ability to visualise which parts of your output are associated with a particular function is useful for diagnosing what your system is doing. My experience has been that iterated function systems are difficult to reason about just by looking at the code: the relationship between the code and the output is pretty opaque, so you have to rely on diagnostics like this when tweaking the output of your system.\nFor no particular reason, here’s our fern with the colour aesthetic mapped to the iteration number:\n\nggplot(fern_dat, aes(x, y, colour = iteration)) +\n  geom_point(size = 1, stroke = 0, show.legend = FALSE) +\n  coord_equal() +\n  theme_void() \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCode for this system is included in the barnsley-fern.R script."
  },
  {
    "objectID": "day-2/session-1/index.html#happy-accidents",
    "href": "day-2/session-1/index.html#happy-accidents",
    "title": "ITERATED FUNCTION SYSTEMS",
    "section": "Happy accidents",
    "text": "Happy accidents\nIterated function systems can be a lot more elaborate than the Barnsley fern, often involving transformation functions that are constructed according to some fancypants compositional rules. For example, the fractal flame algorithm proposed by Scott Draves in 1992 (here’s the original article) specifies transformation functions \\(f_i()\\) – called “flame functions” – that are composed according to the rule:\n\\[\nf_i(\\mathbf{x}) = \\sum_j w_{ij} \\ g_j(\\mathbf{A}_i \\mathbf{x})\n\\]\nwhere\n\n\\(\\mathbf{A}_i\\) is a matrix that defines an affine transformation of the coordinates \\(\\mathbf{x}\\) associated with this specific flame function (i.e., each flame function \\(f_i()\\) has its own transformation \\(\\mathbf{A_i}\\), and in the two dimensional case \\(\\mathbf{x}\\) is just the points \\((x, y)\\));\nthe various \\(g_j()\\) functions are called “variant functions”, and these don’t have to be linear: they can be sinusoidal, or discontinuous, or whatever you like really; and\neach flame function is defined as a linear combination of the variant functions: the coefficient \\(w_{ij}\\) specifies the weight assigned to the \\(j\\)-th variant function by the \\(i\\)-th flame function.\n\nAdditionally, just as we saw with the Barnsley fern, the flame functions themselves can be weighted with a probability vector: a system can be defined in a way that has a bias for some flame functions over others.\nThis probably sounds a bit… intense, right?\nSo yeah. Um.\nWhen I first decided to try implementing the fractal flame algorithm I decided I wasn’t going to bother with fancypants weights \\(w_{ij}\\), so I… ignored them. But then – because I was tired and not really paying attention to the subscripts in Draves equations – I decided that my system was going to have one flame function for every possible combination of transformation matrix \\(\\mathbf{A}_i\\) and variant function \\(g_j()\\). What this meant is that the thing I actually coded was this. Given a set of variant functions \\(g_1, g_2, \\ldots, g_n\\) and some set of transformation matrices \\(\\mathbf{A}_1, \\mathbf{A}_2, \\ldots, \\mathbf{A}_m\\), I included every transformation function \\(f_{ij}(\\mathbf{x})\\) of the following form:\n\\[\nf_{ij}(\\mathbf{x}) = g_j(\\mathbf{A}_i \\mathbf{x})\n\\]\nWhen your transformation functions are composed in this way you can sample a random transformation \\(f_{ij}\\) by sampling the two components independently: sample a transformation matrix \\(\\mathbf{A}_i\\) and a variant function \\(g_j\\), and then you’re done. It ends up being a weird special case of the fractal flame algorithm, but it turns out you can make pretty things that way.\nOh well. Whatever.\nThe point of art isn’t to mindlessly copy what someone else has done, and if I’m being honest with myself the truth is that some of the best art I’ve created started with a coding error or a misinterpretation like this one. As Bob Ross famously said,\n\nThere are no mistakes, just happy accidents."
  },
  {
    "objectID": "day-2/session-1/index.html#chaos-game-for-unboxing",
    "href": "day-2/session-1/index.html#chaos-game-for-unboxing",
    "title": "ITERATED FUNCTION SYSTEMS",
    "section": "Chaos game for unboxing",
    "text": "Chaos game for unboxing\nEnough chitchat about my artistic process. Let’s actually implement a version of my Unboxing system. In this example, the coefficients that define the affine transformations \\(\\mathbf{A_i}\\) have been sampled uniformly at random, with values ranging from -1 to 1. There’s a layers input argument that specifies how many of these affine transformations to include (no I don’t know why I called it layers – it’s a bad name I think). Anyway, the code snippet below shows how this is implemented:\n\ncoeffs <- array(\n  data = runif(9 * layers, min = -1, max = 1), \n  dim = c(3, 3, layers)\n)\n\nThe coefficients are stored in an array: coeffs[,,i] is the matrix of coefficients \\(\\mathbf{A_i}\\).\nThere are three variant functions \\(g_j\\) in this system: two of them are sinusoidal functions: one of them computes sin(x) and sin(y), and the other computes the same thing but multiplies the output by two. Both of these will produce wavy shapes. The other one is a rescaling function: it tends to shift points towards the top right corner. The code snippet below implements these variant functions:\n\nfuns <- list(\n  function(point) point + (sum(point ^ 2)) ^ (1/3),\n  function(point) sin(point),\n  function(point) 2 * sin(point)\n)\n\nThe unboxer_base() function below implements the whole thing:\n\nunboxer_base <- function(iterations, layers, seed = NULL) {\n  \n  if(!is.null(seed)) set.seed(seed)\n  \n  # coefficients defining affine layer transforms, A_i\n  coeffs <- array(\n    data = runif(9 * layers, min = -1, max = 1), \n    dim = c(3, 3, layers)\n  )\n  \n  # list of variant functions, g_j\n  funs <- list(\n    function(point) point + (sum(point ^ 2)) ^ (1/3),\n    function(point) sin(point),\n    function(point) 2 * sin(point)\n  )\n  \n  # updater function: apply the layer, then the function\n  # (the weirdness with point[3] is me treating colour as special)\n  update <- function(point, layer, transform) {\n    f <- funs[[transform]]\n    z <- point[3]\n    point[3] <- 1\n    point <- f(point %*% coeffs[,,layer])\n    point[3] <- (point[3] + z)/2\n    return(point)\n  }\n  \n  # initial point\n  point0 <- matrix(\n    data = runif(3, min = -1, max = 1), \n    nrow = 1,\n    ncol = 3\n  )\n  \n  # sample points\n  layer_ind <- sample(layers, iterations, replace = TRUE)  \n  trans_ind <- sample(length(funs), iterations, replace = TRUE)  \n  points <- accumulate2(layer_ind, trans_ind, update, .init = point0)\n  \n  # tidy up, add columns, and return\n  points <- matrix(unlist(points), ncol = 3, byrow = TRUE)\n  points <- cbind(\n    points,\n    c(0, layer_ind),\n    c(0, trans_ind)\n  )\n  return(points)\n}\n\nLet’s run this system for a few iterations, just so we can see what the output looks like:\n\nunboxer_base(10, layers = 5, seed = 333)\n\n             [,1]        [,2]       [,3] [,4] [,5]\n [1,] -0.88255069 -0.04718621  0.1969293    0    0\n [2,] -1.67203174  1.84627339 -0.7948247    5    3\n [3,]  0.36262158  1.58519247 -0.4479714    3    1\n [4,]  1.07641590  0.44778402 -0.1920135    1    1\n [5,]  0.96570274  0.34005575 -0.8206870    1    3\n [6,] -0.98567258 -0.99766695 -0.7158925    3    2\n [7,]  0.94597134  0.21844210 -0.3696898    4    2\n [8,] -0.02509324  0.35517269 -0.2772464    4    2\n [9,]  1.21601399  0.20495003 -0.9885079    1    3\n[10,]  1.22236642  3.28357073  1.2944046    2    1\n[11,] -0.93808971 -0.91680227  0.5876316    5    2\n\n\nAs you can see, this time around I’ve not gone to the effort of converting it to a tibble or making it pretty. This output is a matrix. The first column is the x-coordinate and the second column is the y-coordinate. The third column is a “z-coordinate” that we’ll map to the colour aesthetic later. Column four specifies the layer number (i.e., the value \\(i\\) specifying which affine matrix \\(\\mathbf{A}_i\\) was used), and column five specifies the variant function number (i.e., the value \\(j\\) specifying which variant function \\(g_j()\\) was used).\nIf we want to turn these numbers into art and attach colours to the points, we are going to need a palette function, so as usual I’ll insert my code to sample one of the canva palettes:\n\nsample_canva2 <- function(seed = NULL, n = 4) {\n  \n  if(!is.null(seed)) set.seed(seed)\n  sample(ggthemes::canva_palettes, 1)[[1]] |>\n    (\\(x) colorRampPalette(x)(n))()  \n}\n\nHaving done all that work, the rendering function in not very fancy: it’s just some ggplot2 code to create a scatter plot from the points and colour them using a canva palette:\n\nunbox_art <- function(data, seed = NULL, size = 1) {\n  \n  # convert to data frame and sample a palette\n  data <- data |> as.data.frame() |> as_tibble()\n  names(data) <- c(\"x\", \"y\", \"c\", \"l\", \"t\")[1:ncol(data)]\n  shades <- sample_canva2(seed)\n  \n  # render image as a scatter plot\n  ggplot(data, aes(x, y, colour = c)) +\n    geom_point(\n      size = size,\n      stroke = 0,\n      show.legend = FALSE\n    ) + \n    theme_void() + \n    coord_equal(xlim = c(-4, 4), ylim = c(-4, 4)) + \n    scale_colour_gradientn(colours = shades) + \n    scale_x_continuous(expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0)) +\n    theme(panel.background = element_rect(\n      fill = shades[1], colour = shades[1]\n    ))\n}\n\n\n\n\nThe results can be very pretty, especially when you generate a large number of points (say, 3 million) and plot them with a very small marker size (say, .1).\n\nmil <- 1000000\ntic()\nunboxer_base(3 * mil, layers = 3, seed = 66) |> \n  unbox_art(seed = 66, size = .1)\n\n\n\n\n\n\n\ntoc()\n\n29.458 sec elapsed\n\n\nThe system is slow, but I’m usually willing to wait 30 seconds for something pretty. (Though in a moment I’ll talk about how we can speed this up drastically)\n\n\n\n\n\n\nExercise\n\n\n\nCode for this system is included in the unbox-base.R script.\n\n\nThe outputs from this system have a fairly consistent look and feel: a pair of nested boxes, with something “bursting” from the top right corner. The fine grained details vary a lot from output to output, and there are some systematic differences as a function of the number of layers. Here’s an example showing what happens when I ratchet up the number of layers from 2 to 9:\n\ntic()\nunboxer_base(mil, layers = 2, seed = 999) |> unbox_art(seed = 2, size = .2)\nunboxer_base(mil, layers = 5, seed = 333) |> unbox_art(seed = 2, size = .2) \nunboxer_base(mil, layers = 9, seed = 420) |> unbox_art(seed = 2, size = .2)\ntoc() \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n26.623 sec elapsed\n\n\n\n\nTo understand what’s going on in this system, I’ll go through the same exercise I did with the Barnsley fern. I’ll generate the data for a piece of art by calling unboxer_base(), and then plot it three ways. First I’ll show it as a pure black and white image to show the overall configuration of points, then I’ll break it down based on the components. Because each transformation function is defined in terms the affine component and the variant component, I’ll show two different versions of this.\n\ndat <- unboxer_base(mil, layers = 2, seed = 99) |> \n  as.data.frame() |> \n  as_tibble()\n\nnames(dat) <- c(\"x\", \"y\", \"c\", \"affine_layer\", \"variant_function\")\n\ndat <- dat |> \n  slice_tail(n = -1) |> \n  mutate(\n    affine_layer = factor(affine_layer),\n    variant_function = factor(variant_function)\n  ) \n\nggplot(dat, aes(x, y)) +\n  geom_point(size = .4, stroke = 0, show.legend = FALSE) + \n  theme_void() + \n  coord_equal(xlim = c(-4, 4), ylim = c(-4, 4))\nggplot(dat, aes(x, y, colour = variant_function)) +\n  geom_point(size = .4, stroke = 0) + \n  coord_equal(xlim = c(-4, 4), ylim = c(-4, 4)) +\n  scale_colour_brewer(palette = \"Set2\") +\n  guides(colour = guide_legend(nrow = 1, override.aes = list(size = 5))) +\n  theme_void() + \n  theme(legend.position = c(0.2, 0.1))\nggplot(dat, aes(x, y, colour = affine_layer)) +\n  geom_point(size = .4, stroke = 0) + \n  coord_equal(xlim = c(-4, 4), ylim = c(-4, 4)) +\n  scale_colour_brewer(palette = \"Set1\") +\n  guides(colour = guide_legend(nrow = 1, override.aes = list(size = 5))) +\n  theme_void() + \n  theme(legend.position = c(0.2, 0.1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis gives you a sense of what’s going on here: in the middle panel you can see that the two “sinusoidal” components have the effect of creating the boxes, because sin(x) is constrained to lie between -1 and 1. The snaky, wavy patterns that you see in some the outputs are also related to these components, but I haven’t plotted the data in a way that makes this obvious.\nIn contrast, on the right you can see the effect of the affine transformations. Notice that the blue pattern kind of looks like a “squashed and rotated” version of the red pattern? That’s exactly what the affine transforms do. They create these distortions."
  },
  {
    "objectID": "day-2/session-1/index.html#faster-chaos-with-rcpp",
    "href": "day-2/session-1/index.html#faster-chaos-with-rcpp",
    "title": "ITERATED FUNCTION SYSTEMS",
    "section": "Faster chaos with Rcpp",
    "text": "Faster chaos with Rcpp\nWaiting 30 seconds for something pretty is kind of annoying, especially when you’re still developing the system and you just want to tinker with the settings to see what it does. It would be nice if we could speed this up, right? The easiest way to speed things up is to run fewer iterations and use larger plot sizes. I mean, this works perfectly fine…\n\ntic()\nunboxer_base(50000, layers = 2, seed = 999) |> unbox_art(seed = 2, size = 1)\nunboxer_base(50000, layers = 5, seed = 333) |> unbox_art(seed = 2, size = 1) \nunboxer_base(50000, layers = 9, seed = 420) |> unbox_art(seed = 2, size = 1)\ntoc() \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.733 sec elapsed\n\n\n\n\nIf you’re okay with a coarser grained output (or flat out don’t want to mess around with C++ code), your problems are solved! Read no further!\nIf speed is a consideration – especially if the rendering times are interfering with the creative process – one possibility would be to write the slow parts of your code in C++, and then call it from R using the Rcpp package. To be honest, I’m not the best C++ coder myself and am only moderately comfortable with Rcpp, so I’m not going to attempt a tutorial here. Instead, what I’ll do is mention that rcpp.org has some excellent resources, and Advanced R also has a good chapter on Rewriting R code in C++ that you may find helpful. I’ll also show you what I did for this system, because sometimes it’s helpful to see C++ code that implements the same functions as the original R code. Let’s imagine I have a file called unbox-fast.cpp that includes the following:\n\n\n\n\n#include <Rcpp.h>\n#include <iostream>\nusing namespace Rcpp;\nusing namespace std;\n\n// [[Rcpp::export]]\nNumericMatrix unboxer_rcpp(int iterations, int layers) {\n  \n  // variables\n  NumericMatrix pts(iterations, 3); \n  NumericMatrix cff(9, layers);\n  int r, f;\n  double x, y, z, s;\n  \n  // coefficients\n  for(int i = 0; i < 9; i++) {\n    for(int j = 0; j < layers; j++) {\n      cff(i,j) = R::runif(-1,1);\n    }\n  }\n  \n  // initial point\n  pts(0, 0) = R::runif(-1, 1);\n  pts(0, 1) = R::runif(-1, 1);\n  pts(0, 2) = R::runif(-1, 1);\n  \n  // accumulate\n  for(int t = 1; t < iterations; t++) {\n    r = rand() % layers; // which transform to use?\n    f = rand() % 3;      // which function to use?\n    \n    // apply transformation\n    x = cff(0, r) * pts(t-1, 0) + cff(1, r) * pts(t-1, 1) + cff(2, r);\n    y = cff(3, r) * pts(t-1, 0) + cff(4, r) * pts(t-1, 1) + cff(5, r);\n    z = cff(6, r) * pts(t-1, 0) + cff(7, r) * pts(t-1, 1) + cff(8, r);\n    \n    // apply function\n    if(f == 0) {\n      s = pow(x*x + y*y + z*z, 1/3);\n      x = x + s;\n      y = y + s;\n      z = z + s;\n    } else if(f == 1) {\n      x = sin(x);\n      y = sin(y);\n      z = sin(z);\n    } else {\n      x = 2 * sin(x);\n      y = 2 * sin(y);\n      z = 2 * sin(z);\n    }\n    \n    // store new point\n    pts(t, 0) = x;\n    pts(t, 1) = y;\n    pts(t, 2) = (z + pts(t-1, 2))/2;\n  }\n  return pts;\n}\n\nWhen sourced from R in the “right” way, this will create a function unboxer_rcpp() that I can call from R. And when I say “sourced” from R what I really mean is if I did this:\n\nRcpp::sourceCpp(file = \"unbox-fast.cpp\")\n\nIf you’ve used Rcpp, this should seem familiar.\nIf you haven’t used Rcpp and are trying to make up your mind if it is worth the effort to learn, well, I’ll offer this comparison. Here’s the difference in speed for generating a million data points in the original system unbox_base(), compared to the C++ implementation unbox_rcpp():\n\ntic(); set.seed(999); dat <- unboxer_base(mil, layers = 2); toc()\ntic(); set.seed(999); dat <- unboxer_rcpp(mil, layers = 2); toc() \n\n6.677 sec elapsed\n0.044 sec elapsed\n\n\nNot too bad, really :)\nWhen written in C++ we can generate 10 million data points extremely quickly. So much so that it’s outrageously fast to do it three times with different seeds and different numbers of layers:\n\ntic()\nset.seed(123); dat1 <- unboxer_rcpp(10 * mil, layers = 2) \nset.seed(101); dat2 <- unboxer_rcpp(10 * mil, layers = 5) \nset.seed(420); dat3 <- unboxer_rcpp(10 * mil, layers = 9) \ntoc()\n\n1.408 sec elapsed\n\n\n\n\n\n\n\n\nExercise\n\n\n\nThe C++ code for this system is included in the unbox-fast.cpp script, and the code calling it from R to test the timing is included as the unbox-fast-test.R script.\n\n\nTransforming the data into plots, on the other hand, is a little slower. At this point the rendering code is the part that is causing slowness:\n\ntic()\ndat1 |> unbox_art(seed = 123, size = .2)\ndat2 |> unbox_art(seed = 101, size = .2)\ndat3 |> unbox_art(seed = 420, size = .2)\ntoc()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n97.038 sec elapsed\n\n\n\n\nHm. About 1.5 seconds to generate the data, about 100 seconds to produce the plots. That’s a little unfortunate. Perhaps we can speed that up too? After all, ggplot2 has a lot of bells and whistles that we aren’t using in this plot. Maybe we can sidestep the issue…"
  },
  {
    "objectID": "day-2/session-1/index.html#even-faster-chaos-with-raster-representation",
    "href": "day-2/session-1/index.html#even-faster-chaos-with-raster-representation",
    "title": "ITERATED FUNCTION SYSTEMS",
    "section": "Even faster chaos with raster representation",
    "text": "Even faster chaos with raster representation\nBack in the era when I held an academic appointment, one of my research topics used to be human mental representation. When people have to make judgments, choices, or reason about something unfamiliar, we rely on our knowledge of the world to guide us. We have rich, structured knowledge from our past experience that we can bring to bear on new situations, which is super useful because in addition to being fabulous and insanely complicated things, neurons are slow and squishy things relative to machines. Honestly it’s a bit of a surprise that we can compute anything with these things, and borderline miraculous that we manage to think clever thoughts using them.\nAll of this is in service of a really basic comment: if your computing machine doesn’t store data in a sensible format, you’re going to find it really hard to do anything useful. But the converse is also true… if you represent information in the right way, you’ll be able to accomplish a lot. Over and over again, across a lot of different problems I used to study, I’d see a consistent pattern: people make sensible choices when we’re given information structured in the “right” way. But if you present the same information a different and counterintuitive way, people don’t know what to do with it and they make insane choices. As a psychological researcher, it’s really easy to design studies that make people look stupid, and equally easy to design studies that make people look smart. It’s almost criminal easy to “rig” the results of a study this way.\nAnyway.\nMy point here is that machines are kind of the same. If you want your image rendering to go faster, well, maybe you should store the data in a format that mirrors the output you want? I mean, at this point we’re storing a data frame with 10 millions coordinates, and then plotting circles in an abstract canvas that ggplot2 constructs with the help of the grid graphics system, and then… aren’t you tired already?\nIf you want a bitmap that stores pixel values at the end of your generative process, why not start with the data in exactly the same format at the beginning? Don’t draw circles-as-polygons-around-a-coordinate. Just store the damned pixel values from the outset.\nOkay, so here’s a slight reimagining of our Rcpp function that does exactly that. We store a matrix representing the bitmap from the very beginning. The output of this unboxer_grid() function is a square matrix with the number of rows and columns determined by the pixels input:\n\n\n\n\n#include <Rcpp.h>\n#include <iostream>\nusing namespace Rcpp;\nusing namespace std;\n\n// [[Rcpp::export]]\nNumericMatrix unboxer_grid(int iterations, \n                           int layers,\n                           int pixels, \n                           double border) {\n  \n  // variables\n  NumericMatrix image(pixels, pixels); \n  NumericMatrix cff(9, layers);\n  int r, c, f, x_ind, y_ind;\n  double x, y, z, s;\n  \n  // set image matrix to zeros\n  for(int r = 0; r < pixels; r++) {\n    for(int c = 0; c < pixels; c++) {\n      image(c, r) = 0;\n    }\n  }\n  \n  // coefficients\n  for(int i = 0; i < 9; i++) {\n    for(int j = 0; j < layers; j++) {\n      cff(i,j) = R::runif(-1,1);\n    }\n  }\n  \n  // values for initial state\n  double x_old = R::runif(-1, 1);\n  double y_old = R::runif(-1, 1);\n  double z_old = R::runif(-1, 1);\n  \n  // accumulate\n  for(int t = 1; t < iterations; t++) {\n    r = rand() % layers; // which transform to use?\n    f = rand() % 3;      // which function to use?\n    \n    // apply transformation\n    x = cff(0, r) * x_old + cff(1, r) * y_old + cff(2, r);\n    y = cff(3, r) * x_old + cff(4, r) * y_old + cff(5, r);\n    z = cff(6, r) * x_old + cff(7, r) * y_old + cff(8, r);\n    \n    // apply function\n    if(f == 0) {\n      s = pow(x*x + y*y + z*z, 1/3);\n      x = x + s;\n      y = y + s;\n      z = abs(z + s);\n    } else if(f == 1) {\n      x = sin(x);\n      y = sin(y);\n      z = sin(z) + 1;\n    } else {\n      x = 2 * sin(x);\n      y = 2 * sin(y);\n      z = 2 * (sin(z) + 1);\n    }\n    \n    // compute indices to be updated\n    x_ind = int (x * pixels / (2 * border)) + pixels / 2;\n    y_ind = int (y * pixels / (2 * border)) + pixels / 2;\n    \n    // store results if they fall within the range\n    if(x_ind >= 0 & x_ind < pixels) {\n      if(y_ind >= 0 & y_ind < pixels) {\n        image(x_ind, y_ind) = z;\n      }\n    }\n    \n    // move new to old\n    x_old = x;\n    y_old = y;\n    z_old = (z + z_old) / 2; \n  }\n  return image;\n}\n\nFrom a data generation perspective, there’s really not much difference between this version and the last one. They’re both fast. The C++ code to generate the image in a bitmap format isn’t faster or slower than the C++ code we wrote last time:\n\ntic()\nset.seed(123); mat1 <- unboxer_grid(10 * mil, 2, 1000, 4) \nset.seed(101); mat2 <- unboxer_grid(10 * mil, 5, 1000, 4) \nset.seed(420); mat3 <- unboxer_grid(10 * mil, 9, 1000, 4)\ntoc()\n\n1.127 sec elapsed\n\n\nAh, but now look what happens when we generate an image from the data. Originally we were working with ggplot2, and we were forcing it to convert a large data frame to an image in a very very painful way. This time around, the data is already in the right format. It’s a bitmap that we can pass to image(). No heavy lifting required!\n\nraster_art <- function(mat, seed = NULL, trim = .001) {\n  \n  zlim <- quantile(mat, c(trim, 1 - trim))\n  mat[mat < zlim[1]] <- zlim[1]\n  mat[mat > zlim[2]] <- zlim[2]\n  \n  op <- par(mar = c(0, 0, 0, 0))\n  image(\n    z = mat, \n    axes = FALSE, \n    asp = 1, \n    useRaster = TRUE, \n    col = sample_canva2(seed, n = 256)\n  )\n  par(op)\n}\n\ntic()\nraster_art(mat1, seed = 123)\nraster_art(mat2, seed = 101)\nraster_art(mat3, seed = 420)\ntoc()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.407 sec elapsed\n\n\n\n\nOkay fine, this new version doesn’t handle shading in precisely the same way the original version did, but it’s still very pretty – and it’s soooooo much faster!\nHow fast is it? Fast enough that I’m perfectly willing to generate an image by playing the chaos game for 100 million iterations. Hell, it’s fast enough that I’ll generate six of them:\n\npretty_boxes <- function(\n    seed,\n    iterations = 100000000, \n    layers = 5, \n    pixels = 4000, \n    background = \"black\",\n    border = 4,\n    trim = .001\n) {\n  \n  set.seed(seed)\n  \n  mat <- unboxer_grid(\n    iterations = iterations, \n    layers = layers, \n    pixels = pixels, \n    border = border\n  )\n  \n  shades <- c(background, sample_canva2(seed, n = 1023))\n  \n  zlim <- quantile(mat, c(trim, 1 - trim))\n  mat[mat < zlim[1]] <- zlim[1]\n  mat[mat > zlim[2]] <- zlim[2]\n  \n  op <- par(mar = c(0, 0, 0, 0))\n  image(\n    z = mat, \n    axes = FALSE, \n    asp = 1, \n    useRaster = TRUE, \n    col = shades\n  )\n  par(op)\n}\n\ntic()\npretty_boxes(286)\npretty_boxes(380)\npretty_boxes(100)\ntoc()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n21.296 sec elapsed\n\n\n\n\n\ntic()\npretty_boxes(222)\npretty_boxes(567)\npretty_boxes(890)\ntoc() \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n21.665 sec elapsed\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nThe C++ code to generate the data for this system is included in the unbox-grid.cpp script, and plotting code is in the pretty-boxes.R script."
  },
  {
    "objectID": "day-2/session-2/index.html",
    "href": "day-2/session-2/index.html",
    "title": "TILES AND TESSELATIONS",
    "section": "",
    "text": "library(dplyr)\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(ggforce)\nlibrary(deldir)\nlibrary(ggthemes)\nlibrary(voronoise)\nlibrary(tictoc)\nlibrary(ambient)\nlibrary(purrr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(truchet)\nlibrary(sf)"
  },
  {
    "objectID": "day-2/session-2/index.html#rectangle-subdivision",
    "href": "day-2/session-2/index.html#rectangle-subdivision",
    "title": "TILES AND TESSELATIONS",
    "section": "Rectangle subdivision",
    "text": "Rectangle subdivision\nOne of my favourite generative artists in the R community is Ijeamaka Anyene, partly because she’s fabulous but also partly because her approach is so different to mine and she makes things I’d never think to try. She has a talent for designing colourful pieces in a minimalist, geometric style. Minimalism in art is not something I’m good at: I have a habit of overcomplicating my pieces! However, in this first section I’m going to resist the temptation to add complexity, and build a system inspired by Ijeamaka’s recursive rectangle subdivision art. She has a blog post on her approach, by the way.\nRecursive rectangle subdivisions come up a lot in real life. Suppose you have a parcel of land and want to divide it in two parts A and B. In doing so you create a boundary. Later, land unit A wants to divide: this adds a new boundary, splitting A into A1 and A2, but leaving unit B untouched. If this process repeats often enough, you end up with subdivisions that have a very recognisable structure. Here’s a subdivision depicting a 1939 land use survey map for a part of the San Fernando valley in Los Angeles\n\n\n\n\n\n\n\n\n\nLet’s design a generative art system that mimics this process. Suppose we have some data frame blocks where each row represents one rectangular block, and one of the columns it stores is the area of that rectangle. Now imagine that our subdivision process deliberately targets larger blocks: the probability of choosing the a block for subdivision is proportional to its area. The choose_rectangle() function below takes the blocks data frame as input, and randomly selects a row with probability proportional to blocks$area. It returns the row number for the selected rectangle:\n\nchoose_rectangle <- function(blocks) {\n  sample(nrow(blocks), 1, prob = blocks$area)\n}\n\nFor this system we assume that you can only subdivide a rectangle in one of two ways: horizontally, or vertically. We aren’t going to allow diagonal lines or anything that would produce other kinds of polygons. The input to a subdivision is a rectangle, and the output should be two rectangles.\nIf we’re going to do that, we need to select a “break point”. The choose_break() function will do that for us. It takes a lower and upper value as input, and returns a value (expressed as the distance from the lower boundary) specifying where the break is inserted:\n\nchoose_break <- function(lower, upper) {\n  round((upper - lower) * runif(1))\n}\n\nNotice that I’ve called round() here to ensure that the outputs will always be integer value. As a consequence, all of our subdivisions will line up on a grid of some kind: that comes in handy later if, for example, we want to plot the result as a bitmap or a raster object.\nNext, we need a function that can subdivide a rectangle! For the moment, let’s assume that we’re splitting horizontally, so in a moment we’ll write a function called split_rectangle_x() to do this for us. It’s going to take a rectangle as the main argument, which is presumably going to be a tibble that contains columns that define a rectangle. To make life a little simpler, here’s a convenience function create_rectangles() that creates this tibble for us:\n\ncreate_rectangles <- function(left, right, bottom, top, value) {\n  tibble(\n    left = left,\n    right = right,\n    bottom = bottom,\n    top = top,\n    width = right - left,\n    height = top - bottom,\n    area = width * height,\n    value = value\n  )\n}\n\nNote that this function can create multiple rectangles. It doesn’t check to see if the rectangles overlap, though. If I wanted to write rigorous code I would probably prevent it from allowing rectangles to overlap, but I’m not being super rigorous here. It’s not production code!\nAnyway, here are a couple of rectangles that represent a vertical split, where one of them sits above the other:\n\nrect <- create_rectangles(\n  left = 1, \n  right = 10, \n  bottom = c(1, 4), \n  top = c(4, 10),\n  value = 1:2\n)\nrect\n\n# A tibble: 2 × 8\n   left right bottom   top width height  area value\n  <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <int>\n1     1    10      1     4     9      3    27     1\n2     1    10      4    10     9      6    54     2\n\n\nNow we can write our horizontal subdivision function, split_rectangle_x(), and it’s vertical counterpart split_rectangle_y(). Each of these takes a single rectangle as input, calls choose_break() to determine where the break point should be, and then creates two new rectangles that will replace the old one. When called, they’ll automatically recalculate the width, height, and areas for both rectangles. The value of the first rectangle (the one to the left or on the lower side) remains unchanged, and and the new_value argument is used to assign a value to the second rectangle:\n\nsplit_rectangle_x <- function(rectangle, new_value) {\n  with(rectangle, {\n    split <- choose_break(left, right)\n    new_left  <- c(left, left + split)\n    new_right <- c(left + split, right)\n    new_value <- c(value, new_value)\n    create_rectangles(new_left, new_right, bottom, top, new_value)\n  })\n}\n\n\nsplit_rectangle_y <- function(rectangle, new_value) {\n  with(rectangle, {\n    split <- choose_break(bottom, top)\n    new_bottom <- c(bottom, bottom + split)\n    new_top <- c(bottom + split, top)\n    new_value <- c(value, new_value)\n    create_rectangles(left, right, new_bottom, new_top, new_value)\n  })\n}\n\nWhile we are here, we can write a split_rectangle() function that randomly decides whether to split horizontally or vertically, and then calls the relevant function to do the splitting:\n\nsplit_rectangle <- function(rectangle, value) {\n  if(runif(1) < .5) {\n    return(split_rectangle_x(rectangle, value))\n  }\n  split_rectangle_y(rectangle, value)\n}\n\nHere it is in action:\n\nset.seed(1)\nsplit_rectangle(rectangle = rect[1, ], value = 3)\n\n# A tibble: 2 × 8\n   left right bottom   top width height  area value\n  <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     1     4      1     4     3      3     9     1\n2     4    10      1     4     6      3    18     3\n\n\nNotice that it is possible to create a block with zero area. That’s okay: that block will never be selected for later subdivision. We could filter out all zero-area rectangles if we wanted to, but I’m too lazy to bother!\nNow we are in a position to define a function called split_block() that takes block, a tibble of one or more rectangles as input, selects one to be subdivided using choose_rectangle(), and then splits it with split_rectangle(). The old, now-subdivided rectangle is removed from the block, the two new ones are added, and the updated block of rectangles is returned:\n\nsplit_block <- function(blocks, value) {\n  old <- choose_rectangle(blocks) \n  new <- split_rectangle(blocks[old, ], value)\n  bind_rows(blocks[-old, ], new)\n}\n\nHere it is at work:\n\nsplit_block(rect, value = 3)\n\n# A tibble: 3 × 8\n   left right bottom   top width height  area value\n  <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     1    10      1     4     9      3    27     1\n2     1    10      4     5     9      1     9     2\n3     1    10      5    10     9      5    45     3\n\n\nNow that we have a create_rectangles() function that can generate a new rectangle and a split_block() function that can pick one rectangle and split it, we can write subdivision() function quite succinctly. We repeatedly apply the split_block() function until it has created enough splits for us. I could write this as a loop, but it feels more elegant to me to use the reduce() function from the purrr package to do this:\n\nsubdivision <- function(ncol = 1000, \n                        nrow = 1000, \n                        nsplits = 50, \n                        seed = NULL) {\n  \n  if(!is.null(seed)) set.seed(seed)\n  blocks <- create_rectangles(\n    left = 1, \n    right = ncol, \n    bottom = 1, \n    top = nrow, \n    value = 0\n  )\n  reduce(1:nsplits, split_block, .init = blocks)\n}\n\nsubdivision(nsplits = 5)\n\n# A tibble: 6 × 8\n   left right bottom   top width height   area value\n  <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>\n1     1  1000    661  1000   999    339 338661     1\n2     1   207      1   661   206    660 135960     0\n3   207  1000    255   661   793    406 321958     3\n4   207   776      1   255   569    254 144526     2\n5   776   950      1   255   174    254  44196     4\n6   950  1000      1   255    50    254  12700     5\n\n\nAs you can see, in this version of the system I’ve arranged it so that the value column represents the iteration number upon which the corresponding rectangle was created.\nFinally we get to the part where we make art! The develop() function below uses geom_rect() to draw the rectangles, mapping the value to the fill aesthetic:\n\ndevelop <- function(div, seed = NULL) {\n  \n  div |> \n    ggplot(aes(\n      xmin = left, \n      xmax = right, \n      ymin = bottom, \n      ymax = top,\n      fill = value\n    )) +\n    geom_rect(\n      colour = \"#ffffff\", \n      size = 3,\n      show.legend = FALSE\n    ) +\n    scale_fill_gradientn(\n      colours = sample_canva2(seed)\n    ) +\n    coord_equal() +\n    theme_void() +\n    theme(\n      plot.background = element_rect(\n        fill = \"#ffffff\"\n      )\n    ) \n}\n\nsubdivision(seed = 1) |> develop() \n\n\n\n\n\n\n\n\nThe uneven spacing here is not accidental. Because the rectangles are plotted with a thick white border, and plotted against a white background, very thin rectangles are invisible. That leads to a slightly irregular pattern among the visible rectangles. I quite like it!\nHere are a few more outputs from the system:\n\nsubdivision(nsplits = 100, seed = 123) |> develop()\nsubdivision(nsplits = 200, seed = 102) |> develop()\nsubdivision(nsplits = 500, seed = 103) |> develop()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCode for this system is included in the subdivision.R script."
  },
  {
    "objectID": "day-2/session-2/index.html#melancholia",
    "href": "day-2/session-2/index.html#melancholia",
    "title": "TILES AND TESSELATIONS",
    "section": "Melancholia",
    "text": "Melancholia\n\nboxx <- function(left, right, bottom, top, width, \n                 height, area, value, nshades = 100) {\n  \n  set.seed(value)\n  fractals <- list(billow, fbm, ridged)\n  generators <- list(gen_simplex, gen_worley)\n  \n  long_grid(\n    x = left:right, \n    y = bottom:top, \n  ) |>\n    mutate(\n      fill = 10 * value + fracture(\n        x = x,\n        y = y,\n        noise = sample(generators, 1)[[1]],\n        fractal = sample(fractals, 1)[[1]],\n        octaves = sample(10, 1),\n        frequency = sample(10, 1) / 100,\n        value = \"distance2\"\n      ) |>\n        normalise(to = c(1, nshades)) |> \n        round()\n    )\n}\n\ndraw <- function(dat, palette) {\n  dat |>\n    ggplot(aes(x, y, fill = fill)) +\n    geom_tile(show.legend = FALSE) +\n    scale_x_continuous(expand = c(0, 0), breaks = NULL) +\n    scale_y_continuous(expand = c(0, 0), breaks = NULL) +\n    scale_size_identity() +\n    scale_colour_gradientn(colours = palette) +\n    scale_fill_gradientn(colours = palette) +\n    theme_void() +\n    theme(plot.background = element_rect(fill = \"#222222\")) \n}\n\nmelancholia <- function(seed) {\n  base <- subdivision(100, 100, 30, seed) \n  dat <- pmap_dfr(base, boxx) \n  draw(dat, palette = sample_canva2(seed))\n}\n\nmelancholia(1302)\n\n\n\n\n\n\n\n\n\nmelancholia(9999)\nmelancholia(1066)\nmelancholia(1969)"
  },
  {
    "objectID": "day-2/session-2/index.html#voronoi-tesselation",
    "href": "day-2/session-2/index.html#voronoi-tesselation",
    "title": "TILES AND TESSELATIONS",
    "section": "Voronoi tesselation",
    "text": "Voronoi tesselation\nLet’s switch gears a little. So far we’ve only looked at rectangular tilings, but there are many other ways to tile a two dimensional plane. One method for constructing an irregular tiling – one that generative artists are especially fond of – is to generate a collection of points and then computing the Voronoi tesselation (also known as a Voronoi diagram) of those points. Wikipedia definitions are, once again, helpful:\n\nA Voronoi diagram is a partition of a plane into regions close to each of a given set of objects. In the simplest case, these objects are just finitely many points in the plane (called seeds, sites, or generators). For each seed there is a corresponding region, called a Voronoi cell, consisting of all points of the plane closer to that seed than to any other.\n\nExtremely conveniently for our purposes, the ggforce package provides two handy geom functions – geom_voronoi_segment() and geom_voronoi_tile() – that plot the Voronoi tesselation for a set of points. All you have to do as the user is specify the x and y aesthetics (corresponding to the coordinate values of the points), and ggplot2 will do all the work for you. Let’s see what we can do using these tools!\nIn the beginning there were points…\n\nset.seed(61)\ndat <- tibble(\n  x = runif(20),\n  y = runif(20),\n  val = runif(20)\n)\n\npic <- ggplot(dat, aes(x, y, fill = val)) +\n  coord_equal(xlim = c(-.3, 1.3), ylim = c(-.3, 1.3)) +\n  guides(fill = guide_none()) +\n  theme_void()\n\npic + geom_point(colour = \"white\", size = 3)\n\n\n\n\n\n\n\n\nThe points themselves are not very artistically impressive, but we can make something more interesting if we add the Voronoi tesselation. The minimal way to do this is with geom_voronoi_segment()\n\npic + \n  geom_voronoi_segment(colour = \"white\") + \n  geom_point(colour = \"white\", size = 3)\n\n\n\n\n\n\n\n\nWe can already see the beginnings of something pleasing. I mean, if I’m being honest this is already quite pretty in a minimalist way but – as I keep saying – I have an urge to tinker and see what elaborations we can add. First, let’s switch from geom_voronoi_segment() to geom_voronoi_tile():\n\npic + \n  geom_voronoi_tile(colour = \"white\") + \n  geom_point(colour = \"white\", size = 3)\n\n\n\n\n\n\n\n\nSetting the max.radius argument prevents any tile extending beyond a fixed distance from the point generating the tile, giving the image as a whole a “bubbly” look:\n\npic + \n  geom_voronoi_tile(colour = \"white\", max.radius = .2) + \n  geom_point(colour = \"white\", size = 3)\n\n\n\n\n\n\n\n\nHm. Those sharp corners between tiles aren’t the prettiest thing I’ve ever seen. Let’s round those corners a little bit, shall we? The radius argument lets us do that:\n\npic + \n  geom_voronoi_tile(\n    colour = \"white\", \n    max.radius = .2, \n    radius = .02 \n  ) + \n  geom_point(colour = \"white\", size = 3)\n\n\n\n\n\n\n\n\nNext, let’s shrink all the tiles a tiny bit to create small gaps between adjacent tiles:\n\npic + \n  geom_voronoi_tile(\n    colour = \"white\", \n    max.radius = .2, \n    radius = .02,\n    expand = -.005\n  ) + \n  geom_point(colour = \"white\", size = 3)\n\n\n\n\n\n\n\n\nLet’s remove the points themselves, leaving only the rounded tiles:\n\npic + \n  geom_voronoi_tile(\n    colour = \"white\", \n    max.radius = .2, \n    radius = .02,\n    expand = -.005\n  )\n\n\n\n\n\n\n\n\nFinally, we’ll create another tiling and use it as a background texture:\n\nbg_dat <- tibble(\n  x = runif(500, min = -.5, max = 1.5),\n  y = runif(500, min = -.5, max = 1.5)\n)\npic + \n  geom_voronoi_tile(\n    data = bg_dat,\n    fill = \"#333333\", \n    radius = .01,\n    expand = -.0025\n  ) +\n  geom_voronoi_tile(\n    colour = \"white\", \n    max.radius = .2, \n    radius = .02,\n    expand = -.005\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nA script reproducing this piece is included in the voronoi-tiles.R file"
  },
  {
    "objectID": "day-2/session-2/index.html#truchet-tiles",
    "href": "day-2/session-2/index.html#truchet-tiles",
    "title": "TILES AND TESSELATIONS",
    "section": "Truchet tiles",
    "text": "Truchet tiles\nOne final topic to mention before: truchet tiles. Truchet tiles are square tiles decorated with asymmetric patterns, designed so that whenever you lay them out randomly, the patterns will connect up in aesthetically pleasing ways. To be honest, I’ve not explore them much myself but Antonio Páez has written the truchet package that you can use to play with these. It’s not currently on CRAN, but you can install from GitHub with:\nremotes::install_github(\"paezha/truchet\")\nThe basic idea in the truchet package is to represent the patterns compactly as a geometry column. If you’re familiar with the sf package this sort of output will be familiar to you:\n\nset.seed(123)\nmosaic <- st_truchet_ms(\n  tiles = c(\"dr\", \"tn\", \"ane\"), \n  p1 = 0.2, # scale 1 \n  p2 = 0.6, # scale 2\n  p3 = 0.2, # scale 3\n  xlim = c(1, 6),\n  ylim = c(1, 6)\n)\nmosaic\n\nSimple feature collection with 797 features and 1 field\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 0.1666667 ymin: 0.1666667 xmax: 6.833333 ymax: 6.833333\nCRS:           NA\nFirst 10 features:\n   color                       geometry\n1      1 MULTIPOLYGON (((0.8333333 5...\n2      2 POLYGON ((0.4956387 6.16655...\n3      2 POLYGON ((0.8340757 5.53053...\n4      1 MULTIPOLYGON (((2.833333 2....\n5      2 POLYGON ((2.495639 3.166552...\n6      2 POLYGON ((2.834076 2.530531...\n7      1 MULTIPOLYGON (((1.833333 2....\n8      2 MULTIPOLYGON (((2.166667 2....\n9      1 POLYGON ((2.5 0.8333333, 2....\n10     2 POLYGON ((2.833333 0.5, 2.8...\n\n\nIf you’re not familiar, the key things to note are that the geometry column stores the pattern as a polygon (or collection of polygons), and that geom_sf() understands this geometry column. So you can use code like this to plot your truchet tiling:\n\nmosaic |> \n  ggplot(aes(fill = color)) +\n  geom_sf(color = NA, show.legend = FALSE) + \n  scale_fill_gradientn(colours = c(\"#222222\", \"#ffffff\")) + \n  theme_void()\n\n\n\n\n\n\n\n\nIn this example you’ll notice that I don’t actually specify a mapping for geometry. That’s a little unusual for ggplot2, but it is standard to name the column containing a “simple features geometry” as geometry, so geom_sf() will look for a column by that name.\nThat’s about all I wanted to mention about the truchet package. It makes pretty things and you can check out the package website for more information :)\n\nset.seed(123)\nst_truchet_ss(\n  tiles = c(\n    \"silk_1\", \"silk_2\", \n    \"rainbow_1\", \"rainbow_2\",\n    \"cloud_1\", \"cloud_2\"\n  ),\n  xlim = c(1, 9),\n  ylim = c(1, 6)\n) |>\n  ggplot() +\n  geom_sf(colour = \"white\") +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nExample code for truchet tiles is included in the truchet-example.R script."
  },
  {
    "objectID": "day-2/session-3/index.html",
    "href": "day-2/session-3/index.html",
    "title": "PIXEL FILTERS",
    "section": "",
    "text": "library(dplyr)\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(ggforce)\nlibrary(ggfx)\nlibrary(flametree)\nlibrary(ambient)\nThe last technical topic I want to cover in this workshop is pixel filters, and specifically the ggfx package which makes it relatively easy to use them in conjunction with ggplot2. Phrased in the most general terms, a filter is any function that takes one image as input and returns a new (presumably modified!) image as output. As an example, think about how Instagram filters work: the original photo is used as the input, and the modified one is returned as output. This filtering takes place at the pixel level, so it’s not immediately obvious how we could do this with ggplot2. The way that the ggfx package handles this is to render render the image (or part of the image) off screen to obtain a representation that can be filtered. The filter is applied to that rendered image and then, when the final plot is constructed, the filtered versions are included in the final plot rather than the original ones.\nIn this session I’ll provide an introduction to ggfx. The API for ggfx takes a little while to wrap your head around, but once you’ve got a handle on it, it turns out to be a very powerful tool for generative art in R."
  },
  {
    "objectID": "day-2/session-2/index.html#mosaica",
    "href": "day-2/session-2/index.html#mosaica",
    "title": "TILES AND TESSELATIONS",
    "section": "Mosaica",
    "text": "Mosaica\nRemember earlier when I said I have this compulsive tendency to make my generative art systems unnecessarily elaborate? I was not lying. Now that I’ve created this simple and clean subdivision() system my first instinct is to use it as the basis for something more complicated. The fill_rectangle() function below takes a single rectangle as input, divides it into a grid of squares with edge length 1, and then assigns each of those squares a fill value generated with a randomly sampled fractal (using the ambient package to do the work):\n\nfill_rectangle <- function(left, right, bottom, top, width, \n                           height, area, value, nshades = 100) {\n  \n  set.seed(value)\n  fractals <- list(billow, fbm, ridged)\n  generators <- list(gen_simplex, gen_perlin, gen_worley)\n  \n  expand_grid(\n    x = left:right, \n    y = bottom:top, \n  ) |>\n    mutate(\n      fill = 10 * value + fracture(\n        x = x * sample(-3:3, 1),\n        y = y * sample(-3:3, 1),\n        noise = sample(generators, 1)[[1]],\n        fractal = sample(fractals, 1)[[1]],\n        octaves = sample(10, 1),\n        frequency = sample(10, 1) / 20,\n        value = \"distance2\"\n      ) |>\n        normalise(to = c(1, nshades)) |> \n        round()\n    )\n}\n\nI’ll also write a draw_mosaic() function that plots a collection of these unit-square sized tiles:\n\ndraw_mosaic <- function(dat, palette) {\n  background <- sample(palette, 1)\n  dat |>\n    ggplot(aes(x, y, fill = fill)) +\n    geom_tile(show.legend = FALSE, colour = background, size = .2) +\n    scale_size_identity() +\n    scale_colour_gradientn(colours = palette) +\n    scale_fill_gradientn(colours = palette) +\n    scale_x_continuous(expand = expansion(add = 5)) +\n    scale_y_continuous(expand = expansion(add = 5)) +\n    coord_equal() +\n    theme_void() +\n    theme(plot.background = element_rect(fill = background)) \n}\n\nWhen combined with the original subdivision() function I can now write a generative art system called mosaica() that uses subdivision() to partition a grid into rectangular units, then applies fill_rectangle() to separate each of these rectangles into unit squares and fill each of these squares with a colour based on a spatial noise pattern generated using ambient. Then it draws a picture:\n\nmosaica <- function(ncol = 60, \n                    nrow = 60, \n                    nsplits = 30, \n                    seed = NULL) {\n  \n  subdivision(ncol, nrow, nsplits, seed) |>\n    pmap_dfr(fill_rectangle) |> \n    slice_sample(prop = .995) |>\n    filter(!is.na(fill)) |>\n    draw_mosaic(palette = sample_canva2(seed))\n}\n\nmosaica(ncol = 200, nrow = 100, nsplits = 200, seed = 1302)\n\n\n\n\n\n\n\n\nIt makes me happy :)\n\nmosaica(seed = 1977)\nmosaica(seed = 2022)\nmosaica(seed = 1969)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmosaica(nrow = 100, seed = 1)\nmosaica(nrow = 100, seed = 2)\nmosaica(nrow = 100, seed = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCode for this system is included in the mosaica.R script."
  },
  {
    "objectID": "day-2/session-2/index.html#voronoi-baroque-style",
    "href": "day-2/session-2/index.html#voronoi-baroque-style",
    "title": "TILES AND TESSELATIONS",
    "section": "Voronoi baroque style",
    "text": "Voronoi baroque style\n\nunboxy <- function(iterations, layers) {\n  \n  coeffs <- array(\n    data = runif(9 * layers, min = -1, max = 1), \n    dim = c(3, 3, layers)\n  )\n  \n  point0 <- matrix(\n    data = runif(3, min = -1, max = 1), \n    nrow = 1,\n    ncol = 3\n  )\n  \n  funs <- list(\n    function(point) point + (sum(point ^ 2)) ^ (1/3),\n    function(point) sin(point),\n    function(point) 2 * sin(point)\n  )\n  \n  update <- function(point, t) {\n    l <- sample(layers, 1)\n    f <- sample(funs, 1)[[1]]\n    z <- point[3]\n    point[3] <- 1\n    point <- f(point %*% coeffs[,,l])\n    point[3] <- (point[3] + z)/2\n    return(point)\n  }\n  \n  points <- accumulate(1:iterations, update, .init = point0)\n  points <- matrix(unlist(points), ncol = 3, byrow = TRUE)\n  points <- as_tibble(as.data.frame(points)) \n  names(points) <- c(\"x\", \"y\", \"c\")\n  return(points)\n}\n\n\nset.seed(1)\ndata <- unboxy(iterations = 1000, layers = 5) \n\nggplot(data, aes(x, y, fill = c)) +\n  geom_voronoi_tile(\n    max.radius = NULL,\n    radius = 0,\n    expand = 0,\n    colour = \"#222222\",\n    size = .2, \n    show.legend = FALSE\n  ) +\n  theme_void() + \n  coord_equal(xlim = c(-3, 3), ylim = c(-3, 3)) + \n  scale_fill_gradientn(colours = sample_canva2()) + \n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0))\n\n\n\n\n\n\n\n\n\nsift <- function(grain = .025) {\n  function(data) {\n    data <- data |>\n      group_by(group) |>\n      mutate(tilesize = (max(x) - min(x)) * (max(y) - min(y))) |>\n      ungroup()\n    data$tilealpha <- .5\n    data$tilealpha[data$tilesize < grain^2] <- 1\n    return(data)\n  }\n}\n\nmake_voronoise_art <- function(data, mapping, perturb, ...) {\n  ggplot(data, mapping) +\n    geom_voronoise(\n      perturb = perturb,\n      ...,\n      show.legend = FALSE\n    ) +\n    theme_void() + \n    coord_equal(xlim = c(-3, 3), ylim = c(-3, 3)) + \n    scale_fill_gradientn(colours = sample_canva2()) + \n    scale_alpha_identity() +\n    scale_x_continuous(expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0))\n}\n\nset.seed(1)\nmake_voronoise_art(\n  data = unboxy(iterations = 10000, layers = 5),\n  mapping = aes(x, y, fill = c, alpha = after_stat(tilealpha)),\n  max.radius = NULL,\n  radius = 0,\n  expand = 0,\n  perturb = sift(.2)\n)\n\n\n\n\n\n\n\n\n\nthat_boxy_style <- function(seed) {\n  set.seed(seed)\n  make_voronoise_art(\n    data = unboxy(iterations = 10000, layers = 5),\n    mapping = aes(x, y, fill = c, alpha = after_stat(tilealpha)),\n    max.radius = NULL,\n    radius = 0,\n    expand = 0,\n    perturb = sift(.2)\n  )\n}\n\nthat_boxy_style(1234)\nthat_boxy_style(4000)\nthat_boxy_style(2468)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(42)\n\nggplot(\n  data = unboxy(10000, 5), \n  mapping = aes(\n    x = x,\n    y = y, \n    fill = c\n  )\n) +\n  geom_voronoise(\n    perturb = function(data) {\n      data |> \n        group_by(group) |>\n        mutate(\n          x = x + runif(1)/10, \n          y = y + runif(1)/10\n        ) |>\n        ungroup()\n    },\n    max.radius = NULL,\n    radius = 0,\n    expand = 0,\n    colour = \"#222222\",\n    size = .2, \n    show.legend = FALSE\n  ) +\n  theme_void() + \n  coord_equal(xlim = c(-3, 3), ylim = c(-3, 3)) + \n  scale_fill_gradientn(colours = sample_canva2()) + \n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  theme(panel.background = element_rect(\n    fill = \"#222222\", colour = \"#222222\"\n  ))"
  },
  {
    "objectID": "day-2/session-2/index.html#an-exercise-in-voronoi-baroque",
    "href": "day-2/session-2/index.html#an-exercise-in-voronoi-baroque",
    "title": "TILES AND TESSELATIONS",
    "section": "An exercise in Voronoi baroque",
    "text": "An exercise in Voronoi baroque\n\nunboxy <- function(iterations, layers) {\n  \n  coeffs <- array(\n    data = runif(9 * layers, min = -1, max = 1), \n    dim = c(3, 3, layers)\n  )\n  \n  point0 <- matrix(\n    data = runif(3, min = -1, max = 1), \n    nrow = 1,\n    ncol = 3\n  )\n  \n  funs <- list(\n    function(point) point + (sum(point ^ 2)) ^ (1/3),\n    function(point) sin(point),\n    function(point) 2 * sin(point)\n  )\n  \n  update <- function(point, t) {\n    l <- sample(layers, 1)\n    f <- sample(funs, 1)[[1]]\n    z <- point[3]\n    point[3] <- 1\n    point <- f(point %*% coeffs[,,l])\n    point[3] <- (point[3] + z)/2\n    return(point)\n  }\n  \n  points <- accumulate(1:iterations, update, .init = point0)\n  points <- matrix(unlist(points), ncol = 3, byrow = TRUE)\n  points <- as_tibble(as.data.frame(points)) \n  names(points) <- c(\"x\", \"y\", \"c\")\n  return(points)\n}\n\n\nset.seed(1)\ndata <- unboxy(iterations = 1000, layers = 5) \n\nggplot(data, aes(x, y, fill = c)) +\n  geom_voronoi_tile(\n    max.radius = NULL,\n    radius = 0,\n    expand = 0,\n    colour = \"#222222\",\n    size = .2, \n    show.legend = FALSE\n  ) +\n  theme_void() + \n  coord_equal(xlim = c(-3, 3), ylim = c(-3, 3)) + \n  scale_fill_gradientn(colours = sample_canva2()) + \n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0))\n\n\n\n\n\n\n\n\n\nsift <- function(grain = .025) {\n  function(data) {\n    data <- data |>\n      group_by(group) |>\n      mutate(tilesize = (max(x) - min(x)) * (max(y) - min(y))) |>\n      ungroup()\n    data$tilealpha <- .5\n    data$tilealpha[data$tilesize < grain^2] <- 1\n    return(data)\n  }\n}\n\nmake_voronoise_art <- function(data, mapping, perturb, ...) {\n  ggplot(data, mapping) +\n    geom_voronoise(\n      perturb = perturb,\n      ...,\n      show.legend = FALSE\n    ) +\n    theme_void() + \n    coord_equal(xlim = c(-3, 3), ylim = c(-3, 3)) + \n    scale_fill_gradientn(colours = sample_canva2()) + \n    scale_alpha_identity() +\n    scale_x_continuous(expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0))\n}\n\nset.seed(1)\nmake_voronoise_art(\n  data = unboxy(iterations = 10000, layers = 5),\n  mapping = aes(x, y, fill = c, alpha = after_stat(tilealpha)),\n  max.radius = NULL,\n  radius = 0,\n  expand = 0,\n  perturb = sift(.2)\n)\n\n\n\n\n\n\n\n\n\nthat_boxy_style <- function(seed) {\n  set.seed(seed)\n  make_voronoise_art(\n    data = unboxy(iterations = 10000, layers = 5),\n    mapping = aes(x, y, fill = c, alpha = after_stat(tilealpha)),\n    max.radius = NULL,\n    radius = 0,\n    expand = 0,\n    perturb = sift(.2)\n  )\n}\n\nthat_boxy_style(1234)\nthat_boxy_style(4000)\nthat_boxy_style(2468)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(42)\n\nggplot(\n  data = unboxy(10000, 5), \n  mapping = aes(\n    x = x,\n    y = y, \n    fill = c\n  )\n) +\n  geom_voronoise(\n    perturb = function(data) {\n      data |> \n        group_by(group) |>\n        mutate(\n          x = x + runif(1)/10, \n          y = y + runif(1)/10\n        ) |>\n        ungroup()\n    },\n    max.radius = NULL,\n    radius = 0,\n    expand = 0,\n    colour = \"#222222\",\n    size = .2, \n    show.legend = FALSE\n  ) +\n  theme_void() + \n  coord_equal(xlim = c(-3, 3), ylim = c(-3, 3)) + \n  scale_fill_gradientn(colours = sample_canva2()) + \n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  theme(panel.background = element_rect(\n    fill = \"#222222\", colour = \"#222222\"\n  ))"
  },
  {
    "objectID": "day-2/session-2/index.html#voronoi-baroque",
    "href": "day-2/session-2/index.html#voronoi-baroque",
    "title": "TILES AND TESSELATIONS",
    "section": "“Voronoi baroque”",
    "text": "“Voronoi baroque”\n\nunboxy <- function(iterations, layers) {\n  \n  coeffs <- array(\n    data = runif(9 * layers, min = -1, max = 1), \n    dim = c(3, 3, layers)\n  )\n  \n  point0 <- matrix(\n    data = runif(3, min = -1, max = 1), \n    nrow = 1,\n    ncol = 3\n  )\n  \n  funs <- list(\n    function(point) point + (sum(point ^ 2)) ^ (1/3),\n    function(point) sin(point),\n    function(point) 2 * sin(point)\n  )\n  \n  update <- function(point, t) {\n    l <- sample(layers, 1)\n    f <- sample(funs, 1)[[1]]\n    z <- point[3]\n    point[3] <- 1\n    point <- f(point %*% coeffs[,,l])\n    point[3] <- (point[3] + z)/2\n    return(point)\n  }\n  \n  points <- accumulate(1:iterations, update, .init = point0)\n  points <- matrix(unlist(points), ncol = 3, byrow = TRUE)\n  points <- as_tibble(as.data.frame(points)) \n  names(points) <- c(\"x\", \"y\", \"c\")\n  return(points)\n}\n\n\nset.seed(1)\ndata <- unboxy(iterations = 1000, layers = 5) \n\nggplot(data, aes(x, y, fill = c)) +\n  geom_voronoi_tile(\n    max.radius = NULL,\n    radius = 0,\n    expand = 0,\n    colour = \"#222222\",\n    size = .2, \n    show.legend = FALSE\n  ) +\n  theme_void() + \n  coord_equal(xlim = c(-3, 3), ylim = c(-3, 3)) + \n  scale_fill_gradientn(colours = sample_canva2()) + \n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0))\n\n\n\n\n\n\n\n\n\nsift <- function(grain = .025) {\n  function(data) {\n    data <- data |>\n      group_by(group) |>\n      mutate(tilesize = (max(x) - min(x)) * (max(y) - min(y))) |>\n      ungroup()\n    data$tilealpha <- .5\n    data$tilealpha[data$tilesize < grain^2] <- 1\n    return(data)\n  }\n}\n\nmake_voronoise_art <- function(data, mapping, perturb, ...) {\n  ggplot(data, mapping) +\n    geom_voronoise(\n      perturb = perturb,\n      ...,\n      show.legend = FALSE\n    ) +\n    theme_void() + \n    coord_equal(xlim = c(-3, 3), ylim = c(-3, 3)) + \n    scale_fill_gradientn(colours = sample_canva2()) + \n    scale_alpha_identity() +\n    scale_x_continuous(expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0))\n}\n\nset.seed(1)\nmake_voronoise_art(\n  data = unboxy(iterations = 10000, layers = 5),\n  mapping = aes(x, y, fill = c, alpha = after_stat(tilealpha)),\n  max.radius = NULL,\n  radius = 0,\n  expand = 0,\n  perturb = sift(.2)\n)\n\n\n\n\n\n\n\n\n\nthat_boxy_style <- function(seed) {\n  set.seed(seed)\n  make_voronoise_art(\n    data = unboxy(iterations = 10000, layers = 5),\n    mapping = aes(x, y, fill = c, alpha = after_stat(tilealpha)),\n    max.radius = NULL,\n    radius = 0,\n    expand = 0,\n    perturb = sift(.2)\n  )\n}\n\nthat_boxy_style(1234)\nthat_boxy_style(4000)\nthat_boxy_style(2468)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(42)\n\nggplot(\n  data = unboxy(10000, 5), \n  mapping = aes(\n    x = x,\n    y = y, \n    fill = c\n  )\n) +\n  geom_voronoise(\n    perturb = function(data) {\n      data |> \n        group_by(group) |>\n        mutate(\n          x = x + runif(1)/10, \n          y = y + runif(1)/10\n        ) |>\n        ungroup()\n    },\n    max.radius = NULL,\n    radius = 0,\n    expand = 0,\n    colour = \"#222222\",\n    size = .2, \n    show.legend = FALSE\n  ) +\n  theme_void() + \n  coord_equal(xlim = c(-3, 3), ylim = c(-3, 3)) + \n  scale_fill_gradientn(colours = sample_canva2()) + \n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  theme(panel.background = element_rect(\n    fill = \"#222222\", colour = \"#222222\"\n  ))"
  },
  {
    "objectID": "day-2/session-2/index.html#studies-in-voronoi-baroque",
    "href": "day-2/session-2/index.html#studies-in-voronoi-baroque",
    "title": "TILES AND TESSELATIONS",
    "section": "Studies in Voronoi baroque",
    "text": "Studies in Voronoi baroque\nWhen I first started playing around with Voronoi tesselations the pieces I made looked a lot like the worked example: the Voronoise series I posted on my art site contains pieces that look like the one above, generated from random collections of points. What I started realising a little later is that if you feed a structured set of points into your Voronoi tesselations, you can create some very elaborate patterns. I’ve played around with this idea in a few series (my favourite so far is Sadists Kiss).\nI’ll illustrate the approach by reusing an earlier system. The unboxy() function shown below reimplements the “unboxing” system that I talked about in the section on iterated function systems:\n\nunboxy <- function(iterations, layers) {\n  \n  coeffs <- array(\n    data = runif(9 * layers, min = -1, max = 1), \n    dim = c(3, 3, layers)\n  )\n  \n  point0 <- matrix(\n    data = runif(3, min = -1, max = 1), \n    nrow = 1,\n    ncol = 3\n  )\n  \n  funs <- list(\n    function(point) point + (sum(point ^ 2)) ^ (1/3),\n    function(point) sin(point),\n    function(point) 2 * sin(point)\n  )\n  \n  update <- function(point, t) {\n    l <- sample(layers, 1)\n    f <- sample(funs, 1)[[1]]\n    z <- point[3]\n    point[3] <- 1\n    point <- f(point %*% coeffs[,,l])\n    point[3] <- (point[3] + z)/2\n    return(point)\n  }\n  \n  points <- accumulate(1:iterations, update, .init = point0)\n  points <- matrix(unlist(points), ncol = 3, byrow = TRUE)\n  points <- as_tibble(as.data.frame(points)) \n  names(points) <- c(\"x\", \"y\", \"val\")\n  return(points)\n}\n\n\nset.seed(1)\ndat <- unboxy(iterations = 1000, layers = 5) \n\ndat\nggplot(dat, aes(x, y)) + \n  geom_point(colour = \"white\", show.legend = FALSE) +\n  coord_equal(xlim = c(-2.5, 2.5), ylim = c(-2.5, 2.5)) + \n  theme_void()\n\n\n\n# A tibble: 1,001 × 3\n         x       y     val\n     <dbl>   <dbl>   <dbl>\n 1  0.579  -0.953  -0.0455\n 2  0.236   1.93    0.427 \n 3  0.666   0.962   1.32  \n 4 -1.95    1.07    1.65  \n 5  0.935   0.643   0.670 \n 6 -0.0757  2.51    1.85  \n 7 -0.884  -0.0703  1.36  \n 8  1.09    0.233   0.158 \n 9  0.672  -0.966  -0.421 \n10 -0.929  -0.227  -0.539 \n# … with 991 more rows\n\n\n\n\n\n\n\n\n\n\n\n\npic <- ggplot(dat, aes(x, y, fill = val)) +\n  theme_void() + \n  coord_equal(xlim = c(-2.5, 2.5), ylim = c(-2.5, 2.5)) + \n  scale_fill_gradientn(colours = sample_canva2()) + \n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0))\n\npic +\n  geom_voronoi_tile(\n    max.radius = NULL,\n    radius = 0,\n    expand = 0,\n    colour = \"#222222\",\n    size = .2, \n    show.legend = FALSE\n  )\n\n\n\n\n\n\n\n\n\nsift <- function(grain = .025) {\n  function(data) {\n    data <- data |>\n      group_by(group) |>\n      mutate(tilesize = (max(x) - min(x)) * (max(y) - min(y))) |>\n      ungroup()\n    data$tilealpha <- .5\n    data$tilealpha[data$tilesize < grain^2] <- 1\n    return(data)\n  }\n}\n\nmake_voronoise_art <- function(data, mapping, perturb, ...) {\n  ggplot(data, mapping) +\n    geom_voronoise(\n      perturb = perturb,\n      ...,\n      show.legend = FALSE\n    ) +\n    theme_void() + \n    coord_equal(xlim = c(-3, 3), ylim = c(-3, 3)) + \n    scale_fill_gradientn(colours = sample_canva2()) + \n    scale_alpha_identity() +\n    scale_x_continuous(expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0))\n}\n\nset.seed(1)\nmake_voronoise_art(\n  data = unboxy(iterations = 10000, layers = 5),\n  mapping = aes(x, y, fill = val, alpha = after_stat(tilealpha)),\n  max.radius = NULL,\n  radius = 0,\n  expand = 0,\n  perturb = sift(.2)\n)\n\n\n\n\n\n\n\n\n\nthat_boxy_style <- function(seed) {\n  set.seed(seed)\n  make_voronoise_art(\n    data = unboxy(iterations = 10000, layers = 5),\n    mapping = aes(x, y, fill = val, alpha = after_stat(tilealpha)),\n    max.radius = NULL,\n    radius = 0,\n    expand = 0,\n    perturb = sift(.2)\n  )\n}\n\nthat_boxy_style(1234)\nthat_boxy_style(4000)\nthat_boxy_style(2468)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(42)\n\nggplot(\n  data = unboxy(10000, 5), \n  mapping = aes(\n    x = x,\n    y = y, \n    fill = val\n  )\n) +\n  geom_voronoise(\n    perturb = function(data) {\n      data |> \n        group_by(group) |>\n        mutate(\n          x = x + runif(1)/10, \n          y = y + runif(1)/10\n        ) |>\n        ungroup()\n    },\n    max.radius = NULL,\n    radius = 0,\n    expand = 0,\n    colour = \"#222222\",\n    size = .2, \n    show.legend = FALSE\n  ) +\n  theme_void() + \n  coord_equal(xlim = c(-3, 3), ylim = c(-3, 3)) + \n  scale_fill_gradientn(colours = sample_canva2()) + \n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  theme(panel.background = element_rect(\n    fill = \"#222222\", colour = \"#222222\"\n  ))"
  },
  {
    "objectID": "day-2/session-2/index.html#studies-in-voronoi-baroque-part-i",
    "href": "day-2/session-2/index.html#studies-in-voronoi-baroque-part-i",
    "title": "TILES AND TESSELATIONS",
    "section": "Studies in Voronoi baroque: Part I",
    "text": "Studies in Voronoi baroque: Part I\nWhen I first started playing around with Voronoi tesselations the pieces I made looked a lot like the worked example: the Voronoise series I posted on my art site contains pieces that look like the one above, generated from random collections of points. What I started realising a little later is that if you feed a structured set of points into your Voronoi tesselations, you can create some very elaborate patterns. I’ve played around with this idea in a few series (my favourite so far is Sadists Kiss).\nI’ll illustrate the approach by reusing an earlier system. The unboxy() function shown below reimplements the “unboxing” system that I talked about in the section on iterated function systems:\n\nunboxy <- function(iterations, layers) {\n  \n  coeffs <- array(\n    data = runif(9 * layers, min = -1, max = 1), \n    dim = c(3, 3, layers)\n  )\n  \n  point0 <- matrix(\n    data = runif(3, min = -1, max = 1), \n    nrow = 1,\n    ncol = 3\n  )\n  \n  funs <- list(\n    function(point) point + (sum(point ^ 2)) ^ (1/3),\n    function(point) sin(point),\n    function(point) 2 * sin(point)\n  )\n  \n  update <- function(point, t) {\n    l <- sample(layers, 1)\n    f <- sample(funs, 1)[[1]]\n    z <- point[3]\n    point[3] <- 1\n    point <- f(point %*% coeffs[,,l])\n    point[3] <- (point[3] + z)/2\n    return(point)\n  }\n  \n  points <- accumulate(1:iterations, update, .init = point0)\n  points <- matrix(unlist(points), ncol = 3, byrow = TRUE)\n  points <- as_tibble(as.data.frame(points)) \n  names(points) <- c(\"x\", \"y\", \"val\")\n  return(points)\n}\n\nI’m not going to explain the inner workings of this function here (because they’re already discussed elsewhere), but in case you need a refresher or haven’t read the relevant page, here’s a look at the kinds of data this function produces, and a scatterplot showing the very non-random spatial patterns it generates:\n\nset.seed(1)\ndat <- unboxy(iterations = 1000, layers = 5) \n\ndat\nggplot(dat, aes(x, y)) + \n  geom_point(colour = \"white\", show.legend = FALSE) +\n  coord_equal(xlim = c(-2.5, 2.5), ylim = c(-2.5, 2.5)) + \n  theme_void()\n\n\n\n# A tibble: 1,001 × 3\n         x       y     val\n     <dbl>   <dbl>   <dbl>\n 1  0.579  -0.953  -0.0455\n 2  0.236   1.93    0.427 \n 3  0.666   0.962   1.32  \n 4 -1.95    1.07    1.65  \n 5  0.935   0.643   0.670 \n 6 -0.0757  2.51    1.85  \n 7 -0.884  -0.0703  1.36  \n 8  1.09    0.233   0.158 \n 9  0.672  -0.966  -0.421 \n10 -0.929  -0.227  -0.539 \n# … with 991 more rows\n\n\n\n\n\n\n\n\n\n\n\nNow let’s plot the Voronoi tesselation corresponding to these points, once again relying on our old friend sample_canva2() to generate the palette:\n\npic <- ggplot(dat, aes(x, y, fill = val)) +\n  theme_void() + \n  coord_equal(xlim = c(-2.5, 2.5), ylim = c(-2.5, 2.5)) + \n  scale_fill_gradientn(colours = sample_canva2()) + \n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0))\n\npic +\n  geom_voronoi_tile(\n    colour = \"#222222\",\n    size = .2, \n    show.legend = FALSE\n  )\n\n\n\n\n\n\n\n\nRounding the corners and expanding the tiles gives the piece a different feel…\n\npic +\n  geom_voronoi_tile(\n    radius = .01,\n    expand = .01,\n    colour = \"#222222\",\n    size = .2, \n    show.legend = FALSE\n  )\n\n\n\n\n\n\n\n\nSo does this…\n\npic +\n  geom_voronoi_tile(\n    max.radius = .1,\n    radius = .01,\n    expand = -.0001,\n    colour = \"#222222\",\n    size = .2, \n    show.legend = FALSE\n  )\n\n\n\n\n\n\n\n\nThe possibilities are surprisingly rich, and quite a lot of fun to play around with!\n\n\n\n\n\n\nExercise\n\n\n\nA script containing code for this system is included in the materials folder, as the voronoi-unbox.R file"
  },
  {
    "objectID": "day-2/session-2/index.html#studies-in-voronoi-baroque-part-ii",
    "href": "day-2/session-2/index.html#studies-in-voronoi-baroque-part-ii",
    "title": "TILES AND TESSELATIONS",
    "section": "Studies in Voronoi baroque: Part II",
    "text": "Studies in Voronoi baroque: Part II\nOkay, I need to confess something. Voronoi tiling art was the thing that finally pushed me to learn the ggproto object oriented programming system used by ggplot2. It’s not because I’m a masochist and enjoy the pain of learning an OOP system that isn’t used for anything except ggplot2. No-one is that much of a masochist, surely. No, it was because I wanted the ability to intercept and modify the Voronoi tiles during the plot construction process. Because… yeah, I don’t even remember why I wanted that. Evil reasons, probably.\nEnter stage left, the voronoise package. It’s not on CRAN – because I can’t think of a single good reason to send it to CRAN – but you can install it from GitHub with\nremotes::install_github(\"djnavarro/voronoise\")\nThe voronoise package only does one thing: it supplies geom_voronoise(), a geom that behaves just like geom_voronoi_tile() except for the fact you can pass it a “perturbing function” that modifies the tiles. Annoyingly – because I was not a very good software developer at the time and I was not thinking about what someone else (i.e., future me) would use it for later – the default arguments to geom_voronoise() aren’t the same as the defaults for geom_voronoi_tile(), which means it’s a good idea to explicitly specify things like max.radius etc even if you’re “just going to use the defaults”. Sorry. That was my mistake. I cannot stress enough that voronoise is not a good package. But… it’ll do for my purposes today.\nHere’s a simple example where the perturb argument is used to shift all the tiles to the right by a random offset:\n\npic +\n  geom_voronoi_tile( # original tiling in grey\n    max.radius = .1,\n    radius = .01,\n    expand = -.0001,\n    fill = \"#444444\",\n    colour = \"#222222\",\n    size = .2, \n    show.legend = FALSE\n  ) +\n  voronoise::geom_voronoise( # perturbed tiling\n    max.radius = .1,\n    radius = .01,\n    expand = -.0002,\n    perturb = \\(data) data |> \n      group_by(group) |> \n      mutate(x = x + runif(1, min = 0, max = .2)), \n    show.legend = FALSE\n  )\n\n\n\n\n\n\n\n\nThat’s kind of neat. Another approach I’ve been fond of in the past is to use something like this sift() function, which computes a crude approximation to the area of each tile and perturbs only those tiles smaller than a certain size:\n\nsift <- function(data) {\n  data <- data |>\n    group_by(group) |>\n    mutate(\n      tilesize = (max(x) - min(x)) * (max(y) - min(y)),\n      x = if_else(tilesize > .02, x, x + rnorm(1)/10), \n      y = if_else(tilesize > .02, y, y + rnorm(1)/10)\n    ) |>\n    ungroup()\n  return(data)\n}\n\n\nvoronoi_baroque <- function(\n    seed, \n    perturb, \n    max.radius = NULL, \n    radius = 0, \n    expand = 0,\n    ...\n) {\n  \n  set.seed(seed)\n  \n  blank <- ggplot(mapping = aes(x, y, fill = val)) +\n    theme_void() + \n    coord_equal(xlim = c(-2.75, 2.75), ylim = c(-2.75, 2.75)) + \n    guides(fill = guide_none(), alpha = guide_none()) +\n    scale_fill_gradientn(colours = sample_canva2(seed)) + \n    scale_alpha_identity() + \n    scale_x_continuous(expand = c(0, 0)) +\n    scale_y_continuous(expand = c(0, 0))\n  \n  blank + \n    geom_voronoise(\n      data = unboxy(iterations = 10000, layers = 5),\n      perturb = perturb,\n      max.radius = max.radius,\n      radius = radius,\n      expand = expand,\n      ...,\n      show.legend = FALSE\n    )\n}\n\n\nvoronoi_baroque(1234, sift)\nvoronoi_baroque(4000, sift)\nvoronoi_baroque(2468, sift)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe fun thing about voronoi_baroque() is that you can write whatever perturbation function you like… up to a point, of course. I cannot stress enough that the voronoise package is not particularly reliable!\n\nshake <- function(data) {\n  data |> \n    group_by(group) |>\n    mutate(\n      x = x + runif(1)/10, \n      y = y + runif(1)/10\n    ) |>\n    ungroup()\n}\n\n\nvoronoi_baroque(21, shake)\nvoronoi_baroque(43, shake)\nvoronoi_baroque(17, shake)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nCode for this system is included in the voronoi-baroque.R script."
  },
  {
    "objectID": "day-2/session-4/index.html",
    "href": "day-2/session-4/index.html",
    "title": "WRAP UP",
    "section": "",
    "text": "See that pretty life in pictures  See your lips erasing me  You’re so good to her, it’s vicious  Yeah, she should be thanking me  Oh, who’s gonna touch you like me?  Yeah, tell me, who?  Who can make you forget about me?      –Camila Cabello\nAnd so we come to the end. I’ve never loved writing endings. Beginnings feel natural to me: every human life begins in approximately the same state – human embryos just aren’t that different from one another in the big scheme of things – but everyone follows a different trajectory. Lives end in a myriad of different ways, and there’s not usually a coherent story to tell about them. Endings to books, articles, workshops, courses, etc … either I’m unskilled at writing them, or technical writing just doesn’t have a narrative structure that lends itself to tidy endings.\nOh well.\nStill, I have to write something on this page, and maybe it isn’t a bad idea to take a step back and think about the role generative art can play in life, careers, and so on."
  },
  {
    "objectID": "day-2/session-3/index.html#blah",
    "href": "day-2/session-3/index.html#blah",
    "title": "PIXEL FILTERS WITH GGFX",
    "section": "BLAH",
    "text": "BLAH\n\nnative_flora <- function(dat, shades, xlim = NULL, ylim = NULL) {\n  \n  dat <- dat |> \n    group_by(id_tree) |> \n    filter(\n      id_path %in% sample(max(id_path), 0.4 * max(id_path)), \n      id_time > 2\n    ) |>\n    mutate(\n      coord_x = coord_x + runif(1, min = -3, max = 3),\n      coord_y = coord_y + runif(1, min = -3, max = 3)\n    ) |>\n    ungroup()\n  \n  leaf <- dat |> \n    filter(\n      id_time == max(id_time), \n      id_step == 2\n    )\n  \n  dat |> \n    ggplot(aes(\n      x = coord_x, \n      y = coord_y, \n      group = id_pathtree, \n      colour = id_tree\n    )) + \n    geom_bezier(\n      alpha = 1, \n      size = 0.3, \n      show.legend = FALSE, \n      lineend = \"round\"\n    ) + \n    geom_point(\n      data = leaf, \n      show.legend = FALSE, \n      size = 1.3, \n      stroke = 0\n    ) + \n    scale_size_identity() + \n    scale_color_gradientn(colours = shades) + \n    theme_void() + \n    coord_equal(xlim = xlim, ylim = ylim) + \n    theme(panel.background = element_rect(\n      fill = \"#303030\", colour = \"#303030\"\n    ))\n}\n\ntic()\ndat <- flametree_grow(\n  time = 11, \n  trees = 10, \n  seed = 286,\n  scale = c(.8, .9, .95)\n)\npic <- dat |> \n  native_flora(\n    shades = c(\"#0c0c1e\", \"#74112f\", \"#f3e3e2\"), \n    xlim = c(-6, 2), \n    ylim = c(1, 9)\n  )\npic\n\n\n\n\n\n\n\ntoc()\n\n12.49 sec elapsed\n\n\n\nflora_fx <- function(dat, \n                     shape = 1, \n                     shades = NULL, \n                     xlim = NULL, \n                     ylim = NULL, \n                     seed = NULL) {\n  \n  if(is.null(shades)) shades <- sample(canva_palettes, 1)[[1]]\n  if(is.null(xlim)) xlim <- range(dat$coord_x)\n  if(is.null(ylim)) ylim <- range(dat$coord_y)\n  if(!is.null(seed)) set.seed(seed)\n  \n  dat <- dat |> \n    group_by(id_tree) |> \n    filter(\n      id_path %in% sample(max(id_path), 0.4 * max(id_path)), \n      id_time > 2\n    ) |>\n    mutate(\n      coord_x = coord_x + runif(1, min = -3, max = 3),\n      coord_y = coord_y + runif(1, min = -3, max = 3)\n    ) |>\n    ungroup()\n  \n  leaf <- dat |> \n    filter(\n      id_time == max(id_time), \n      id_step == 2\n    )\n  \n  dat |> \n    ggplot(aes(\n      x = coord_x, \n      y = coord_y, \n      group = id_pathtree, \n      colour = id_tree\n    )) + \n    \n    # group the \"flora\" layers\n    as_group(\n      geom_bezier(\n        alpha = 1, \n        size = 0.3, \n        show.legend = FALSE, \n        lineend = \"round\"\n      ), \n      geom_point(\n        data = leaf, \n        show.legend = FALSE, \n        size = 1.3, \n        stroke = 0\n      ), \n      id = \"flora\"\n    ) + \n    \n    # layer to serve as a \"canvas\"\n    as_reference(\n      geom_point(\n        data = tibble(\n          x = runif(10, min = xlim[1], max = xlim[2]),\n          y = runif(10, min = ylim[1], max = ylim[2])\n        ),\n        mapping = aes(x, y),\n        colour = \"#303030\",\n        fill = \"#303030\",\n        shape = shape,\n        stroke = 20,\n        size = 100,\n        show.legend = FALSE,\n        inherit.aes = FALSE\n      ),\n      id = \"canvas\"\n    ) +    \n    \n    # create a print layer that fills the \n    # \"canvas\" layer using the \"flora\" layer\n    as_reference(\n      with_blend(\"flora\",\n                 bg_layer = \"canvas\",\n                 blend_type = \"in\",\n                 flip_order = FALSE\n      ),\n      id = \"print\"\n    ) +\n    \n    # add drop shadow because why not\n    with_shadow(\"print\") +  \n    \n    scale_size_identity() + \n    scale_color_gradientn(colours = shades) + \n    theme_void() + \n    coord_equal(xlim = xlim, ylim = ylim) + \n    theme(panel.background = element_rect(\n      fill = \"#303030\", colour = \"#303030\"\n    ))\n}\n\ntic()\ndat <- flametree_grow(\n  time = 11, \n  trees = 10, \n  seed = 286,\n  scale = c(.8, .9, .95)\n)\ndat |> flora_fx(    \n  shades = c(\"#0c0c1e\", \"#74112f\", \"#f3e3e2\"), \n  xlim = c(-6, 2), \n  ylim = c(1, 9)\n)\n\n\n\n\n\n\n\ntoc()\n\n11.398 sec elapsed\n\n\n\ndat |> flora_fx(seed = 999, xlim = c(-8, 4), ylim = c(-1, 11))\ndat |> flora_fx(seed = 333, xlim = c(-6, 2), ylim = c(1, 9))\ndat |> flora_fx(seed = 666, xlim = c(-4, 0), ylim = c(3, 7), shape = 0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npixels <- 1000\nseed <- 1234\npalette <- c(\"#222222\",\"#e83e8c\")\n\n\ncanvas <- long_grid(\n  x = seq(from = -1, to = 1, length.out = pixels),\n  y = seq(from = -1, to = 1, length.out = pixels)\n) |> \n  mutate(\n    lf_noise = gen_simplex(x, y, frequency = 2, seed = seed),\n    mf_noise = gen_simplex(x, y, frequency = 20, seed = seed),\n    hf_noise = gen_simplex(x, y, frequency = 99, seed = seed),\n    paint = lf_noise + mf_noise + hf_noise\n  )\n\nhexagon <- tibble(\n  theta = (1:6)/6 * 2 * pi,\n  x = sin(theta),\n  y = cos(theta)\n)\n\nhextext <- tibble(\n  x = 0,\n  y = c(.2, -.2),\n  text = c(\"use(code) |>\", \"make(art)\")\n)\n\ncanvas |> \n  ggplot(aes(x, y)) + \n  as_reference(\n    geom_polygon(data = hexagon, fill = \"white\"), \n    id = \"hexagon\"\n  ) +  \n  as_group(\n    geom_raster(aes(fill = paint), show.legend = FALSE),\n    geom_text(data = hextext, aes(label = text), size = 18, colour = \"white\", \n              family = \"Ubuntu\", fontface = \"bold\"),\n    geom_polygon(data = hexagon, fill = NA, colour = \"white\", size = 10),\n    id = \"interior\"\n  ) + \n  with_blend(\"interior\", \"hexagon\", blend_type = \"in\") +\n  theme_void() +\n  coord_equal() +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  scale_fill_gradientn(colours = palette)"
  },
  {
    "objectID": "day-2/session-3/index.html#dithering",
    "href": "day-2/session-3/index.html#dithering",
    "title": "PIXEL FILTERS WITH GGFX",
    "section": "Dithering",
    "text": "Dithering\n\nset.seed(1)\nn <- 200\npolar_data <- tibble(\n  x0 = runif(n),\n  y0 = runif(n),\n  x1 = x0 + runif(n, min = -.2, max = .2),\n  y1 = y0,\n  shade = runif(n), \n  size = runif(n)\n)\n\npolar_canvas <- ggplot(\n  data = polar_data, \n  mapping = aes(x0, y0, xend = x1, yend = y1, colour = shade, size = size)\n) + \n  coord_polar(clip = \"off\") +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 1), oob = oob_keep) +\n  scale_x_continuous(expand = c(0, 0), limits = c(0, 1), oob = oob_keep) + \n  scale_colour_gradientn(colours = sample_canva2(seed = 10)) + \n  guides(colour = guide_none(), size = guide_none()) + \n  scale_size(range = c(0, 10)) + \n  theme_void()\n\n\npolar_canvas + geom_segment()\npolar_canvas + with_dither(geom_segment(), max_colours = 6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npolar_canvas + geom_segment()\npolar_canvas + with_halftone_dither(geom_segment())\npolar_canvas + with_halftone_dither(geom_segment(), black = FALSE)"
  },
  {
    "objectID": "day-2/session-3/index.html#dither",
    "href": "day-2/session-3/index.html#dither",
    "title": "PIXEL FILTERS",
    "section": "Dither",
    "text": "Dither\nThe previous example gives you a pretty good sense of the core mechanic of ggfx: the package supplies the with_*() functions that correspond to different kinds of pixel filtering operations. There are quite a lot of filters you might want to try. Dithering is a technique in which we reduce (or quantise) an image that has many colours down to an image with fewer colours, and then add some random (or not-so-random) noise to the coarser-grained image in a way that leaves it looking fairly natural. There are a lot of ways in which you can dither an image: one of the most famous is the Floyd-Steinberg algorithm. The Wikipedia page on Floyd-Steinberg dithering gives a nice (CC-licenced!) example using a kitten picture, shown to the left.\n  \nThe original image is shown on the left. The image in the middle reduces the number of distinct colours in the image (i.e. quantises it) but doesn’t apply any dithering. It’s immediately obvious that there are artifacts in the image, and it doesn’t look like a very good approximation to the original. On the right, a dithering algorithm is applied. The image still uses the same small set of colours, but arranges the pixels in such a way that the local density of light and dark pixels gives the impression of shading.\nThe ggfx package supplies several dithering filters, including:\n\nwith_dither() uses Floyd-Steinberg dithering\nwith_halftone_dither() uses halftone dots\nwith_ordered_dither() uses ordered dithering\nwith_custom_dither() lets you build your own!\n\nSo let’s take a look. If we want to apply dithering to some generative art, it would help to have some generative art code! This time around, I’ll reuse the code that we wrote in the very first session to create “polar coordinate art” in ggplot2. To spare you the effort of revisiting, here’s the code we’re going to use to specify a base image:\n\nset.seed(1)\npolar <- tibble(\n  arc_start = runif(200),\n  arc_end = arc_start + runif(200, min = -.2, max = .2),\n  radius = runif(200),\n  shade = runif(200), \n  size = runif(200)\n)\n\nbase <- ggplot(\n  data = polar, \n  mapping = aes(\n    x = arc_start, \n    y = radius,\n    xend = arc_end, \n    yend = radius, \n    colour = shade, \n    size = size\n  )\n) + \n  coord_polar(clip = \"off\") +\n  scale_y_continuous(limits = c(0, 1), oob = scales::oob_keep) +\n  scale_x_continuous(limits = c(0, 1), oob = scales::oob_keep) + \n  scale_colour_viridis_c(option = \"magma\") +\n  guides(colour = guide_none(), size = guide_none()) + \n  scale_size(range = c(0, 10)) + \n  theme_void() +\n  theme(panel.background = element_rect(fill = \"#aaaaaa\"))\n\nThe details to this don’t matter very much for this session. All that matters is that when we add geom_segment() to base, it produces radial art like the image shown below on the left. Then, on the right, we can see the effect of the with_dither() function. I’ve reduced the image to five distinct colours in order to exaggerate the dithering effect as much as possible. Any lower than this and the image degrades too much.\n\nbase + geom_segment()\nbase + with_dither(geom_segment(), max_colours = 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFloyd-Steinberg dithering gives the image a slightly grainy feel. It can be very handy when you don’t want the art to look too clean. Rendering the image in halftone gives it a more patterend feel, as the images below illustrate:\n\nbase + with_halftone_dither(geom_segment())\nwith_halftone_dither(base + geom_segment())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotice the difference between these two examples. The with_*() functions in ggfx are quite flexible. You can pass a single layer as the input, or alternatively you can pass the whole image. In fact, if you’re comfortable with grid graphics, you can pass individual grobs too. This is discussed in the ggfx object support help page.\n\n\n\n\n\n\nExercise\n\n\n\nA script containing this code is included as the ggfx-dither.R file"
  },
  {
    "objectID": "day-2/session-3/index.html#mask",
    "href": "day-2/session-3/index.html#mask",
    "title": "PIXEL FILTERS",
    "section": "Mask",
    "text": "Mask\nOne of my favourite filtering tricks is to use with_mask() as a way of displaying one layer of the plot only when it overlaps with a second layer (referred to as the “mask”). To see why I love this so much, let’s use the ambient package to create a textured grid that we could draw using geom_raster(). I talked about this in the session on spatial noise tricks, so I won’t bore you by repeating the explanation. Instead, here’s the code to create a layer called texture:\n\ntexture <- geom_raster(\n  mapping = aes(x, y, fill = paint),\n  data = long_grid(\n    x = seq(from = -1, to = 1, length.out = 1000),\n    y = seq(from = -1, to = 1, length.out = 1000)\n  ) |> \n    mutate(\n      lf_noise = gen_simplex(x, y, frequency = 2, seed = 1234),\n      mf_noise = gen_simplex(x, y, frequency = 20, seed = 1234),\n      hf_noise = gen_simplex(x, y, frequency = 99, seed = 1234),\n      paint = lf_noise + mf_noise + hf_noise\n    )\n)\n\nWe’re going to use texture as our background, but instead of plotting the whole thing we’re going mask it. Let’s create a polygon layer that will serve as the mask.\n\nhex <- tibble(x = sin((0:6)/6 * 2 * pi), y = cos((0:6)/6 * 2 * pi))\nmask <- geom_polygon(aes(x, y), hex, fill = \"white\")\n\nAs before I’ll create a base plot to which we can add these geoms. The code isn’t very interesting, but I should be thorough and show it to you anyway:\n\nbase <- ggplot() + \n  theme_void() +\n  coord_equal() +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  scale_fill_gradientn(\n    colours = c(\"#222222\",\"#e83e8c\"), \n    guide = guide_none()\n  )\n\nOkay, so now let’s take a look the two layers individually:\n\nbase + texture\nbase + mask\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGosh, I wonder what we could possibly do with a texture and a hexagon shape…\n\nbase + \n  as_reference(mask, id = \"mask\") + \n  with_mask(texture, \"mask\")\n\n\n\n\n\n\n\n\nHuh. Well look at that… we have something that could quite easily turn into the design of a hex sticker. Amazing.\nBefore we move on I should explain why I called as_reference() in the previous example, and what that function does. To get a sense of it, let’s see what happens if I attempt the more “intuitive” strategy of trying to pass the mask layer directly to with_mask():\n\nbase + with_mask(texture, mask)\n\nError in UseMethod(\"as.raster\"): no applicable method for 'as.raster' applied to an object of class \"c('LayerInstance', 'Layer', 'ggproto', 'gg')\"\n\n\nThe error message here complains that R doesn’t know how to convert the mask layer to a raster object. Remember at the beginning I said that ggfx works by converting everything to a pixel representation (i.e., turn our vector graphics layer into raster graphics). What’s going on here is that the second argument to with_mask() is allowed to be a “registered filter”, or it has to actually be a raster object. I’m not doing either one! I’m trying to pass it a raw ggplot layer. That’s where the as_reference() function comes in. Its role is to take a layer and “register” it as a filter (the id argument is used to give it a name) that can subsequently used as the mask.\nThere are a few functions in ggfx that work like that. Another one is the as_group() function. Suppose I want to apply a filter to several layers at once, but not necessarily to the whole plot. For example, suppose I want some text and a pretty border on my hex sticker, represented by these two layers:\n\nborder <- geom_path(aes(x, y), hex, colour = \"white\", size = 15)\n\ntext <- geom_text(\n  mapping = aes(x, y, label = text), \n  dat = tibble(x = 0, y = 0, text = \"ART\"), \n  size = 36,\n  colour = \"white\", \n  fontface = \"bold\"\n) \n\nWhen I construct my mask, what I really want to do is apply it to all three layers: texture, border, and text should all be masked by the mask layer. To do that I pass texture, border, and text to as_group() to define the group; then I pass mask to as_reference() to register it as a filter; and then I apply with_mask(). Here’s how that works:\n\nbase + texture + text + border\nbase + \n  as_group(texture, text, border, id = \"content\") +\n  as_reference(mask, id = \"mask\") + \n  with_mask(\"content\", \"mask\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThat’s awfully convenient :)\n\n\n\n\n\n\nExercise\n\n\n\nA script containing this code is included as the ggfx-mask.R file"
  },
  {
    "objectID": "day-2/session-3/index.html#glow",
    "href": "day-2/session-3/index.html#glow",
    "title": "PIXEL FILTERS",
    "section": "Glow",
    "text": "Glow\n…but it could be prettier, don’t you think? Maybe we could add a glow around the leaves, to give it a twinkling look. This feels like the kind of job for a pixel filter, and ggfx should be able to do this for us. Conceptually, what we want to do is apply a “glow” filter to the leaves of our tree, but not to the trunk. We can do that in ggfx by using the with_outer_glow() filtering function: we pass the leaves layer to the filter, along with some other arguments (e.g., colour) that specify the properties of the glow. The examples below show this in action: the left plot is the original tree, the middle one adds a small white glow to the leaves, and the right one adds a much bigger glow:\n\nbase + trunk + leaves\nbase +   \n  trunk + \n  with_outer_glow(leaves, colour = \"white\")\nbase +   \n  trunk + \n  with_outer_glow(leaves, colour = \"white\", sigma = 5, expand = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn the third example, sigma is interpreted as the standard deviation of the Gaussian blur added around each point: sigma = 5 specifies that this standard deviation is 5 pixels in size. The expand = 3 argument tells ggfx to “expand” each point by 3 pixels before drawing the glow. This can be handy for very small objects that would otherwise be difficult to see even with the added glow.\nWhen written like this – with each layer stored as a named variable – ggfx code is very easy to read. I’ve quickly found myself adopting this code style any time I want to do pixel filtering. Constructing the plot piecewise and storing each layer as a variable makes it much easier to see what I’m doing!\nAs an aside, yes, there is also a with_inner_glow() function that applies the glow to the interior of each object rather than extending the glow outside it.\n\n\n\n\n\n\nExercise\n\n\n\nA script containing this code is included as the ggfx-glow.R file"
  },
  {
    "objectID": "day-2/session-3/index.html#displace",
    "href": "day-2/session-3/index.html#displace",
    "title": "PIXEL FILTERS",
    "section": "Displace",
    "text": "Displace\nDisplacement filters are conceptually simple, but extremely powerful, and can be a bit counterintuitive to work with in practice. The idea to shift all the pixels in one layer based on the pixel values in another layer (referred to as the displacement map). For example, a black pixel in the displacement map might be interpreted to mean “don’t move this pixel in the original layer”, whereas a white pixel might mean “move this 10 pixels to the right”. The idea of constructing a pixel value to displacement mapping makes conceptual sense to me, but I find it a little hard to visualise what that actually means. A worked example would probably help!\nLet’s start by creating some ggplot layers that each contain semi-transparent triangles:\n\npolygon_layer <- function(x, y, fill = \"white\", alpha = .5) {\n  geom_polygon(aes(x, y), fill = fill, alpha = alpha)\n}\npoly1 <- polygon_layer(x = c(1, 0, 0), y = c(0, 0, 1))\npoly2 <- polygon_layer(x = c(0, 1, 1), y = c(0, 0, 1))\npoly3 <- polygon_layer(x = c(.3, 1, 1), y = c(0, 0, .7))\npoly4 <- polygon_layer(x = c(0, 0, .7), y = c(.3, 1, 1))\n\nNext, I’ll define a base plot and then show you what these polygons look like when drawn together:\n\nbase <- ggplot() + \n  coord_equal(xlim = c(0, 1), ylim = c(0, 1)) + \n  theme_void() + \n  theme(panel.background = element_rect(fill = \"#333333\"))\n\nbase + poly1 + poly2 + poly3 + poly4\n\n\n\n\n\n\n\n\nLater on, we’re going to use this as our displacement map. The easiest way to interpret this map (I think?) is to think about each of the shaded regions separately. Let’s start by thinking about the darkest area, the region that makes up the border of the image and the diagonal stripe in the center. When we go to “fill in” that part of the final image, we won’t grab the “same” pixel in the other image: instead we’re going to grab a pixel that is below and to the left. For the brightest areas (the two bright white triangles, one to the top left of the map and the other to the bottom right), we’ll displace in the other direction.\nOkay, so if we’re going to do this, we will need an layer that can serve as the image to be displaced. I’ll keep it simple. Here’s a layer that plots the word \"ART\" using geom_text():\n\ntext <- geom_text(\n  mapping = aes(0.5, 0.5, label = \"ART\"), \n  size = 60, \n  colour = \"black\", \n  fontface = \"bold\"\n)\n\nSo here’s our process:\n\nUse as_group() to convert the four polygon layers into a single group.\nUse as_reference() to register that group as a filter.\nUse with_displacement() to displace the text layer using the polygons.\n\nHere’s the code, and the results:\n\nbase + poly1 + poly2 + poly3 + poly4 + text\nbase + \n  as_group(poly1, poly2, poly3, poly4, id = \"polygons\", include = TRUE) +\n  as_reference(\"polygons\", id = \"displacement_map\") + \n  with_displacement(\n    text,\n    x_map = ch_alpha(\"displacement_map\"),\n    y_map = ch_alpha(\"displacement_map\"), \n    x_scale = 150,\n    y_scale = -150\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAgain, this is very pretty, but it probably needs a little explanation:\n\nWhen I called with_displacement() I passed the text object first: that’s the “thing we will displace”. Next, I specified two displacement maps, x_map and y_map. It is, after all, quite possible to use a different displacement map to describe how we find the displacement in the horizontal direction and the vertical directions! However, I haven’t done that here because it makes my head hurt.\nWhen constructing the displacement maps I used ch_alpha() to make clear that we should use the transparency value of each pixel as the basis for the displacement. That makes sense in this case because transparency is the thing that varies across the image.\nThe x_scale and y_scale parameters specify the number of pixels to shift. Specifically, setting x_scale = 150 means that the maximum difference in transparency should correspoind to a shift of 150 pixels.\n\nTo be perfectly honest, I find it hard to visualise the effect of with_displacement(). My spatial reasoning skills just aren’t good enough. So what I usually do is tinker until I find something I like. YMMV.\n\n\n\n\n\n\nExercise\n\n\n\nA script containing this code is included as the ggfx-displace.R file"
  },
  {
    "objectID": "day-2/session-3/index.html#blend",
    "href": "day-2/session-3/index.html#blend",
    "title": "PIXEL FILTERS",
    "section": "Blend",
    "text": "Blend\nThe last ggfx trick I want to mention is with_blend(). Blending filters compose two images together using a particular rule. For example, we could \"darken_intensity\" by selecting the darker of the two pixel values at each location. Or we could use a \"plus\" filter that just adds the pixel values together. Blending is a powerful technique and can be used to mimic the behaviour of other filters (e.g., a mask is really just a very particular type of blend). I’m not going to try to summarise all the different kinds of blend you can do. But I will point you to the documentation page for with_blend(), which provides a pretty good place to start and has links to other resources you can follow up on.\nMeanwhile, I’ll give a simple example using an \"xor\" blend. I’ll return to our flametree plot as the basis for this example. The trunk and leaves plot layers below define the flametree image in solid white colour:\n\nleaves <- geom_point(\n  data = leaf, \n  mapping = aes(coord_x, coord_y, colour = seg_col),\n  colour = \"white\",\n  size = 2, \n  stroke = 0\n)\n\ntrunk <- geom_bezier(\n  data = tree,\n  mapping = aes(\n    x = coord_x, \n    y = coord_y, \n    size = seg_wid,\n    group = id_pathtree\n  ),\n  colour = \"white\",\n  lineend = \"round\"\n)\n\nNext I’ll create a triangle layer that is a solid white triangle on the lower right side of the image, but is otherwise empty:\n\ntriangle <- polygon_layer(\n  x = c(-4, 2, 2), \n  y = c(0, 0, 6), \n  fill = \"white\",\n  alpha = 1\n)\n\nBecause these images are binary valued the exclusive-or \"xor\" filter is easy to visualise in this case. If a pixel is white in exactly one of the two inputs (the tree or the triangle), that pixel will also be white in the output. Otherwise that pixel will be transparent. That gives us this:\n\nbase <- ggplot() + \n  theme_void() +\n  coord_equal(xlim = c(-3, 1), ylim = c(1, 5)) +\n  scale_x_continuous(expand = c(0, 0)) +\n  scale_y_continuous(expand = c(0, 0)) +\n  scale_size_identity(guide = guide_none())\n\nbase +\n  as_group(trunk, leaves, id = \"tree\") + \n  with_blend(triangle, \"tree\", blend_type = \"xor\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nA script containing this code is included as the ggfx-blend.R file"
  },
  {
    "objectID": "day-2/session-3/index.html#prelude-flametree",
    "href": "day-2/session-3/index.html#prelude-flametree",
    "title": "PIXEL FILTERS",
    "section": "Prelude: flametree",
    "text": "Prelude: flametree\n\ntree <- flametree_grow(\n  seed = 1, \n  time = 8, \n  angle = c(-15, 15, 30)\n)\ntree\n\n# A tibble: 1,533 × 12\n   coord_x coord_y id_tree id_time id_path id_leaf id_pathtree id_step seg_deg\n     <dbl>   <dbl>   <int>   <int>   <int> <lgl>   <chr>         <int>   <dbl>\n 1  -0.839    0          1       1       1 FALSE   1_1               0      90\n 2  -0.839    0.5        1       1       1 FALSE   1_1               1      90\n 3  -0.839    1          1       1       1 FALSE   1_1               2      90\n 4  -0.839    1          1       2       2 FALSE   1_2               0      75\n 5  -0.839    1.45       1       2       2 FALSE   1_2               1      75\n 6  -0.606    1.87       1       2       2 FALSE   1_2               2      75\n 7  -0.839    1          1       2       3 FALSE   1_3               0      75\n 8  -0.839    1.3        1       2       3 FALSE   1_3               1      75\n 9  -0.683    1.58       1       2       3 FALSE   1_3               2      75\n10  -0.606    1.87       1       3       4 FALSE   1_4               0     105\n# … with 1,523 more rows, and 3 more variables: seg_len <dbl>, seg_col <dbl>,\n#   seg_wid <dbl>\n\n\n\ntrunk <- geom_bezier(\n  mapping = aes(coord_x, coord_y, group = id_pathtree, size = seg_wid),\n  data = tree, \n  lineend = \"round\", \n  colour = \"#444444\",\n  show.legend = FALSE\n)\n\nleaf <- tree |> \n  filter(id_time == max(id_time), id_step == 2)\n\nleaves <- geom_point(\n  mapping = aes(coord_x, coord_y),\n  data = leaf, \n  size = 1.3, \n  stroke = 0, \n  colour = \"#e38b75\"\n)\n\nbase <- ggplot() + scale_size_identity() + theme_void() + coord_equal()\nbase + trunk + leaves"
  },
  {
    "objectID": "day-2/session-3/index.html#prelude",
    "href": "day-2/session-3/index.html#prelude",
    "title": "PIXEL FILTERS",
    "section": "Prelude",
    "text": "Prelude\nWhen we dive into ggfx, it will be handy to have some data that we can use to make interesting art. For that purpose I’ll rely on the flametree package which I’ve used in the past to make pretty pictures of trees. The flametree_grow() function generates the raw data:\n\ntree <- flametree_grow(\n  seed = 1, \n  time = 9, \n  angle = c(-15, 15, 30)\n)\ntree\n\n\n\n# A tibble: 3,069 × 12\n   coord_x coord_y id_tree id_time id_path id_leaf id_pathtree id_step seg_deg seg_len seg_col seg_wid\n     <dbl>   <dbl>   <int>   <int>   <int> <lgl>   <chr>         <int>   <dbl>   <dbl>   <dbl>   <dbl>\n 1  -0.429    0          1       1       1 FALSE   1_1               0      90    1          3    4.67\n 2  -0.429    0.5        1       1       1 FALSE   1_1               1      90    1          3    4.67\n 3  -0.429    1          1       1       1 FALSE   1_1               2      90    1          3    4.67\n 4  -0.429    1          1       2       2 FALSE   1_2               0      75    0.9        4    3.59\n 5  -0.429    1.45       1       2       2 FALSE   1_2               1      75    0.9        4    3.59\n 6  -0.196    1.87       1       2       2 FALSE   1_2               2      75    0.9        4    3.59\n 7  -0.429    1          1       2       3 FALSE   1_3               0      75    0.6        4    3.59\n 8  -0.429    1.3        1       2       3 FALSE   1_3               1      75    0.6        4    3.59\n 9  -0.274    1.58       1       2       3 FALSE   1_3               2      75    0.6        4    3.59\n10  -0.196    1.87       1       3       4 FALSE   1_4               0     105    0.54       5    2.32\n# … with 3,059 more rows\n\n\nYou can render the output conveniently with the help of flametree_plot():\n\ntree |> \n  flametree_plot(\n    background = \"#222222\", \n    palette = c(\"#ffffff\", \"#f652a0\")\n  )\n\n\n\n\nThe flametree_plot() function is fairly flexible and allows you to draw the tree in several different styles, but for the purposes of this session we’ll want to write our own ggplot2 (and ggfx) code, so it may be helpful to explain what you’re looking at in this tree. Each curved segment in the tree is drawn as a Bézier curve specified by three control points whose locations are given by the coord_x and coord_y variables. Each row in the tibble refers to one control point, so there are three rows per segment. Here’s the three rows that correspond to the 99th segment in the tree:\n\ntree |> filter(path_id == 99)\n\n\n\n# A tibble: 3 × 12\n  coord_x coord_y id_tree id_time id_path id_leaf id_pathtree id_step seg_deg seg_len seg_col seg_wid\n    <dbl>   <dbl>   <int>   <int>   <int> <lgl>   <chr>         <int>   <dbl>   <dbl>   <dbl>   <dbl>\n1   -1.05    2.75       1       7      99 FALSE   1_99              0     180   0.140       9   0.161\n2   -1.11    2.78       1       7      99 FALSE   1_99              1     180   0.140       9   0.161\n3   -1.19    2.75       1       7      99 FALSE   1_99              2     180   0.140       9   0.161\n\n\nThe various columns here describe different aspects of the tree: there’s a seg_wid column representing the width of each segment (usually mapped to the size aesthetic), a seg_col column specifying a colour (usually mapped to the colour aesthetic), etc.\nOf particular relevance here is the id_leaf column. This column is a logical variable that is TRUE only for those control points that represent the very tips of the tree: the leaves, essentially. Later on I’m going to plot the tree trunk and leaves separately, so it’s convenient to have a leaf tibble that contains the data only for the leaf nodes:\n\nleaf <- tree |> filter(id_leaf == TRUE)\n\nOkay, now let’s construct a flametree image piece by piece. I’ll start with a base plot that specifies some stylistic choices but doesn’t map any aesthetics, doesn’t include any data, and doesn’t have any geoms. It’s a blank canvas:\n\nbase <- ggplot() + \n  scale_size_identity() + \n  theme_void() + \n  coord_equal()\n\nNow I’m going to create the individual geoms. Usually when we write ggplot2 code we just add the geoms directly to the plot, and if my only intention was to show you how flametree works I’d do that here. But later I’m going to use this in conjunction with ggfx, and the design of ggfx is such that you (usually) apply a filter to a ggplot2 layer. The ggfx code will look a lot cleaner if we store our layers as variables.\nFirst, let’s create a layer representing the leaves. The only thing we want to do with the leaf data is draw a scatter plot, and we can accomplish our goal using geom_point():\n\nleaves <- geom_point(\n  mapping = aes(coord_x, coord_y),\n  data = leaf, \n  size = 1.3, \n  stroke = 0, \n  colour = \"#e38b75\"\n)\n\nNow we can do the same thing to create the trunk. What we want in this case is something similar to geom_path(), but instead of plotting paths in linear segments we want to draw Bézier curves. Conveniently for us, the ggforce package supplies the geom_bezier() function that does exactly this. All we need to do is make sure we specify the group aesthetic so that there is one curve per segment in the tree. Here’s the code for doing that:\n\ntrunk <- geom_bezier(\n  mapping = aes(coord_x, coord_y, group = id_pathtree, size = seg_wid),\n  data = tree, \n  lineend = \"round\", \n  colour = \"#555555\",\n  show.legend = FALSE\n)\n\nHaving done all the work in this piecewise manner, the code to draw the tree is as simple as adding the trunk and leaves to the base image:\n\nbase + trunk + leaves\n\n\n\n\n\n\n\n\nVery pretty!\n\n\n\n\n\n\nExercise\n\n\n\nA script containing this code is included as the flametree-example.R script."
  },
  {
    "objectID": "day-2/session-4/index.html#let-them-eat-cake",
    "href": "day-2/session-4/index.html#let-them-eat-cake",
    "title": "WRAP UP",
    "section": "“Let them eat cake!”",
    "text": "“Let them eat cake!”\n\n# https://github.com/djnavarro/jasmines\nlibrary(jasmines)\nlibrary(dplyr)\n\ndat <- use_seed(769) |>\n  entity_heart(grain = 2000) |>\n  mutate(ind = 1:n()) |>\n  unfold_warp() |>\n  unfold_worley(scatter = TRUE) |>\n  unfold_breeze(\n    iterations = 100,\n    scale = .0005,\n    drift = 0,\n    fractal = ambient::billow,\n    octaves = 1\n  )  |>\n  mutate(val = ind + id * 50)\n\n# https://www.canva.com/colors/color-palettes/lily-leap/\nshades <- c(\"#40c69f\", \"#2e765e\",\"#d62b83\",\"#05234c\")\n\ndat |>\n  style_ribbon(\n    palette = palette_manual(shades),\n    colour = \"order\",\n    alpha = c(.25,.02),\n    background = \"grey90\",\n    type = \"segment\",\n    size = .4\n  )"
  },
  {
    "objectID": "day-2/session-4/index.html#icing-the-cake",
    "href": "day-2/session-4/index.html#icing-the-cake",
    "title": "WRAP UP",
    "section": "Icing the cake",
    "text": "Icing the cake\nA little while back I had the good fortune to come across Mine Çetinkaya-Rundels wonderful slide deck on best practices when teaching data science, “Let them eat cake (first)!”. In it, she talks about the importance of engaging learner interest in the topic early on. Very few people have ever been motivated to learn R by reading about operator precedence, functions as first class objects, or lazy evaluation. Whatever its other merits, I have never heard anyone argue the case that S4 is “sexy”, or that the R internals manual really really made them love the language. That’s not how this works. People want to be delighted by their tools. We like to play. Code that allows people to experience joy and do things love doing… it provides opportunities for growth, learning, and personal development.\nWhen I make art, my daughter Fiona is frequent collaborator and art critic. She was 6 when I started making generative art: she’s now 9. She’s interested in what I do artistically because she likes to draw, and is fascinated by the fact that I draw with code. In fact, she’s become curious about it enough that she has her own private repo on my GitHub account where – with a little help from me – she makes her own generative art. With her permission I’ll share one of her pieces here. She doesn’t use ggplot2 or ambient (yet!), but instead relies on the jasmines package I wrote to bundle up some of my art functions. Personally I don’t use jasmines anymore because that package really doesn’t do anything except provide a few canned tricks using ambient. But it is a handy package for people who aren’t quite ready to dive into those packages.\nAnyway, this is “Lily Pad”:\n\n# https://github.com/djnavarro/jasmines\nlibrary(jasmines)\nlibrary(dplyr)\n\ndat <- use_seed(769) |>\n  entity_heart(grain = 2000) |>\n  mutate(ind = 1:n()) |>\n  unfold_warp() |>\n  unfold_worley(scatter = TRUE) |>\n  unfold_breeze(\n    iterations = 100,\n    scale = .0005,\n    drift = 0,\n    fractal = ambient::billow,\n    octaves = 1\n  )  |>\n  mutate(val = ind + id * 50)\n\n# https://www.canva.com/colors/color-palettes/lily-leap/\nshades <- c(\"#40c69f\", \"#2e765e\",\"#d62b83\",\"#05234c\")\n\ndat |>\n  style_ribbon(\n    palette = palette_manual(shades),\n    colour = \"order\",\n    alpha = c(.25,.02),\n    background = \"grey90\",\n    type = \"segment\",\n    size = .4\n  )\n\n\n\n\n\n\n\n\nIt’s one of my favourite pieces of hers. Personally I love it, but maybe more importantly, she loved making it. Every time I find time to make art, she offers comments and critique, and when she’s in the mood she writes her own code.\nI love this so much because so much of the world seems hellbent on convincing her that she can’t accomplish “technical” things. No-one says it out loud, but looking at how content is designed for girls and boys it’s pretty hard to escape the conclusion that there’s a cultural bias towards misogyny that kicks in very early on. I mean, this was a girl who stole my copy of Gaussian Processes for Machine Learning at age 5 and got me to teach her “the maths with letters”. She’s quite capable of doing these things, but over time she’s become convinced that she’s not good at mathematics. There’s very little I can do about this as a parent: I can tell her these stories about her own past and about her abilities, yes, but she’s swimming in the same cultural waters as the rest of us, and she picks things up.\nAnd yet… she codes. She codes because no-one has told her she can’t. She codes because she loves it, because she can make beautiful things with it that appeal to her interests, and that motivates her to continue.\nAll this brings me back to Mine Çetinkaya-Rundels claim about pedagogy. If we want people to learn modern tools for data science, we should let them “eat cake first”. Show them the delightful things first. Don’t start classes by talking about operator precedence, start with ggplot2. Or… start with art. Okay it doesn’t have to be art. But start with something that makes people feel happy to be in the room. It will make a difference to them."
  },
  {
    "objectID": "slides/index.html#housekeeping",
    "href": "slides/index.html#housekeeping",
    "title": "ART FROM CODE",
    "section": "Housekeeping",
    "text": "Housekeeping\n\nWritten tutorial, data sets, exercises\n\nWebsite: art-from-code.netlify.app\nGitHub: github.com/rstudio-conf-2022/art-from-code\n\nInstructors:\n\nDanielle Navarro\n\n\n\n\nart-from-code.netlify.app"
  }
]